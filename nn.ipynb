{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DZEH【动物耳号】                                         0\n",
      "XKZH【许可证号】                                         0\n",
      "NCBH【农场编号】                                       600\n",
      "STATUS【状态】（0：合格；1：不合格）                             0\n",
      "YBMC【疫病名称】                                    162155\n",
      "JCJG【检测结果】                                    162541\n",
      "TTZL【淘汰种类】（G:个体淘汰;Q:规定疫病种类全群淘汰；C：阳性结果超限淘汰）    120256\n",
      "LCID【流程ID】                                     97661\n",
      "XB【性别】                                             0\n",
      "PZ【品种】                                           315\n",
      "TZZT【屠宰状态】                                    182038\n",
      "ACTIONMC【操作步骤】                                 99677\n",
      "CLYY【处理原因】                                    132959\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_data1 = pd.read_excel(\"./buffer.xlsx\", sheet_name=\"15\")\n",
    "all_data2 = pd.read_excel(\"./buffer.xlsx\", sheet_name=\"16\")\n",
    "all_data3 = pd.read_excel(\"./buffer.xlsx\", sheet_name=\"17\")\n",
    "all_data_c1 = all_data1.copy()\n",
    "all_data_c2 = all_data2.copy()\n",
    "all_data_c3 = all_data3.copy()\n",
    "'''\n",
    "all_data1 = all_data_c1\n",
    "all_data2 = all_data_c2\n",
    "all_data3  = all_data_c3\n",
    "all_data1.head()\n",
    "'''\n",
    "all_data1.fillna(0)\n",
    "all_data2.fillna(0)\n",
    "all_data3.fillna(0)\n",
    "print(all_data1.isnull().sum())\n",
    "data_map = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZEH【动物耳号】</th>\n",
       "      <th>XKZH【许可证号】</th>\n",
       "      <th>NCBH【农场编号】</th>\n",
       "      <th>STATUS【状态】（0：合格；1：不合格）</th>\n",
       "      <th>YBMC【疫病名称】</th>\n",
       "      <th>JCJG【检测结果】</th>\n",
       "      <th>TTZL【淘汰种类】（G:个体淘汰;Q:规定疫病种类全群淘汰；C：阳性结果超限淘汰）</th>\n",
       "      <th>LCID【流程ID】</th>\n",
       "      <th>XB【性别】</th>\n",
       "      <th>PZ【品种】</th>\n",
       "      <th>TZZT【屠宰状态】</th>\n",
       "      <th>ACTIONMC【操作步骤】</th>\n",
       "      <th>CLYY【处理原因】</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>951 000000002554</td>\n",
       "      <td>AA0015011493</td>\n",
       "      <td>EFAU06779</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>10575.0</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>951 000000002555</td>\n",
       "      <td>AA0015011493</td>\n",
       "      <td>EFAU06779</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>10575.0</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>951 000000002565</td>\n",
       "      <td>AA0015011493</td>\n",
       "      <td>EFAU11174</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10575.0</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>951 000000002568</td>\n",
       "      <td>AA0015011493</td>\n",
       "      <td>EFAU11174</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10575.0</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>951 000000002621</td>\n",
       "      <td>AA0015011493</td>\n",
       "      <td>EFAU11174</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10575.0</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DZEH【动物耳号】    XKZH【许可证号】 NCBH【农场编号】  STATUS【状态】（0：合格；1：不合格）  \\\n",
       "0  951 000000002554  AA0015011493  EFAU06779                       1   \n",
       "1  951 000000002555  AA0015011493  EFAU06779                       1   \n",
       "2  951 000000002565  AA0015011493  EFAU11174                       1   \n",
       "3  951 000000002568  AA0015011493  EFAU11174                       1   \n",
       "4  951 000000002621  AA0015011493  EFAU11174                       1   \n",
       "\n",
       "  YBMC【疫病名称】 JCJG【检测结果】 TTZL【淘汰种类】（G:个体淘汰;Q:规定疫病种类全群淘汰；C：阳性结果超限淘汰）  \\\n",
       "0        NaN        NaN                                          B   \n",
       "1        NaN        NaN                                          B   \n",
       "2        NaN        NaN                                        NaN   \n",
       "3        NaN        NaN                                        NaN   \n",
       "4        NaN        NaN                                        NaN   \n",
       "\n",
       "   LCID【流程ID】 XB【性别】 PZ【品种】 TZZT【屠宰状态】 ACTIONMC【操作步骤】 CLYY【处理原因】  \n",
       "0     10575.0      雌      牛        NaN           临床检查     临床检查淘汰  \n",
       "1     10575.0      雌      牛        NaN           临床检查     临床检查淘汰  \n",
       "2     10575.0      雌      牛        NaN           临床检查     临床检查淘汰  \n",
       "3     10575.0      雌      牛        NaN           临床检查     临床检查淘汰  \n",
       "4     10575.0      雌      牛        NaN           临床检查     临床检查淘汰  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = all_data1.columns.values.tolist()\n",
    "for i in range(len(columns_name)):\n",
    "    columns_name[i] = columns_name[i].split(\"【\")[0]\n",
    "    columns_name[i] = columns_name[i].split(\" \")[0]\n",
    "all_data1.columns = columns_name\n",
    "all_data2.columns = columns_name\n",
    "all_data3.columns = columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "buffer = []\n",
    "voc_XKZH_1 = all_data1[\"XKZH\"].unique()\n",
    "voc_XKZH_2 = all_data2[\"XKZH\"].unique()\n",
    "voc_XKZH_3 = all_data3[\"XKZH\"].unique()\n",
    "voc_XKZH = np.hstack([voc_XKZH_1, voc_XKZH_2])\n",
    "voc_XKZH = np.hstack([voc_XKZH, voc_XKZH_3])\n",
    "for i in voc_XKZH:\n",
    "    if i == \"\" or i == None or i == \"无\":\n",
    "        continue\n",
    "    i = str(i)\n",
    "    if re.match(\"\\d\", i[0:2]):\n",
    "        continue\n",
    "    else:\n",
    "        buffer.append(i[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'AF']\n"
     ]
    }
   ],
   "source": [
    "buffer = list(set(buffer))\n",
    "print(buffer)\n",
    "data_map.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data1[\"XKZH\"] = all_data1[\"XKZH\"].map(lambda XKZH: buffer.index(str(XKZH)[0:2])+1 if str(XKZH)[0:2] in buffer else 0)\n",
    "all_data2[\"XKZH\"] = all_data2[\"XKZH\"].map(lambda XKZH: buffer.index(str(XKZH)[0:2])+1 if str(XKZH)[0:2] in buffer else 0)\n",
    "all_data3[\"XKZH\"] = all_data3[\"XKZH\"].map(lambda XKZH: buffer.index(str(XKZH)[0:2])+1 if str(XKZH)[0:2] in buffer else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = []\n",
    "voc_DZEH_1 = all_data1[\"DZEH\"].unique()\n",
    "voc_DZEH_2 = all_data2[\"DZEH\"].unique()\n",
    "voc_DZEH_3 = all_data3[\"DZEH\"].unique()\n",
    "voc_DZEH = np.hstack([voc_DZEH_1, voc_DZEH_2])\n",
    "voc_DZEH = np.hstack([voc_DZEH, voc_DZEH_3])\n",
    "for i in voc_DZEH:\n",
    "    if i == \"\" or i == None or i == \"无\":\n",
    "        continue\n",
    "    i = str(i)\n",
    "    if i == \"nan\":\n",
    "        buffer.append(\"nan\")\n",
    "    if re.match(\"\\d\", i[0:2]):\n",
    "        continue\n",
    "    else:\n",
    "        buffer.append(i[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OR', 'K1', 'FR', 'S5', 'QY', 'M4', 'D4', 'DG', 'J9', 'LN', 'P8', 'SS', 'GF', 'H5', 'R4', 'L1', 'J8', 'H8', 'Z0', 'G5', 'E2', 'Z6', 'SV', 'S2', 'SF', 'RT', 'Y5', 'BG', 'Wa', 'Z2', 'X4', 'S6', 'S1', 'L4', 'M1', 'C7', 'C4', 'H7', 'AB', 'H3', 'R7', 'A5', 'R2', 'F4', 'G4', 'BP', 'C8', 'Z3', 'Z5', 'K2', 'FF', 'J2', 'R8', 'P2', 'K5', 'M2', 'WH', 'BE', 'Y8', 'QR', 'K4', 'E3', 'QX', 'C2', 'Y6', 'K7', 'C9', 'A9', 'K3', 'G3', 'DC', '\"W', 'A0', 'P4', 'P7', '\"B', 'J4', 'M3', 'RS', 'P6', 'Y7', 'PU', 'A1', 'A4', 'G7', 'H2', 'H9', 'A6', 'F0', 'D2', 'B7', 'X6', 'WF', 'A8', 'P9', 'GO', 'K9', 'YE', 'M6', 'R6', 'S3', 'K8', 'PM', 'X0', 'B1', 'J7', 'C5', 'B3', 'R3', 'SM', 'B2', 'Y9', 'E6', 'R9', 'M8', 'E1', 'X7', 'R5', 'S9', 'J1', 'E7', 'YN', 'E5', 'G6', 'BL', 'B8', 'Y0', 'F3', 'D0', 'LS', 'Y2', 'D3', 'GR', 'A3', 'S4', 'H6', 'F1', 'D1', 'X1', 'o9', 'P1', 'o ', 'C0', 'o8', 'NO', 'A2', 'X2', 'WT', 'A7', 'SN', 'C6', 'UN', 'PO', 'P3', 'KP', 'S7', 'H0', 'M5', 'QT', 'P5', 'G0', 'LE', 'B5', 'E4', 'G1', 'H1', 'J3', 'H4', 'X3', 'MM', 'C1', 'B4', 'S8', 'X5', 'B9', 'Z1', 'Z4', 'F2', 'CA', 'K6', 'R1', 'B6', 'M7', 'B0', 'PI']\n"
     ]
    }
   ],
   "source": [
    "buffer = list(set(buffer))\n",
    "print(buffer)\n",
    "data_map.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data1[\"DZEH\"] = all_data1[\"DZEH\"].map(lambda DEZH: buffer.index(str(DEZH)[0:2])+1 if str(DEZH)[0:2] in buffer else 0)\n",
    "all_data2[\"DZEH\"] = all_data2[\"DZEH\"].map(lambda DEZH: buffer.index(str(DEZH)[0:2])+1 if str(DEZH)[0:2] in buffer else 0)\n",
    "all_data3[\"DZEH\"] = all_data3[\"DZEH\"].map(lambda DEZH: buffer.index(str(DEZH)[0:2])+1 if str(DEZH)[0:2] in buffer else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = []\n",
    "voc_NCBH_1 = all_data1[\"NCBH\"].unique()\n",
    "voc_NCBH_2 = all_data2[\"NCBH\"].unique()\n",
    "voc_NCBH_3 = all_data3[\"NCBH\"].unique()\n",
    "voc_NCBH = np.hstack([voc_NCBH_1, voc_NCBH_2])\n",
    "voc_NCBH = np.hstack([voc_NCBH, voc_NCBH_3])\n",
    "for i in voc_NCBH:\n",
    "    if i == \"\" or i == None or i == \"无\":\n",
    "        continue\n",
    "    i = str(i)\n",
    "    if i == \"nan\":\n",
    "        buffer.append(\"nan\")\n",
    "    if re.match(\"\\d\", i[0:4]):\n",
    "        continue\n",
    "    else:\n",
    "        buffer.append(i[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EFUY', 'EFUS', 'EFMN', 'nan', 'EFDK', 'EFNL', 'EFNZ', 'EFFR', 'EFAU', 'EFCL', 'EFCA']\n"
     ]
    }
   ],
   "source": [
    "buffer = list(set(buffer))\n",
    "print(buffer)\n",
    "data_map.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data1[\"NCBH\"] = all_data1[\"NCBH\"].map(lambda NCBH: buffer.index(str(NCBH)[0:4])+1 if str(NCBH)[0:4] in buffer else 0)\n",
    "all_data2[\"NCBH\"] = all_data2[\"NCBH\"].map(lambda NCBH: buffer.index(str(NCBH)[0:4])+1 if str(NCBH)[0:4] in buffer else 0)\n",
    "all_data3[\"NCBH\"] = all_data3[\"NCBH\"].map(lambda NCBH: buffer.index(str(NCBH)[0:4])+1 if str(NCBH)[0:4] in buffer else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZEH</th>\n",
       "      <th>XKZH</th>\n",
       "      <th>NCBH</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>LCID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>182188.000000</td>\n",
       "      <td>182188.000000</td>\n",
       "      <td>182188.000000</td>\n",
       "      <td>182188.000000</td>\n",
       "      <td>84527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.684035</td>\n",
       "      <td>1.006471</td>\n",
       "      <td>8.851527</td>\n",
       "      <td>0.270391</td>\n",
       "      <td>17029.651058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55.428563</td>\n",
       "      <td>0.080184</td>\n",
       "      <td>0.801091</td>\n",
       "      <td>0.444163</td>\n",
       "      <td>5796.683695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22053.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24659.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DZEH           XKZH           NCBH         STATUS  \\\n",
       "count  182188.000000  182188.000000  182188.000000  182188.000000   \n",
       "mean       40.684035       1.006471       8.851527       0.270391   \n",
       "std        55.428563       0.080184       0.801091       0.444163   \n",
       "min         0.000000       1.000000       3.000000       0.000000   \n",
       "25%         0.000000       1.000000       9.000000       0.000000   \n",
       "50%         0.000000       1.000000       9.000000       0.000000   \n",
       "75%        88.000000       1.000000       9.000000       1.000000   \n",
       "max       185.000000       2.000000      11.000000       1.000000   \n",
       "\n",
       "               LCID  \n",
       "count  84527.000000  \n",
       "mean   17029.651058  \n",
       "std     5796.683695  \n",
       "min     9202.000000  \n",
       "25%    10162.000000  \n",
       "50%    20117.000000  \n",
       "75%    22053.000000  \n",
       "max    24659.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = []\n",
    "voc_NCBH_1 = all_data1[\"YBMC\"].unique()\n",
    "voc_NCBH_2 = all_data2[\"YBMC\"].unique()\n",
    "voc_NCBH_3 = all_data3[\"YBMC\"].unique()\n",
    "voc_NCBH = np.hstack([voc_NCBH_1, voc_NCBH_2])\n",
    "voc_NCBH = np.hstack([voc_NCBH, voc_NCBH_3])\n",
    "for i in voc_NCBH:\n",
    "    if i == \"\" or i == None or i == \"无\":\n",
    "        continue\n",
    "    i = str(i)\n",
    "    if i == \"nan\":\n",
    "        buffer.append(\"nan\")\n",
    "    else:\n",
    "        i = i.split(\",\")\n",
    "        for text in i:\n",
    "            if text != \"\":\n",
    "                buffer.append(text)\n",
    "buffer = list(set(buffer))\n",
    "buffer[buffer.index(\"nan\")] = buffer[0]\n",
    "buffer[0] = \"nan\"\n",
    "buffer = list(set(buffer))\n",
    "data_map.append(buffer)\n",
    "all_data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['边界病', '猪生殖和呼吸系统综合症', 'nan', '牛传染性鼻气管炎', '布氏杆菌病', '伪狂犬病', '猪传染性胃肠炎', '猪繁殖与呼吸综合症', '鹿流行性出血热', '享德拉病毒', '牛病毒性腹泻', '猪传染性胸膜肺炎', '猪支原体肺炎', '猪繁殖与呼吸道综合征', '副结核病', '马病毒性动脉炎', '衣原体病', '马媾疫', '牛病毒性腹泻\\n', '马鼻腔肺炎', '阳性结果超限淘汰', '赤羽病', '蓝舌病', '猪蓝耳病', '布氏杆菌', '0', '规定疫病种类全群淘汰', '结核病', 'Q热', '马鼻肺炎', '马流感', '牛地方流行性白血病', '马鼻疽']\n",
      "[23.  7. 13.  0.]\n"
     ]
    }
   ],
   "source": [
    "def in2list(text_area, buffer):\n",
    "    text_area = str(text_area)\n",
    "    index_buffer = np.zeros([4,])\n",
    "    if text_area ==\"nan\" or text_area==\"\" or text_area == \"无\":\n",
    "        return index_buffer\n",
    "    for i,var in enumerate(text_area.split(\",\")):\n",
    "        index_buffer[i] = buffer.index(var)+1\n",
    "    return index_buffer\n",
    "a  = \"蓝舌病,猪传染性胃肠炎,猪支原体肺炎\"\n",
    "print(buffer)\n",
    "print(in2list(a, buffer))\n",
    "data_map.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data1[\"YBMC\"] = all_data1[\"YBMC\"].map(lambda YBMC: in2list(YBMC, buffer))\n",
    "all_data2[\"YBMC\"] = all_data2[\"YBMC\"].map(lambda YBMC: in2list(YBMC, buffer))\n",
    "all_data3[\"YBMC\"] = all_data3[\"YBMC\"].map(lambda YBMC: in2list(YBMC, buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_dic = {\n",
    "    \"阳性\":1,\n",
    "    \"阴\":0,\n",
    "}\n",
    "voc = [\"阳性\"]\n",
    "data_map.append(voc)\n",
    "all_data1[\"JCJG\"] = all_data1[\"JCJG\"].map(lambda TTLZ: 1 if TTLZ==\"阳性\" else 0)\n",
    "all_data2[\"JCJG\"] = all_data2[\"JCJG\"].map(lambda TTLZ: 1 if TTLZ==\"阳性\" else 0)\n",
    "all_data3[\"JCJG\"] = all_data3[\"JCJG\"].map(lambda TTLZ: 1 if TTLZ==\"阳性\" else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_dic = [\"G\", \"B\", \"C\", \"Q\"]\n",
    "data_map.append(buffer_dic)\n",
    "all_data1[\"TTZL\"] = all_data1[\"TTZL\"].map(lambda TTLZ: buffer_dic.index(TTLZ) if TTLZ in buffer_dic else 0)\n",
    "all_data2[\"TTZL\"] = all_data2[\"TTZL\"].map(lambda TTLZ: buffer_dic.index(TTLZ) if TTLZ in buffer_dic else 0)\n",
    "all_data3[\"TTZL\"] = all_data3[\"TTZL\"].map(lambda TTLZ: buffer_dic.index(TTLZ) if TTLZ in buffer_dic else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data1.LCID.fillna(0)\n",
    "all_data2.LCID.fillna(0)\n",
    "all_data3.LCID.fillna(0)\n",
    "voc = all_data1.LCID.unique()\n",
    "voc = np.hstack([voc, all_data2.LCID.unique()])\n",
    "voc = np.hstack([voc, all_data3.LCID.unique()])\n",
    "voc = list(set(voc))\n",
    "for i,val in enumerate(voc):\n",
    "    if val == np.nan:\n",
    "        voc[i] = 0\n",
    "voc = np.nan_to_num(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = list(set(voc))\n",
    "voc = list(np.sort(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZEH</th>\n",
       "      <th>XKZH</th>\n",
       "      <th>NCBH</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>YBMC</th>\n",
       "      <th>JCJG</th>\n",
       "      <th>TTZL</th>\n",
       "      <th>LCID</th>\n",
       "      <th>XB</th>\n",
       "      <th>PZ</th>\n",
       "      <th>TZZT</th>\n",
       "      <th>ACTIONMC</th>\n",
       "      <th>CLYY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>雌</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DZEH  XKZH  NCBH  STATUS                  YBMC  JCJG  TTZL  LCID XB PZ  \\\n",
       "0     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93  雌  牛   \n",
       "1     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93  雌  牛   \n",
       "2     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93  雌  牛   \n",
       "3     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93  雌  牛   \n",
       "4     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93  雌  牛   \n",
       "\n",
       "  TZZT ACTIONMC    CLYY  \n",
       "0  NaN     临床检查  临床检查淘汰  \n",
       "1  NaN     临床检查  临床检查淘汰  \n",
       "2  NaN     临床检查  临床检查淘汰  \n",
       "3  NaN     临床检查  临床检查淘汰  \n",
       "4  NaN     临床检查  临床检查淘汰  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data1[\"LCID\"] = all_data1[\"LCID\"].map(lambda LCID: voc.index(LCID) if LCID in voc else 0)\n",
    "all_data2[\"LCID\"] = all_data2[\"LCID\"].map(lambda LCID: voc.index(LCID) if LCID in voc else 0)\n",
    "all_data3[\"LCID\"] = all_data3[\"LCID\"].map(lambda LCID: voc.index(LCID) if LCID in voc else 0)\n",
    "all_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZEH</th>\n",
       "      <th>XKZH</th>\n",
       "      <th>NCBH</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>YBMC</th>\n",
       "      <th>JCJG</th>\n",
       "      <th>TTZL</th>\n",
       "      <th>LCID</th>\n",
       "      <th>XB</th>\n",
       "      <th>PZ</th>\n",
       "      <th>TZZT</th>\n",
       "      <th>ACTIONMC</th>\n",
       "      <th>CLYY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DZEH  XKZH  NCBH  STATUS                  YBMC  JCJG  TTZL  LCID  XB PZ  \\\n",
       "0     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0  牛   \n",
       "1     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0  牛   \n",
       "2     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "3     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "4     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "\n",
       "  TZZT ACTIONMC    CLYY  \n",
       "0  NaN     临床检查  临床检查淘汰  \n",
       "1  NaN     临床检查  临床检查淘汰  \n",
       "2  NaN     临床检查  临床检查淘汰  \n",
       "3  NaN     临床检查  临床检查淘汰  \n",
       "4  NaN     临床检查  临床检查淘汰  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data1.XB.fillna(\"无性\")\n",
    "all_data2.XB.fillna(\"无性\")\n",
    "all_data3.XB.fillna(\"无性\")\n",
    "voc = [\"雌\", \"雄\", \"无性\"]\n",
    "data_map.append(voc)\n",
    "all_data1[\"XB\"] = all_data1[\"XB\"].map(lambda XB: voc.index(XB) if XB in voc else 0)\n",
    "all_data2[\"XB\"] = all_data2[\"XB\"].map(lambda XB: voc.index(XB) if XB in voc else 0)\n",
    "all_data3[\"XB\"] = all_data3[\"XB\"].map(lambda XB: voc.index(XB) if XB in voc else 0)\n",
    "all_data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZEH</th>\n",
       "      <th>XKZH</th>\n",
       "      <th>NCBH</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>YBMC</th>\n",
       "      <th>JCJG</th>\n",
       "      <th>TTZL</th>\n",
       "      <th>LCID</th>\n",
       "      <th>XB</th>\n",
       "      <th>PZ</th>\n",
       "      <th>TZZT</th>\n",
       "      <th>ACTIONMC</th>\n",
       "      <th>CLYY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>临床检查</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DZEH  XKZH  NCBH  STATUS                  YBMC  JCJG  TTZL  LCID  XB PZ  \\\n",
       "0     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0  牛   \n",
       "1     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0  牛   \n",
       "2     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "3     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "4     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "\n",
       "   TZZT ACTIONMC    CLYY  \n",
       "0     0     临床检查  临床检查淘汰  \n",
       "1     0     临床检查  临床检查淘汰  \n",
       "2     0     临床检查  临床检查淘汰  \n",
       "3     0     临床检查  临床检查淘汰  \n",
       "4     0     临床检查  临床检查淘汰  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data1[\"TZZT\"] = all_data1[\"TZZT\"].map(lambda TZZT: 1 if TZZT == \"已屠宰\" else 0)\n",
    "all_data2[\"TZZT\"] = all_data2[\"TZZT\"].map(lambda TZZT: 1 if TZZT == \"已屠宰\" else 0)\n",
    "all_data3[\"TZZT\"] = all_data3[\"TZZT\"].map(lambda TZZT: 1 if TZZT == \"已屠宰\" else 0)\n",
    "all_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = []\n",
    "voc_ACTIONMC_1 = all_data1[\"ACTIONMC\"].unique()\n",
    "voc_ACTIONMC_2 = all_data2[\"ACTIONMC\"].unique()\n",
    "voc_ACTIONMC_3 = all_data3[\"ACTIONMC\"].unique()\n",
    "voc_ACTIONMC = np.hstack([voc_ACTIONMC_1, voc_ACTIONMC_2])\n",
    "voc_ACTIONMC = np.hstack([voc_ACTIONMC, voc_ACTIONMC_3])\n",
    "for i in voc_ACTIONMC:\n",
    "    if i == \"\" or i == None or i == \"无\":\n",
    "        continue\n",
    "    i = str(i)\n",
    "    if i == \"nan\":\n",
    "        buffer.append(\"nan\")\n",
    "    else:\n",
    "        i = i.split(\",\")\n",
    "        for text in i:\n",
    "            if text != \"\":\n",
    "                buffer.append(text)\n",
    "buffer = list(set(buffer))\n",
    "buffer[buffer.index(\"nan\")] = buffer[0]\n",
    "buffer[0] = \"nan\"\n",
    "buffer = list(set(buffer))\n",
    "buffer.pop(buffer.index(\"0\"))\n",
    "_=buffer.pop(buffer.index(\"nan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['进场检疫', '临床检查', '检测结果判定', '农场资质审定', '样品送检', '入境口岸现场检疫', '运输监管', '动物入场', '出口编号', '其他原因淘汰动物', '监督装运']\n"
     ]
    }
   ],
   "source": [
    "print(buffer)\n",
    "data_map.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZEH</th>\n",
       "      <th>XKZH</th>\n",
       "      <th>NCBH</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>YBMC</th>\n",
       "      <th>JCJG</th>\n",
       "      <th>TTZL</th>\n",
       "      <th>LCID</th>\n",
       "      <th>XB</th>\n",
       "      <th>PZ</th>\n",
       "      <th>TZZT</th>\n",
       "      <th>ACTIONMC</th>\n",
       "      <th>CLYY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>牛</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DZEH  XKZH  NCBH  STATUS                  YBMC  JCJG  TTZL  LCID  XB PZ  \\\n",
       "0     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0  牛   \n",
       "1     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0  牛   \n",
       "2     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "3     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "4     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0  牛   \n",
       "\n",
       "   TZZT  ACTIONMC    CLYY  \n",
       "0     0         2  临床检查淘汰  \n",
       "1     0         2  临床检查淘汰  \n",
       "2     0         2  临床检查淘汰  \n",
       "3     0         2  临床检查淘汰  \n",
       "4     0         2  临床检查淘汰  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data1[\"ACTIONMC\"] = all_data1[\"ACTIONMC\"].map(lambda ACTIONMC: buffer.index(ACTIONMC)+1 if ACTIONMC in buffer else 0)\n",
    "all_data2[\"ACTIONMC\"] = all_data2[\"ACTIONMC\"].map(lambda ACTIONMC: buffer.index(ACTIONMC)+1 if ACTIONMC in buffer else 0)\n",
    "all_data3[\"ACTIONMC\"] = all_data3[\"ACTIONMC\"].map(lambda ACTIONMC: buffer.index(ACTIONMC)+1 if ACTIONMC in buffer else 0)\n",
    "all_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = {\"羊\":[0,0, 0],\n",
    "          \"萨福克\":[0, 1, 0],\n",
    "          \"黑萨福克\":[0, 1, 1],\n",
    "          \"白萨福克\":[0, 1, 2],\n",
    "          \"杜泊\":[0, 2, 0],\n",
    "          \"白杜泊\":[0, 2, 1],\n",
    "          \"黑杜泊\":[0, 2, 2],\n",
    "          \"绵羊\":[0, 3, 0],\n",
    "          \"山羊\":[0, 4, 0],\n",
    "          \"猪\":[1, 0, 0],\n",
    "          \"大白种猪\":[1, 1, 0],\n",
    "          \"Yorkshire\":[1, 1, 0],\n",
    "          \"Large White\":[1, 1, 0],\n",
    "          \"LW\":[1, 1, 0],\n",
    "          \"杜洛克\":[1, 2, 0],\n",
    "          \"Duroc\":[1, 2, 0],\n",
    "          \"LR\":[1, 3, 0],\n",
    "          \"皮特兰\":[1, 4, 0],\n",
    "          \"长白猪\":[1, 5, 0],\n",
    "          \"DD猪\":[1, 0, 0],\n",
    "          \"LL猪\":[1, 0, 0],\n",
    "          \"YY猪\":[1,0,0],\n",
    "          \"牛\":[2, 0, 0],\n",
    "          \"即宰牛\":[2,1,0],\n",
    "          \"屠宰牛\":[2, 1, 0],\n",
    "          \"种牛\":[2, 2, 0],\n",
    "          \"荷斯坦\":[2, 3, 0],\n",
    "          \"Holstein\":[2, 4, 0],\n",
    "          \"肉牛\":[2, 5, 0],\n",
    "          \"Fleckvieh\":[2, 6, 0],\n",
    "          \"Friesian\":[2, 7, 0],\n",
    "          \"Hereford\":[2, 8, 0],\n",
    "          \"Jersey\":[2, 9, 0],\n",
    "          \"Simmental\":[2, 10, 0],\n",
    "          \"Wagu\":[2, 11, 0],\n",
    "          \"Samm\":[2, 12, 0],\n",
    "          \"马\":[3, 0, 0],\n",
    "          \"赛马\":[3, 1, 0],\n",
    "          \"蒙古马\":[3, 2, 0],\n",
    "          \"羊驼\":[4, 0, 0],\n",
    "          }\n",
    "data_map.append(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZEH</th>\n",
       "      <th>XKZH</th>\n",
       "      <th>NCBH</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>YBMC</th>\n",
       "      <th>JCJG</th>\n",
       "      <th>TTZL</th>\n",
       "      <th>LCID</th>\n",
       "      <th>XB</th>\n",
       "      <th>PZ</th>\n",
       "      <th>TZZT</th>\n",
       "      <th>ACTIONMC</th>\n",
       "      <th>CLYY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>临床检查淘汰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DZEH  XKZH  NCBH  STATUS                  YBMC  JCJG  TTZL  LCID  XB  \\\n",
       "0     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0   \n",
       "1     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     1    93   0   \n",
       "2     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0   \n",
       "3     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0   \n",
       "4     0     1     9       1  [0.0, 0.0, 0.0, 0.0]     0     0    93   0   \n",
       "\n",
       "          PZ  TZZT  ACTIONMC    CLYY  \n",
       "0  [2, 0, 0]     0         2  临床检查淘汰  \n",
       "1  [2, 0, 0]     0         2  临床检查淘汰  \n",
       "2  [2, 0, 0]     0         2  临床检查淘汰  \n",
       "3  [2, 0, 0]     0         2  临床检查淘汰  \n",
       "4  [2, 0, 0]     0         2  临床检查淘汰  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data1[\"PZ\"] = all_data1[\"PZ\"].map(lambda PZ: buffer[PZ] if PZ in buffer else [0, 0, 0])\n",
    "all_data2[\"PZ\"] = all_data2[\"PZ\"].map(lambda PZ: buffer[PZ] if PZ in buffer else [0, 0, 0])\n",
    "all_data3[\"PZ\"] = all_data3[\"PZ\"].map(lambda PZ: buffer[PZ] if PZ in buffer else [0, 0, 0])\n",
    "all_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = []\n",
    "voc_CLYY_1 = all_data1[\"CLYY\"].unique()\n",
    "voc_CLYY_2 = all_data2[\"CLYY\"].unique()\n",
    "voc_CLYY_3 = all_data3[\"CLYY\"].unique()\n",
    "voc_CLYY = np.hstack([voc_CLYY_1, voc_CLYY_2])\n",
    "voc_CLYY = np.hstack([voc_CLYY, voc_CLYY_3])\n",
    "for i in voc_CLYY:\n",
    "    if i == \"\" or i == None or i == \"无\":\n",
    "        continue\n",
    "    i = str(i)\n",
    "    if i == \"nan\":\n",
    "        buffer.append(\"nan\")\n",
    "    else:\n",
    "        i = i.split(\",\")\n",
    "        for text in i:\n",
    "            if text != \"\":\n",
    "                buffer.append(text)\n",
    "buffer = list(set(buffer))\n",
    "buffer[buffer.index(\"nan\")] = buffer[0]\n",
    "buffer[0] = \"nan\"\n",
    "buffer = list(set(buffer))\n",
    "buffer.pop(buffer.index(\"0\"))\n",
    "_=buffer.pop(buffer.index(\"nan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\jax500\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.592 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['隔离', '消化系统', '死亡', 'TB', '反应', '机械', '进场', '积食', '孕检', '不合格', '赤羽', '抗体', '阳性', '胸膜肺炎', '腿脚', '创伤', '正常', 'PPD', '运输', '眼疾', '结核病', '淘汰', '出口', '外伤', '未卸船', '采血', '应激', '牛', '鼻气管炎', '可疑', '放弃', '临检', '海运', '卧底', '腹膜炎', '腹泻', '粘膜病', 'IBR', '生殖', '缺陷', '未发运', '丢失', '瘤胃臌气', '蓝舌病', '体重', '疝气', '肝脏', '资审', '脱肛', '品种', '酸中毒', '拒绝销售', '检疫', '接卸', '肺脓肿', '骨折', '结核抗体', '蠕虫', '皮肤病', '腿病', '心肌炎', '生殖检查', '呼吸系统疾病', '进口商', '瘸腿', '体弱', '体型小', '蹄病', '直肠检查', '未采血', '不进食', '其他', '卸船', '消瘦', '未下船', '坏死性肺炎', '疥癣', '耳号', '错误', '饲养未满', '6个月']\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "res = \"\"\n",
    "for i in buffer:\n",
    "    res += (i).replace(\"\\n\", \"\")\n",
    "import jieba as jb\n",
    "seg_list = jb.cut(res, cut_all=False)\n",
    "res = \" \".join(jb.cut(res, cut_all=False))\n",
    "res = res.split(\" \")\n",
    "for i, val in enumerate(res):\n",
    "    if re.match(u\"[\\u4e00-\\u9fa5]+\",val):\n",
    "        res[i] = re.match(u\"[\\u4e00-\\u9fa5]+\",val)[0]\n",
    "##去除主语，按照动物+病的模式生成最长字典：同时删除\n",
    "buffer = {\n",
    "'隔离期间消化系统疾病死亡':['隔离', '消化系统', '死亡'],\n",
    "'TB皮内变态反应': ['TB', '反应'],\n",
    " '0': [], \n",
    "'机械性死亡': ['机械', '死亡'], \n",
    "'进场过程中死亡，解剖见瘤胃积食': ['进场', '死亡', '积食'], \n",
    "'孕检不合格': ['孕检', '不合格'],\n",
    "'赤羽病抗体阳性': ['赤羽', '抗体', '阳性'], \n",
    "'传染性胸膜肺炎抗体阳性': ['胸膜肺炎', '抗体', '阳性'],\n",
    "'腿脚伤':['腿脚','创伤'],\n",
    "'正常死亡': ['正常', '死亡'],\n",
    "'PPD': ['PPD'],\n",
    "'汽车运输途中死亡': ['运输', '死亡'],\n",
    "'眼疾': ['眼疾'], \n",
    "'同群结核病全群淘汰': ['结核病', '淘汰'],\n",
    "'出口商淘汰': ['出口', '淘汰'],\n",
    "'外伤严重未卸船': ['外伤', '未卸船'],\n",
    "'在入场后到采血前期间应激死亡': ['进场', '采血', '应激', '死亡'], \n",
    "'外伤': ['外伤'],\n",
    "'牛传染性鼻气管炎可疑': ['牛', '鼻气管炎', '可疑'],\n",
    "'死于创伤意外。': ['创伤', '死亡'], \n",
    "'出现应激反应，双腿无法站立，经随船兽医处理无效，放弃。': ['应激', '腿脚', '放弃'],\n",
    "'临床检查淘汰': ['临检', '淘汰'], \n",
    "'海运途中因体质较弱，卧地不起死亡。': ['海运', '卧底', '死亡'],\n",
    "'运输途中死亡': ['运输', '死亡'], \n",
    "'死于急性腹膜炎。': ['腹膜炎', '死亡'], \n",
    "'病毒性腹泻/粘膜病抗体阳性': ['腹泻', '粘膜病', '阳性'], \n",
    "'IBR检出率大于50%': ['IBR'], \n",
    "'生殖缺陷': ['生殖', '缺陷'], \n",
    "'农场主未发运': ['未发运'],\n",
    "'丢失': ['丢失'], \n",
    "'海运途中因瘤胃臌气死亡。': ['海运', '瘤胃臌气', '死亡'], \n",
    "'兰舌病抗体阳性': ['蓝舌病', '阳性'], \n",
    "'体重不符合装运要求': ['体重', '不合格'], \n",
    "'疝气': ['疝气'], \n",
    "'外伤严重淘汰': ['外伤', '淘汰'], \n",
    "'采血前死亡，解剖见肝脏肿大，有血，脾脏肿大腹围增大': ['采血', '肝脏', '死亡'],\n",
    "'农场资质审定不合格': ['资审', '不合格'], \n",
    "'脱肛': ['脱肛'], \n",
    "'品种问题淘汰': ['品种', '淘汰'], \n",
    "'海运途中因酸中毒死亡。': ['海运', '酸中毒', '死亡'],\n",
    "'原农场主拒绝销售':['拒绝销售'], \n",
    "'隔离检疫死亡': ['检疫', '死亡'], \n",
    "'蓝舌病检测可疑动物个体淘汰。': ['蓝舌病', '可疑', '淘汰'], \n",
    "'nan':[], \n",
    "'接卸期间死亡': ['接卸', '死亡'], \n",
    "'采血前死亡，解剖见肺脓肿，大量血块，粘连': ['采血', '死亡', '肺脓肿'], \n",
    "'海运途中因腿部骨折死亡。':['海运', '腿脚', '骨折', '死亡'], \n",
    "'副结核抗体阳性': ['结核抗体', '阳性'], \n",
    "'蠕虫性皮肤病': ['蠕虫', '皮肤病'], \n",
    "'腿病': ['腿病'], \n",
    "'因心肌炎死亡': ['心肌炎', '死亡'], \n",
    "'隔离场进场前临场及生殖检查淘汰': ['进场', '临检', '生殖检查', '淘汰'],\n",
    "'海运死亡': ['海运', '死亡'], \n",
    "'死于呼吸系统疾病。': ['呼吸系统疾病', '死亡'], \n",
    "'进口商挑选淘汰': ['进口商', '淘汰'], \n",
    "'瘸/跛腿': ['腿脚', '瘸腿'], \n",
    "'体弱，体型过小': ['体弱', '体型小'], \n",
    "'蹄病': ['蹄病'], \n",
    "'直肠检查不合格': ['直肠检查', '不合格'], \n",
    "'蓝舌病可疑，淘汰个体': ['蓝舌病', '可疑', '淘汰'], \n",
    "'未采血': ['未采血'], \n",
    "'瘦弱/不进食': ['体弱', '不进食'], \n",
    "'其他': ['其他'], \n",
    "'卸船过程中肌体严重消瘦、不符合交货条件，未卸离船舶。': ['卸船', '消瘦', '不合格'], \n",
    "'未下船': ['未下船'], \n",
    "'因坏死性肺炎死亡': ['坏死性肺炎', '死亡'], \n",
    "'疥癣': ['疥癣'], \n",
    "'耳号有误': ['耳号', '错误'],\n",
    "'原农场饲养未满6个月': ['饲养未满', '6个月'], \n",
    "'阳性': ['阳性']}\n",
    "rank_buffer = []\n",
    "for key in buffer:\n",
    "    for var in buffer[key]:\n",
    "        if var not in rank_buffer:\n",
    "            rank_buffer.append(var)\n",
    "print(rank_buffer)\n",
    "print(len(rank_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##对此字段集合再次清洗，归并意义词，减少计算量\n",
    "def get_function(in_str):\n",
    "    res = np.zeros([4,])\n",
    "    if in_str in buffer:\n",
    "        in_str = buffer[in_str]\n",
    "        for i,ind in enumerate(in_str):\n",
    "            if ind in rank_buffer:\n",
    "                res[i] = rank_buffer.index(ind)\n",
    "            else:\n",
    "                res[i] = 0\n",
    "        return res\n",
    "    else:\n",
    "        return np.zeros([4,])\n",
    "all_data1[\"CLYY\"] = all_data1[\"CLYY\"].map(lambda CLYY: get_function(CLYY))\n",
    "all_data2[\"CLYY\"] = all_data2[\"CLYY\"].map(lambda CLYY: get_function(CLYY))\n",
    "all_data3[\"CLYY\"] = all_data3[\"CLYY\"].map(lambda CLYY: get_function(CLYY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_data = pd.concat([all_data1, all_data2, all_data3], axis=0)\n",
    "y = all_data.pop(\"STATUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "466377\n"
     ]
    }
   ],
   "source": [
    "#3 8 11\n",
    "input_data_train = []\n",
    "input_data_test = []\n",
    "emd_in_dim = []\n",
    "all_data = all_data.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_data, y, test_size = 0.25,shuffle=True)\n",
    "y_train, y_test = y_train.values, y_test.values\n",
    "L_save = len(x_train)\n",
    "print()\n",
    "print(L_save)\n",
    "for i in range(x_train.shape[1]):\n",
    "    if i not in [3, 8, 11]:\n",
    "        input_data_train.append(x_train[:, i].astype(int))\n",
    "        input_data_test.append(x_test[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 9 array([0., 0., 0., 0.]) 0 0 0 0 list([2, 0, 0]) 0 0\n",
      " array([0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0, :])\n",
    "input3_train = np.zeros([len(x_train),4])\n",
    "input8_train =  np.zeros([len(x_train),3])\n",
    "input11_train =  np.zeros([len(x_train),4])\n",
    "for i in range(len(x_train)):\n",
    "    input3_train[i,:] = x_train[i, 3].reshape([4,])\n",
    "for i in range(len(x_train)):\n",
    "    input8_train[i,:] = np.asarray(x_train[i, 8]).reshape([3,])\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    input11_train[i,:] = x_train[i, 11].reshape([4,])\n",
    "\n",
    "input3_test = np.zeros([len(x_test),4])\n",
    "input8_test =  np.zeros([len(x_test),3])\n",
    "input11_test =  np.zeros([len(x_test),4])\n",
    "for i in range(len(x_test)):\n",
    "    input3_test[i,:] = x_test[i, 3]\n",
    "for i in range(len(x_test)):\n",
    "    input8_test[i,:] = np.asarray(x_test[i, 8]).reshape([3,])\n",
    "for i in range(len(x_test)):\n",
    "    input11_test[i,:] = x_test[i, 11].reshape([4,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_train.append(input3_train)\n",
    "input_data_train.append(input8_train)\n",
    "input_data_train.append(input11_train)\n",
    "input_data_test.append(input3_test)\n",
    "input_data_test.append(input8_test)\n",
    "input_data_test.append(input11_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_next = np.zeros([y_train.shape[0], 2])\n",
    "y_test_next = np.zeros([y_test.shape[0], 2])\n",
    "for i in range(y_train.shape[0]):\n",
    "    if i<y_test.shape[0]:\n",
    "        if y_test[i] ==0:\n",
    "            y_test_next[i, :] = [1, 0]\n",
    "        else:\n",
    "            y_test_next[i, :] = [0, 1]\n",
    "    if y_train[i] ==0:\n",
    "        y_train_next[i, :] = [1, 0]\n",
    "    else:\n",
    "        y_train_next[i, :] = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_sz_in = []\n",
    "for i in range(len(input_data_train)):\n",
    "    input_data_train[i] = input_data_train[i].astype(int)\n",
    "    voc_sz_in.append(np.max(input_data_train[i]))\n",
    "for i in range(len(input_data_test)):\n",
    "    input_data_test[i] = input_data_test[i].astype(int)\n",
    "    voc_sz_in[i] =  int(max(np.max(input_data_train[i]), voc_sz_in[i]))+100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jax500\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 10)\n",
      "(?, 90)\n",
      "(?, 30)\n",
      "(?, 120)\n",
      "WARNING:tensorflow:From <ipython-input-37-21eae125e477>:48: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jax500\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "lr = 0.01\n",
    "class Embedding():\n",
    "    def __init__(self, vocab_sz, emd_dim=50):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.emd_dim = emd_dim\n",
    "        self.embeddings = tf.Variable(tf.random_uniform([self.vocab_sz, self.emd_dim]), dtype=tf.float32)\n",
    "\n",
    "    def __call__(self, words_ids):\n",
    "        return tf.nn.embedding_lookup(self.embeddings, words_ids, name=\"Embedding_layers\")\n",
    "\n",
    "input1 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input2 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input3 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input4 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input5 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input6 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input7 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input8 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input9 = tf.placeholder(shape=[None, 1], dtype=tf.int32)\n",
    "input_layers_1 = [input1, input2, input3, input4, input5, input6, input7, input8, input9]\n",
    "input10 = tf.placeholder(shape=[None, 4, 1], dtype=tf.int32)\n",
    "input11 = tf.placeholder(shape=[None, 3, 1], dtype=tf.int32)\n",
    "input12 = tf.placeholder(shape=[None, 4, 1], dtype=tf.int32)\n",
    "input_layers_2 = [input10, input11, input12]\n",
    "\n",
    "for i in range(9):\n",
    "    name_buffer = \"emd{}\".format(i+1)\n",
    "    input_layers_1[i] = tf.squeeze(Embedding(vocab_sz = voc_sz_in[i], emd_dim=10)(input_layers_1[i]), axis=1, name=name_buffer)\n",
    "    print((input_layers_1[i]).shape)\n",
    "for i in range(len(input_layers_2)):\n",
    "    idx = i+9\n",
    "    input_layers_2[i] = tf.expand_dims(tf.squeeze(Embedding(vocab_sz=voc_sz_in[i], emd_dim=10)(input_layers_2[i]), axis=2), axis=-1)\n",
    "    input_layers_2[i] = tf.squeeze(tf.layers.Conv2D(filters=1, kernel_size=[input_layers_2[i].shape[1], 1], strides=1, padding=\"valid\", data_format=\"channels_last\")(input_layers_2[i]), axis=[1, -1])\n",
    "    print(input_layers_2[i].shape)\n",
    "\n",
    "input_layers_1 = tf.concat(input_layers_1, axis=-1)\n",
    "input_layers_2 = tf.concat(input_layers_2, axis=-1)\n",
    "print(input_layers_1.shape)\n",
    "print(input_layers_2.shape)\n",
    "main_input = tf.concat([input_layers_1, input_layers_2], axis=-1)\n",
    "print(main_input.shape)  ##for dense classify\n",
    "main_input = tf.layers.Dense(units=256, activation=\"relu\",kernel_initializer=tf.random_uniform_initializer, bias_initializer=tf.constant_initializer(value=0.1))(main_input)\n",
    "main_input = tf.layers.Dense(units=128, activation=\"relu\",kernel_initializer=tf.random_uniform_initializer, bias_initializer=tf.constant_initializer(value=0.1))(main_input)\n",
    "logits = tf.layers.Dense(units=2, use_bias=True, kernel_initializer=tf.random_uniform_initializer, bias_initializer=tf.constant_initializer(value=0.1))(main_input)\n",
    "y_ = tf.placeholder(shape=[None, 2], dtype=tf.int32)\n",
    "y = tf.nn.softmax(logits)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "## create diffrent voc for each columns because the voc[0, 0] !=0 sothat the nan value will still into the caculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 64\n",
    "class next_batch(object):\n",
    "    def __init__(self,x_train, y_train, batch_sz=1000):\n",
    "         \n",
    "            self.x_train = x_train\n",
    "            self.y_train = y_train\n",
    "            self.all_data = self.get_next_batch_(x_train, y_train)\n",
    "            self.data_L = max(y_train.shape[0], y_train.shape[1])\n",
    "            self.Iter = 0\n",
    "            self.epo = 0\n",
    "            self.batch_sz = batch_sz\n",
    "    def get_dic(self, x_p,labels):\n",
    "        ini_dic = {}\n",
    "        exec_str = \"ini_dic.update({\"\n",
    "        for i in range(12):\n",
    "            exec_str+=\"input{}:x_p[{}],\".format(i+1, i)\n",
    "        exec_str+=\"})\"\n",
    "        #print(exec_str)\n",
    "        ini_dic.update({y_:labels})\n",
    "        exec(exec_str)\n",
    "\n",
    "        return ini_dic\n",
    "\n",
    "    def get_next_batch_(self, x_train, y_train):\n",
    "        for i in range(int(len(x_train[0])/batch_sz)):\n",
    "            res = []\n",
    "            for j in range(12):\n",
    "                if j<9:\n",
    "                    res.append((x_train[j][i*batch_sz:(i+1)*batch_sz, :]).astype(int))\n",
    "                else:\n",
    "                    res.append((x_train[j][i*batch_sz:(i+1)*batch_sz, :, :]).astype(int))\n",
    "\n",
    "            yield res,y_train[i*batch_sz:(i+1)*batch_sz]\n",
    "    def get_dic_data(self):\n",
    "        try:\n",
    "            buffer = self.all_data.__next__()\n",
    "        except StopIteration:\n",
    "            self.epo+=1\n",
    "            self.Iter = 0\n",
    "            self.all_data = self.get_next_batch_(self.x_train, self.y_train)\n",
    "            buffer = self.all_data.__next__()\n",
    "        self.Iter+=self.batch_sz\n",
    "        return self.get_dic(buffer[0], buffer[1])\n",
    "    @staticmethod\n",
    "    def mask_input(idx, x_list):\n",
    "        if isinstance(idx, list):\n",
    "            for i in idx:\n",
    "                x_list[i] = np.zeros(x_list[i].shape)\n",
    "        else:\n",
    "            x_list[idx] = np.zeros(x_list[idx].shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 1)\n",
      "(466377, 4, 1)\n",
      "(466377, 3, 1)\n",
      "(466377, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_data_train)):\n",
    "    input_data_train[i] = input_data_train[i].squeeze()\n",
    "    input_data_train[i] = np.expand_dims(input_data_train[i], axis=-1)\n",
    "    print(input_data_train[i].shape)\n",
    "for i in range(len(input_data_test)):\n",
    "    input_data_test[i] = np.expand_dims(input_data_test[i], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 traning the loss is 8599.123046875\n",
      "after 1 traning the loss is 731.769287109375\n",
      "after 2 traning the loss is 4389.7841796875\n",
      "after 3 traning the loss is 6060.8310546875\n",
      "after 4 traning the loss is 4571.6259765625\n",
      "after 5 traning the loss is 6544.62890625\n",
      "after 6 traning the loss is 5980.5888671875\n",
      "after 7 traning the loss is 4674.0146484375\n",
      "after 8 traning the loss is 3406.067626953125\n",
      "after 9 traning the loss is 1167.138916015625\n",
      "after 10 traning the loss is 92.846923828125\n",
      "after 11 traning the loss is 2267.5029296875\n",
      "after 12 traning the loss is 3734.102783203125\n",
      "after 13 traning the loss is 3110.62353515625\n",
      "after 14 traning the loss is 3540.6982421875\n",
      "after 15 traning the loss is 2295.860595703125\n",
      "after 16 traning the loss is 1329.2193603515625\n",
      "after 17 traning the loss is 194.34765625\n",
      "after 18 traning the loss is 449.1300048828125\n",
      "after 19 traning the loss is 532.69482421875\n",
      "after 20 traning the loss is 1233.827392578125\n",
      "after 21 traning the loss is 1161.7554931640625\n",
      "after 22 traning the loss is 1594.675048828125\n",
      "after 23 traning the loss is 1157.673828125\n",
      "after 24 traning the loss is 701.1370849609375\n",
      "after 25 traning the loss is 886.4964599609375\n",
      "after 26 traning the loss is 690.1917114257812\n",
      "after 27 traning the loss is 547.365966796875\n",
      "after 28 traning the loss is 571.6160888671875\n",
      "after 29 traning the loss is 326.0673828125\n",
      "after 30 traning the loss is 217.29656982421875\n",
      "after 31 traning the loss is 98.11679077148438\n",
      "after 32 traning the loss is 62.22354507446289\n",
      "after 33 traning the loss is 14.89711856842041\n",
      "after 34 traning the loss is 4.565491676330566\n",
      "after 35 traning the loss is 7.471119403839111\n",
      "after 36 traning the loss is 6.572825908660889\n",
      "after 37 traning the loss is 4.375768184661865\n",
      "after 38 traning the loss is 2.490377426147461\n",
      "after 39 traning the loss is 1.6787631511688232\n",
      "after 40 traning the loss is 1.7228477001190186\n",
      "after 41 traning the loss is 0.7004472017288208\n",
      "after 42 traning the loss is 0.909087061882019\n",
      "after 43 traning the loss is 0.7307410836219788\n",
      "after 44 traning the loss is 0.754371702671051\n",
      "after 45 traning the loss is 0.6633867025375366\n",
      "after 46 traning the loss is 0.6401289701461792\n",
      "after 47 traning the loss is 0.6169052124023438\n",
      "after 48 traning the loss is 0.6193424463272095\n",
      "after 49 traning the loss is 0.5262423753738403\n",
      "after 50 traning the loss is 0.6460993885993958\n",
      "after 51 traning the loss is 0.6253973245620728\n",
      "after 52 traning the loss is 0.703475296497345\n",
      "after 53 traning the loss is 0.6386097073554993\n",
      "after 54 traning the loss is 0.6363992691040039\n",
      "after 55 traning the loss is 0.6478772759437561\n",
      "after 56 traning the loss is 0.6923544406890869\n",
      "after 57 traning the loss is 0.7742165923118591\n",
      "after 58 traning the loss is 0.6221773624420166\n",
      "after 59 traning the loss is 0.7820162773132324\n",
      "after 60 traning the loss is 0.7632068991661072\n",
      "after 61 traning the loss is 0.7913995981216431\n",
      "after 62 traning the loss is 0.5762895941734314\n",
      "after 63 traning the loss is 0.5074812173843384\n",
      "after 64 traning the loss is 0.674621045589447\n",
      "after 65 traning the loss is 0.6193533539772034\n",
      "after 66 traning the loss is 0.6454508304595947\n",
      "after 67 traning the loss is 0.681330680847168\n",
      "after 68 traning the loss is 0.6211768388748169\n",
      "after 69 traning the loss is 0.6343197822570801\n",
      "after 70 traning the loss is 0.696220338344574\n",
      "after 71 traning the loss is 0.6438688635826111\n",
      "after 72 traning the loss is 0.6049576997756958\n",
      "after 73 traning the loss is 0.6301397085189819\n",
      "after 74 traning the loss is 0.6242409944534302\n",
      "after 75 traning the loss is 0.6258598566055298\n",
      "after 76 traning the loss is 0.6042128801345825\n",
      "after 77 traning the loss is 0.6465521454811096\n",
      "after 78 traning the loss is 0.619646430015564\n",
      "after 79 traning the loss is 0.650489091873169\n",
      "after 80 traning the loss is 0.6708287596702576\n",
      "after 81 traning the loss is 0.6511663198471069\n",
      "after 82 traning the loss is 0.6306585073471069\n",
      "after 83 traning the loss is 0.6185847520828247\n",
      "after 84 traning the loss is 0.6233037710189819\n",
      "after 85 traning the loss is 0.5602493286132812\n",
      "after 86 traning the loss is 0.5949124097824097\n",
      "after 87 traning the loss is 0.6381343007087708\n",
      "after 88 traning the loss is 0.6363334655761719\n",
      "after 89 traning the loss is 0.5451004505157471\n",
      "after 90 traning the loss is 0.6214777231216431\n",
      "after 91 traning the loss is 0.7281616926193237\n",
      "after 92 traning the loss is 0.530439019203186\n",
      "after 93 traning the loss is 0.623103678226471\n",
      "after 94 traning the loss is 0.618962824344635\n",
      "after 95 traning the loss is 0.6518261432647705\n",
      "after 96 traning the loss is 0.7233930230140686\n",
      "after 97 traning the loss is 0.6222938299179077\n",
      "after 98 traning the loss is 0.6174871325492859\n",
      "after 99 traning the loss is 0.5950247049331665\n",
      "after 100 traning the loss is 0.671189546585083\n",
      "after 101 traning the loss is 0.583803653717041\n",
      "after 102 traning the loss is 0.6585785150527954\n",
      "after 103 traning the loss is 0.6447161436080933\n",
      "after 104 traning the loss is 0.5648304224014282\n",
      "after 105 traning the loss is 0.6440359354019165\n",
      "after 106 traning the loss is 0.6306393146514893\n",
      "after 107 traning the loss is 0.6731575131416321\n",
      "after 108 traning the loss is 0.5905149579048157\n",
      "after 109 traning the loss is 0.6647276878356934\n",
      "after 110 traning the loss is 0.6212590932846069\n",
      "after 111 traning the loss is 0.5715422630310059\n",
      "after 112 traning the loss is 0.6039328575134277\n",
      "after 113 traning the loss is 0.654511570930481\n",
      "after 114 traning the loss is 0.665878415107727\n",
      "after 115 traning the loss is 0.6882631182670593\n",
      "after 116 traning the loss is 0.6725380420684814\n",
      "after 117 traning the loss is 0.5595528483390808\n",
      "after 118 traning the loss is 0.6207402348518372\n",
      "after 119 traning the loss is 0.6545286178588867\n",
      "after 120 traning the loss is 0.6329085826873779\n",
      "after 121 traning the loss is 0.6437397003173828\n",
      "after 122 traning the loss is 0.6901030540466309\n",
      "after 123 traning the loss is 0.6858967542648315\n",
      "after 124 traning the loss is 0.72480309009552\n",
      "after 125 traning the loss is 0.7058226466178894\n",
      "after 126 traning the loss is 0.6056381464004517\n",
      "after 127 traning the loss is 0.6377191543579102\n",
      "after 128 traning the loss is 0.671612560749054\n",
      "after 129 traning the loss is 0.6336598992347717\n",
      "after 130 traning the loss is 0.6644068956375122\n",
      "after 131 traning the loss is 0.5774420499801636\n",
      "after 132 traning the loss is 0.6294741630554199\n",
      "after 133 traning the loss is 0.646779477596283\n",
      "after 134 traning the loss is 0.6330841779708862\n",
      "after 135 traning the loss is 0.6445945501327515\n",
      "after 136 traning the loss is 0.6395159959793091\n",
      "after 137 traning the loss is 0.7116352319717407\n",
      "after 138 traning the loss is 0.5591223239898682\n",
      "after 139 traning the loss is 0.6645469069480896\n",
      "after 140 traning the loss is 0.7177942991256714\n",
      "after 141 traning the loss is 0.6625989675521851\n",
      "after 142 traning the loss is 0.6224306225776672\n",
      "after 143 traning the loss is 0.680438220500946\n",
      "after 144 traning the loss is 0.6287893056869507\n",
      "after 145 traning the loss is 0.604205846786499\n",
      "after 146 traning the loss is 0.5605028867721558\n",
      "after 147 traning the loss is 0.5829670429229736\n",
      "after 148 traning the loss is 0.553499698638916\n",
      "after 149 traning the loss is 0.6443313956260681\n",
      "after 150 traning the loss is 0.5603786110877991\n",
      "after 151 traning the loss is 0.603456974029541\n",
      "after 152 traning the loss is 0.6178876757621765\n",
      "after 153 traning the loss is 0.5613323450088501\n",
      "after 154 traning the loss is 0.7108817100524902\n",
      "after 155 traning the loss is 0.5477422475814819\n",
      "after 156 traning the loss is 0.6100233793258667\n",
      "after 157 traning the loss is 0.7519327402114868\n",
      "after 158 traning the loss is 0.7174462080001831\n",
      "after 159 traning the loss is 0.6234866976737976\n",
      "after 160 traning the loss is 0.6985650062561035\n",
      "after 161 traning the loss is 0.5774717330932617\n",
      "after 162 traning the loss is 0.6829379796981812\n",
      "after 163 traning the loss is 0.6395878195762634\n",
      "after 164 traning the loss is 0.6436315774917603\n",
      "after 165 traning the loss is 0.6336562633514404\n",
      "after 166 traning the loss is 0.6254584789276123\n",
      "after 167 traning the loss is 0.6301137208938599\n",
      "after 168 traning the loss is 0.6363811492919922\n",
      "after 169 traning the loss is 0.639147937297821\n",
      "after 170 traning the loss is 0.6150256395339966\n",
      "after 171 traning the loss is 0.6699440479278564\n",
      "after 172 traning the loss is 0.6140628457069397\n",
      "after 173 traning the loss is 0.59249347448349\n",
      "after 174 traning the loss is 0.6253007650375366\n",
      "after 175 traning the loss is 0.5930098295211792\n",
      "after 176 traning the loss is 0.665478527545929\n",
      "after 177 traning the loss is 0.593961238861084\n",
      "after 178 traning the loss is 0.6816942691802979\n",
      "after 179 traning the loss is 0.6817016005516052\n",
      "after 180 traning the loss is 0.5360698699951172\n",
      "after 181 traning the loss is 0.6085801720619202\n",
      "after 182 traning the loss is 0.672863245010376\n",
      "after 183 traning the loss is 0.5992063283920288\n",
      "after 184 traning the loss is 0.6476370096206665\n",
      "after 185 traning the loss is 0.5811775922775269\n",
      "after 186 traning the loss is 0.6870905756950378\n",
      "after 187 traning the loss is 0.6728395223617554\n",
      "after 188 traning the loss is 0.621094822883606\n",
      "after 189 traning the loss is 0.5919992923736572\n",
      "after 190 traning the loss is 0.6514718532562256\n",
      "after 191 traning the loss is 0.6162609457969666\n",
      "after 192 traning the loss is 0.534049928188324\n",
      "after 193 traning the loss is 0.5553961992263794\n",
      "after 194 traning the loss is 0.6675710082054138\n",
      "after 195 traning the loss is 0.6074212789535522\n",
      "after 196 traning the loss is 0.621114194393158\n",
      "after 197 traning the loss is 0.5743441581726074\n",
      "after 198 traning the loss is 0.5780617594718933\n",
      "after 199 traning the loss is 0.6699854731559753\n",
      "after 200 traning the loss is 0.6486750245094299\n",
      "after 201 traning the loss is 0.6081936955451965\n",
      "after 202 traning the loss is 0.6892515420913696\n",
      "after 203 traning the loss is 0.5638055801391602\n",
      "after 204 traning the loss is 0.5905046463012695\n",
      "after 205 traning the loss is 0.6213033199310303\n",
      "after 206 traning the loss is 0.5805046558380127\n",
      "after 207 traning the loss is 0.7121742963790894\n",
      "after 208 traning the loss is 0.5987821221351624\n",
      "after 209 traning the loss is 0.7023396492004395\n",
      "after 210 traning the loss is 0.6511456370353699\n",
      "after 211 traning the loss is 0.6655480861663818\n",
      "after 212 traning the loss is 0.5877149105072021\n",
      "after 213 traning the loss is 0.6148625612258911\n",
      "after 214 traning the loss is 0.6717722415924072\n",
      "after 215 traning the loss is 0.6710340976715088\n",
      "after 216 traning the loss is 0.6531597971916199\n",
      "after 217 traning the loss is 0.5794564485549927\n",
      "after 218 traning the loss is 0.7206234931945801\n",
      "after 219 traning the loss is 0.6615883708000183\n",
      "after 220 traning the loss is 0.5753966569900513\n",
      "after 221 traning the loss is 0.6983667612075806\n",
      "after 222 traning the loss is 0.629700779914856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 223 traning the loss is 0.6440260410308838\n",
      "after 224 traning the loss is 0.6395308971405029\n",
      "after 225 traning the loss is 0.6524896621704102\n",
      "after 226 traning the loss is 0.6416971683502197\n",
      "after 227 traning the loss is 0.6330384016036987\n",
      "after 228 traning the loss is 0.636379063129425\n",
      "after 229 traning the loss is 0.6446983218193054\n",
      "after 230 traning the loss is 0.7084033489227295\n",
      "after 231 traning the loss is 0.6597685217857361\n",
      "after 232 traning the loss is 0.6533160209655762\n",
      "after 233 traning the loss is 0.6042196154594421\n",
      "after 234 traning the loss is 0.6531599760055542\n",
      "after 235 traning the loss is 0.6627510190010071\n",
      "after 236 traning the loss is 0.6241278648376465\n",
      "after 237 traning the loss is 0.6439182162284851\n",
      "after 238 traning the loss is 0.6983139514923096\n",
      "after 239 traning the loss is 0.6338988542556763\n",
      "after 240 traning the loss is 0.6532507538795471\n",
      "after 241 traning the loss is 0.6697498559951782\n",
      "after 242 traning the loss is 0.6164916753768921\n",
      "after 243 traning the loss is 0.6355692148208618\n",
      "after 244 traning the loss is 0.6615656018257141\n",
      "after 245 traning the loss is 0.6615778207778931\n",
      "after 246 traning the loss is 0.6477333307266235\n",
      "after 247 traning the loss is 0.6282520890235901\n",
      "after 248 traning the loss is 0.6790739297866821\n",
      "after 249 traning the loss is 0.6794033050537109\n",
      "after 250 traning the loss is 0.6602764129638672\n",
      "after 251 traning the loss is 0.65129554271698\n",
      "after 252 traning the loss is 0.6563350558280945\n",
      "after 253 traning the loss is 0.5951554775238037\n",
      "after 254 traning the loss is 0.6273460388183594\n",
      "after 255 traning the loss is 0.5930396318435669\n",
      "after 256 traning the loss is 0.6580029726028442\n",
      "after 257 traning the loss is 0.6488513946533203\n",
      "after 258 traning the loss is 0.6653151512145996\n",
      "after 259 traning the loss is 0.5997945070266724\n",
      "after 260 traning the loss is 0.5824061036109924\n",
      "after 261 traning the loss is 0.6570477485656738\n",
      "after 262 traning the loss is 0.5623810291290283\n",
      "after 263 traning the loss is 0.6340405344963074\n",
      "after 264 traning the loss is 0.594999372959137\n",
      "after 265 traning the loss is 0.5945650339126587\n",
      "after 266 traning the loss is 0.5592638850212097\n",
      "after 267 traning the loss is 0.6333675384521484\n",
      "after 268 traning the loss is 0.608964204788208\n",
      "after 269 traning the loss is 0.6199219226837158\n",
      "after 270 traning the loss is 0.609154462814331\n",
      "after 271 traning the loss is 0.5556594729423523\n",
      "after 272 traning the loss is 0.5494269132614136\n",
      "after 273 traning the loss is 0.7255957722663879\n",
      "after 274 traning the loss is 0.6189433336257935\n",
      "after 275 traning the loss is 0.6225261688232422\n",
      "after 276 traning the loss is 0.608197808265686\n",
      "after 277 traning the loss is 0.6735693216323853\n",
      "after 278 traning the loss is 0.5964671969413757\n",
      "after 279 traning the loss is 0.6447390913963318\n",
      "after 280 traning the loss is 0.616203784942627\n",
      "after 281 traning the loss is 0.6115586757659912\n",
      "after 282 traning the loss is 0.7258701920509338\n",
      "after 283 traning the loss is 0.6248080730438232\n",
      "after 284 traning the loss is 0.6321057677268982\n",
      "after 285 traning the loss is 0.628311276435852\n",
      "after 286 traning the loss is 0.6777631044387817\n",
      "after 287 traning the loss is 0.6150475144386292\n",
      "after 288 traning the loss is 0.6003274321556091\n",
      "after 289 traning the loss is 0.5909286737442017\n",
      "after 290 traning the loss is 0.671423077583313\n",
      "after 291 traning the loss is 0.5161987543106079\n",
      "after 292 traning the loss is 0.5321604609489441\n",
      "after 293 traning the loss is 0.6473101377487183\n",
      "after 294 traning the loss is 0.6955457925796509\n",
      "after 295 traning the loss is 0.7328085899353027\n",
      "after 296 traning the loss is 0.6056294441223145\n",
      "after 297 traning the loss is 0.610169529914856\n",
      "after 298 traning the loss is 0.6567940711975098\n",
      "after 299 traning the loss is 0.5942588448524475\n",
      "after 300 traning the loss is 0.5594757199287415\n",
      "after 301 traning the loss is 0.5884394645690918\n",
      "after 302 traning the loss is 0.7519975304603577\n",
      "after 303 traning the loss is 0.5714409947395325\n",
      "after 304 traning the loss is 0.6466727256774902\n",
      "after 305 traning the loss is 0.6527942419052124\n",
      "after 306 traning the loss is 0.5399811863899231\n",
      "after 307 traning the loss is 0.5853533148765564\n",
      "after 308 traning the loss is 0.6272873878479004\n",
      "after 309 traning the loss is 0.64805668592453\n",
      "after 310 traning the loss is 0.6332720518112183\n",
      "after 311 traning the loss is 0.6477282643318176\n",
      "after 312 traning the loss is 0.6575219035148621\n",
      "after 313 traning the loss is 0.614427924156189\n",
      "after 314 traning the loss is 0.6627038717269897\n",
      "after 315 traning the loss is 0.6627974510192871\n",
      "after 316 traning the loss is 0.5812370777130127\n",
      "after 317 traning the loss is 0.6242243647575378\n",
      "after 318 traning the loss is 0.6837551593780518\n",
      "after 319 traning the loss is 0.7597012519836426\n",
      "after 320 traning the loss is 0.6375933885574341\n",
      "after 321 traning the loss is 0.6771237850189209\n",
      "after 322 traning the loss is 0.5871401429176331\n",
      "after 323 traning the loss is 0.6948404908180237\n",
      "after 324 traning the loss is 0.6347091794013977\n",
      "after 325 traning the loss is 0.6440407633781433\n",
      "after 326 traning the loss is 0.6262474060058594\n",
      "after 327 traning the loss is 0.5927656292915344\n",
      "after 328 traning the loss is 0.7010518312454224\n",
      "after 329 traning the loss is 0.6435853242874146\n",
      "after 330 traning the loss is 0.6337915658950806\n",
      "after 331 traning the loss is 0.6435045003890991\n",
      "after 332 traning the loss is 0.6075413823127747\n",
      "after 333 traning the loss is 0.6226504445075989\n",
      "after 334 traning the loss is 0.600294828414917\n",
      "after 335 traning the loss is 0.5870136022567749\n",
      "after 336 traning the loss is 0.7314226627349854\n",
      "after 337 traning the loss is 0.6902177333831787\n",
      "after 338 traning the loss is 0.6402125358581543\n",
      "after 339 traning the loss is 0.7025943994522095\n",
      "after 340 traning the loss is 0.6868776082992554\n",
      "after 341 traning the loss is 0.6046004891395569\n",
      "after 342 traning the loss is 0.6574342250823975\n",
      "after 343 traning the loss is 0.6280244588851929\n",
      "after 344 traning the loss is 0.6615649461746216\n",
      "after 345 traning the loss is 0.5859812498092651\n",
      "after 346 traning the loss is 0.6615639925003052\n",
      "after 347 traning the loss is 0.6616117358207703\n",
      "after 348 traning the loss is 0.6105248332023621\n",
      "after 349 traning the loss is 0.5865906476974487\n",
      "after 350 traning the loss is 0.6407245397567749\n",
      "after 351 traning the loss is 0.6707584261894226\n",
      "after 352 traning the loss is 0.6916741132736206\n",
      "after 353 traning the loss is 0.6328573226928711\n",
      "after 354 traning the loss is 0.6223241090774536\n",
      "after 355 traning the loss is 0.5481163263320923\n",
      "after 356 traning the loss is 0.6212078928947449\n",
      "after 357 traning the loss is 0.677035927772522\n",
      "after 358 traning the loss is 0.6569333076477051\n",
      "after 359 traning the loss is 0.6232138872146606\n",
      "after 360 traning the loss is 0.6346244215965271\n",
      "after 361 traning the loss is 0.6899222135543823\n",
      "after 362 traning the loss is 0.6063401699066162\n",
      "after 363 traning the loss is 0.6630083918571472\n",
      "after 364 traning the loss is 0.6722601652145386\n",
      "after 365 traning the loss is 0.6848031282424927\n",
      "after 366 traning the loss is 0.6015894412994385\n",
      "after 367 traning the loss is 0.661820113658905\n",
      "after 368 traning the loss is 0.5868538618087769\n",
      "after 369 traning the loss is 0.647330641746521\n",
      "after 370 traning the loss is 0.578485369682312\n",
      "after 371 traning the loss is 0.6201671361923218\n",
      "after 372 traning the loss is 0.6624535322189331\n",
      "after 373 traning the loss is 0.6173177361488342\n",
      "after 374 traning the loss is 0.6446861028671265\n",
      "after 375 traning the loss is 0.6334359645843506\n",
      "after 376 traning the loss is 0.6424051523208618\n",
      "after 377 traning the loss is 0.5299045443534851\n",
      "after 378 traning the loss is 0.7110015153884888\n",
      "after 379 traning the loss is 0.6495345830917358\n",
      "after 380 traning the loss is 0.6494290828704834\n",
      "after 381 traning the loss is 0.6571993231773376\n",
      "after 382 traning the loss is 0.538580060005188\n",
      "after 383 traning the loss is 0.6190669536590576\n",
      "after 384 traning the loss is 0.6211077570915222\n",
      "after 385 traning the loss is 0.6280922889709473\n",
      "after 386 traning the loss is 0.5852324962615967\n",
      "after 387 traning the loss is 0.6474834680557251\n",
      "after 388 traning the loss is 0.7029608488082886\n",
      "after 389 traning the loss is 0.6380095481872559\n",
      "after 390 traning the loss is 0.6338208913803101\n",
      "after 391 traning the loss is 0.6169135570526123\n",
      "after 392 traning the loss is 0.6416340470314026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 393 traning the loss is 0.63181471824646\n",
      "after 394 traning the loss is 0.6281403303146362\n",
      "after 395 traning the loss is 0.6352218389511108\n",
      "after 396 traning the loss is 0.6272618770599365\n",
      "after 397 traning the loss is 0.6620182394981384\n",
      "after 398 traning the loss is 0.6714488863945007\n",
      "after 399 traning the loss is 0.6715598106384277\n",
      "after 400 traning the loss is 0.5891867280006409\n",
      "after 401 traning the loss is 0.549309253692627\n",
      "after 402 traning the loss is 0.6948602795600891\n",
      "after 403 traning the loss is 0.6164624691009521\n",
      "after 404 traning the loss is 0.6551530361175537\n",
      "after 405 traning the loss is 0.5594997406005859\n",
      "after 406 traning the loss is 0.6448284387588501\n",
      "after 407 traning the loss is 0.6035244464874268\n",
      "after 408 traning the loss is 0.608630359172821\n",
      "after 409 traning the loss is 0.5902549028396606\n",
      "after 410 traning the loss is 0.6347529888153076\n",
      "after 411 traning the loss is 0.5811465978622437\n",
      "after 412 traning the loss is 0.630431056022644\n",
      "after 413 traning the loss is 0.6824928522109985\n",
      "after 414 traning the loss is 0.5625053644180298\n",
      "after 415 traning the loss is 0.6081979274749756\n",
      "after 416 traning the loss is 0.6874300837516785\n",
      "after 417 traning the loss is 0.6158351898193359\n",
      "after 418 traning the loss is 0.6155661940574646\n",
      "after 419 traning the loss is 0.5982880592346191\n",
      "after 420 traning the loss is 0.5257507562637329\n",
      "after 421 traning the loss is 0.6504378318786621\n",
      "after 422 traning the loss is 0.5413650870323181\n",
      "after 423 traning the loss is 0.6332639455795288\n",
      "after 424 traning the loss is 0.6085408926010132\n",
      "after 425 traning the loss is 0.5802052617073059\n",
      "after 426 traning the loss is 0.670948326587677\n",
      "after 427 traning the loss is 0.7312808036804199\n",
      "after 428 traning the loss is 0.5821199417114258\n",
      "after 429 traning the loss is 0.6921156644821167\n",
      "after 430 traning the loss is 0.6718771457672119\n",
      "after 431 traning the loss is 0.626937985420227\n",
      "after 432 traning the loss is 0.6538100242614746\n",
      "after 433 traning the loss is 0.6531751155853271\n",
      "after 434 traning the loss is 0.6178697943687439\n",
      "after 435 traning the loss is 0.6549562215805054\n",
      "after 436 traning the loss is 0.6291366219520569\n",
      "after 437 traning the loss is 0.6386764049530029\n",
      "after 438 traning the loss is 0.6303576827049255\n",
      "after 439 traning the loss is 0.6652753353118896\n",
      "after 440 traning the loss is 0.6672110557556152\n",
      "after 441 traning the loss is 0.6952267289161682\n",
      "after 442 traning the loss is 0.6295926570892334\n",
      "after 443 traning the loss is 0.6377459168434143\n",
      "after 444 traning the loss is 0.6615735292434692\n",
      "after 445 traning the loss is 0.6384390592575073\n",
      "after 446 traning the loss is 0.6104898452758789\n",
      "after 447 traning the loss is 0.5795583128929138\n",
      "after 448 traning the loss is 0.5960636138916016\n",
      "after 449 traning the loss is 0.6043483018875122\n",
      "after 450 traning the loss is 0.5824762582778931\n",
      "after 451 traning the loss is 0.650964617729187\n",
      "after 452 traning the loss is 0.6877892017364502\n",
      "after 453 traning the loss is 0.6008598804473877\n",
      "after 454 traning the loss is 0.6916078329086304\n",
      "after 455 traning the loss is 0.5194242000579834\n",
      "after 456 traning the loss is 0.6546849608421326\n",
      "after 457 traning the loss is 0.6817293167114258\n",
      "after 458 traning the loss is 0.6852843761444092\n",
      "after 459 traning the loss is 0.6033865213394165\n",
      "after 460 traning the loss is 0.6997812390327454\n",
      "after 461 traning the loss is 0.6663362979888916\n",
      "after 462 traning the loss is 0.5971873998641968\n",
      "after 463 traning the loss is 0.6401050090789795\n",
      "after 464 traning the loss is 0.6619221568107605\n",
      "after 465 traning the loss is 0.6106946468353271\n",
      "after 466 traning the loss is 0.5816681981086731\n",
      "after 467 traning the loss is 0.6300265789031982\n",
      "after 468 traning the loss is 0.6655214428901672\n",
      "after 469 traning the loss is 0.6167793869972229\n",
      "after 470 traning the loss is 0.6955768465995789\n",
      "after 471 traning the loss is 0.6607425212860107\n",
      "after 472 traning the loss is 0.6341162919998169\n",
      "after 473 traning the loss is 0.574669599533081\n",
      "after 474 traning the loss is 0.6687116622924805\n",
      "after 475 traning the loss is 0.6275562047958374\n",
      "after 476 traning the loss is 0.6562755107879639\n",
      "after 477 traning the loss is 0.6839937567710876\n",
      "after 478 traning the loss is 0.6589305400848389\n",
      "after 479 traning the loss is 0.5887070894241333\n",
      "after 480 traning the loss is 0.665614902973175\n",
      "after 481 traning the loss is 0.6795005798339844\n",
      "after 482 traning the loss is 0.6130976676940918\n",
      "after 483 traning the loss is 0.6536670923233032\n",
      "after 484 traning the loss is 0.6850512027740479\n",
      "after 485 traning the loss is 0.67737877368927\n",
      "after 486 traning the loss is 0.6548244953155518\n",
      "after 487 traning the loss is 0.6021851897239685\n",
      "after 488 traning the loss is 0.6619445085525513\n",
      "after 489 traning the loss is 0.6181744337081909\n",
      "after 490 traning the loss is 0.5984553098678589\n",
      "after 491 traning the loss is 0.6811280250549316\n",
      "after 492 traning the loss is 0.61112380027771\n",
      "after 493 traning the loss is 0.5714740753173828\n",
      "after 494 traning the loss is 0.707115888595581\n",
      "after 495 traning the loss is 0.6798427700996399\n",
      "after 496 traning the loss is 0.7106434106826782\n",
      "after 497 traning the loss is 0.5846022367477417\n",
      "after 498 traning the loss is 0.5212821960449219\n",
      "after 499 traning the loss is 0.6453649997711182\n",
      "after 500 traning the loss is 0.6643965244293213\n",
      "after 501 traning the loss is 0.6576504707336426\n",
      "after 502 traning the loss is 0.5760312080383301\n",
      "after 503 traning the loss is 0.5766833424568176\n",
      "after 504 traning the loss is 0.6098477840423584\n",
      "after 505 traning the loss is 0.6450002789497375\n",
      "after 506 traning the loss is 0.6453946828842163\n",
      "after 507 traning the loss is 0.6288174986839294\n",
      "after 508 traning the loss is 0.7773233652114868\n",
      "after 509 traning the loss is 0.6221144795417786\n",
      "after 510 traning the loss is 0.595368504524231\n",
      "after 511 traning the loss is 0.5976529121398926\n",
      "after 512 traning the loss is 0.6411490440368652\n",
      "after 513 traning the loss is 0.6032984852790833\n",
      "after 514 traning the loss is 0.6442606449127197\n",
      "after 515 traning the loss is 0.5943571925163269\n",
      "after 516 traning the loss is 0.651843249797821\n",
      "after 517 traning the loss is 0.6475717425346375\n",
      "after 518 traning the loss is 0.7066018581390381\n",
      "after 519 traning the loss is 0.6475169062614441\n",
      "after 520 traning the loss is 0.6832375526428223\n",
      "after 521 traning the loss is 0.6715437173843384\n",
      "after 522 traning the loss is 0.6465011835098267\n",
      "after 523 traning the loss is 0.6397688388824463\n",
      "after 524 traning the loss is 0.6690948009490967\n",
      "after 525 traning the loss is 0.6419253945350647\n",
      "after 526 traning the loss is 0.6292351484298706\n",
      "after 527 traning the loss is 0.6690313816070557\n",
      "after 528 traning the loss is 0.6247221231460571\n",
      "after 529 traning the loss is 0.6231016516685486\n",
      "after 530 traning the loss is 0.6367367506027222\n",
      "after 531 traning the loss is 0.5903847217559814\n",
      "after 532 traning the loss is 0.6756154298782349\n",
      "after 533 traning the loss is 0.620911717414856\n",
      "after 534 traning the loss is 0.6974102258682251\n",
      "after 535 traning the loss is 0.713864803314209\n",
      "after 536 traning the loss is 0.6160902976989746\n",
      "after 537 traning the loss is 0.5468322038650513\n",
      "after 538 traning the loss is 0.6130343079566956\n",
      "after 539 traning the loss is 0.5958800315856934\n",
      "after 540 traning the loss is 0.626818060874939\n",
      "after 541 traning the loss is 0.6328436136245728\n",
      "after 542 traning the loss is 0.6561610698699951\n",
      "after 543 traning the loss is 0.7212287187576294\n",
      "after 544 traning the loss is 0.6773682832717896\n",
      "after 545 traning the loss is 0.6513416767120361\n",
      "after 546 traning the loss is 0.6622482538223267\n",
      "after 547 traning the loss is 0.6057230830192566\n",
      "after 548 traning the loss is 0.6313522458076477\n",
      "after 549 traning the loss is 0.577425479888916\n",
      "after 550 traning the loss is 0.6327657699584961\n",
      "after 551 traning the loss is 0.6108938455581665\n",
      "after 552 traning the loss is 0.6076725125312805\n",
      "after 553 traning the loss is 0.5940254330635071\n",
      "after 554 traning the loss is 0.5967541933059692\n",
      "after 555 traning the loss is 0.575885534286499\n",
      "after 556 traning the loss is 0.5891728401184082\n",
      "after 557 traning the loss is 0.7386983633041382\n",
      "after 558 traning the loss is 0.5950502157211304\n",
      "after 559 traning the loss is 0.6119194030761719\n",
      "after 560 traning the loss is 0.5788658857345581\n",
      "after 561 traning the loss is 0.6422234177589417\n",
      "after 562 traning the loss is 0.6556446552276611\n",
      "after 563 traning the loss is 0.6324874758720398\n",
      "after 564 traning the loss is 0.6485103368759155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 565 traning the loss is 0.6644095182418823\n",
      "after 566 traning the loss is 0.5465298891067505\n",
      "after 567 traning the loss is 0.6929826140403748\n",
      "after 568 traning the loss is 0.6348338723182678\n",
      "after 569 traning the loss is 0.6616056561470032\n",
      "after 570 traning the loss is 0.6393858194351196\n",
      "after 571 traning the loss is 0.6195733547210693\n",
      "after 572 traning the loss is 0.6470559239387512\n",
      "after 573 traning the loss is 0.6116561889648438\n",
      "after 574 traning the loss is 0.6541301012039185\n",
      "after 575 traning the loss is 0.6798384189605713\n",
      "after 576 traning the loss is 0.6474366784095764\n",
      "after 577 traning the loss is 0.5716544389724731\n",
      "after 578 traning the loss is 0.5908756852149963\n",
      "after 579 traning the loss is 0.6841075420379639\n",
      "after 580 traning the loss is 0.6547549962997437\n",
      "after 581 traning the loss is 0.6844061613082886\n",
      "after 582 traning the loss is 0.5864439010620117\n",
      "after 583 traning the loss is 0.5685607194900513\n",
      "after 584 traning the loss is 0.6519314050674438\n",
      "after 585 traning the loss is 0.6153995394706726\n",
      "after 586 traning the loss is 0.660322904586792\n",
      "after 587 traning the loss is 0.5595778822898865\n",
      "after 588 traning the loss is 0.5212476253509521\n",
      "after 589 traning the loss is 0.7816048264503479\n",
      "after 590 traning the loss is 0.5379868149757385\n",
      "after 591 traning the loss is 0.550406813621521\n",
      "after 592 traning the loss is 0.6517257690429688\n",
      "after 593 traning the loss is 0.5839197635650635\n",
      "after 594 traning the loss is 0.5620570182800293\n",
      "after 595 traning the loss is 0.6480041146278381\n",
      "after 596 traning the loss is 0.7257444858551025\n",
      "after 597 traning the loss is 0.633736789226532\n",
      "after 598 traning the loss is 0.6557554006576538\n",
      "after 599 traning the loss is 0.6408994793891907\n",
      "after 600 traning the loss is 0.5768939256668091\n",
      "after 601 traning the loss is 0.6225531101226807\n",
      "after 602 traning the loss is 0.6298738718032837\n",
      "after 603 traning the loss is 0.6343449354171753\n",
      "after 604 traning the loss is 0.6696738004684448\n",
      "after 605 traning the loss is 0.6371074914932251\n",
      "after 606 traning the loss is 0.6731066703796387\n",
      "after 607 traning the loss is 0.6532739996910095\n",
      "after 608 traning the loss is 0.6033608317375183\n",
      "after 609 traning the loss is 0.6106539964675903\n",
      "after 610 traning the loss is 0.6954210996627808\n",
      "after 611 traning the loss is 0.5737128257751465\n",
      "after 612 traning the loss is 0.6158925890922546\n",
      "after 613 traning the loss is 0.6446095705032349\n",
      "after 614 traning the loss is 0.6099389791488647\n",
      "after 615 traning the loss is 0.6341575980186462\n",
      "after 616 traning the loss is 0.6538510322570801\n",
      "after 617 traning the loss is 0.6428419351577759\n",
      "after 618 traning the loss is 0.6420509815216064\n",
      "after 619 traning the loss is 0.6589353680610657\n",
      "after 620 traning the loss is 0.6508914828300476\n",
      "after 621 traning the loss is 0.7093427181243896\n",
      "after 622 traning the loss is 0.5773916244506836\n",
      "after 623 traning the loss is 0.6349532604217529\n",
      "after 624 traning the loss is 0.6782312393188477\n",
      "after 625 traning the loss is 0.6333463788032532\n",
      "after 626 traning the loss is 0.625241219997406\n",
      "after 627 traning the loss is 0.6464189887046814\n",
      "after 628 traning the loss is 0.5916582345962524\n",
      "after 629 traning the loss is 0.6195695400238037\n",
      "after 630 traning the loss is 0.6270750761032104\n",
      "after 631 traning the loss is 0.5985379219055176\n",
      "after 632 traning the loss is 0.5846801996231079\n",
      "after 633 traning the loss is 0.6189048290252686\n",
      "after 634 traning the loss is 0.5890423059463501\n",
      "after 635 traning the loss is 0.6244375705718994\n",
      "after 636 traning the loss is 0.6257445812225342\n",
      "after 637 traning the loss is 0.6200642585754395\n",
      "after 638 traning the loss is 0.5899454355239868\n",
      "after 639 traning the loss is 0.5853888988494873\n",
      "after 640 traning the loss is 0.6605057716369629\n",
      "after 641 traning the loss is 0.6669049263000488\n",
      "after 642 traning the loss is 0.7103593945503235\n",
      "after 643 traning the loss is 0.5629095435142517\n",
      "after 644 traning the loss is 0.6479203701019287\n",
      "after 645 traning the loss is 0.7099143266677856\n",
      "after 646 traning the loss is 0.5595510005950928\n",
      "after 647 traning the loss is 0.5939050912857056\n",
      "after 648 traning the loss is 0.6295382976531982\n",
      "after 649 traning the loss is 0.6843994855880737\n",
      "after 650 traning the loss is 0.605974555015564\n",
      "after 651 traning the loss is 0.6377699375152588\n",
      "after 652 traning the loss is 0.5827848315238953\n",
      "after 653 traning the loss is 0.5985119938850403\n",
      "after 654 traning the loss is 0.7001302242279053\n",
      "after 655 traning the loss is 0.6211181879043579\n",
      "after 656 traning the loss is 0.6213152408599854\n",
      "after 657 traning the loss is 0.6447111368179321\n",
      "after 658 traning the loss is 0.6049574613571167\n",
      "after 659 traning the loss is 0.6450203657150269\n",
      "after 660 traning the loss is 0.5794550180435181\n",
      "after 661 traning the loss is 0.7193460464477539\n",
      "after 662 traning the loss is 0.6332894563674927\n",
      "after 663 traning the loss is 0.6328428983688354\n",
      "after 664 traning the loss is 0.5718801021575928\n",
      "after 665 traning the loss is 0.6435546278953552\n",
      "after 666 traning the loss is 0.664081335067749\n",
      "after 667 traning the loss is 0.6236755847930908\n",
      "after 668 traning the loss is 0.6487222909927368\n",
      "after 669 traning the loss is 0.6370505690574646\n",
      "after 670 traning the loss is 0.6285195350646973\n",
      "after 671 traning the loss is 0.6058955788612366\n",
      "after 672 traning the loss is 0.6411974430084229\n",
      "after 673 traning the loss is 0.6389786005020142\n",
      "after 674 traning the loss is 0.6435571312904358\n",
      "after 675 traning the loss is 0.5794704556465149\n",
      "after 676 traning the loss is 0.6556774377822876\n",
      "after 677 traning the loss is 0.5796622037887573\n",
      "after 678 traning the loss is 0.7032648921012878\n",
      "after 679 traning the loss is 0.5532781481742859\n",
      "after 680 traning the loss is 0.6467519998550415\n",
      "after 681 traning the loss is 0.6285744309425354\n",
      "after 682 traning the loss is 0.569821834564209\n",
      "after 683 traning the loss is 0.5375900268554688\n",
      "after 684 traning the loss is 0.6357651948928833\n",
      "after 685 traning the loss is 0.5800178050994873\n",
      "after 686 traning the loss is 0.6382970809936523\n",
      "after 687 traning the loss is 0.65375816822052\n",
      "after 688 traning the loss is 0.5752270817756653\n",
      "after 689 traning the loss is 0.5890710353851318\n",
      "after 690 traning the loss is 0.6227278709411621\n",
      "after 691 traning the loss is 0.5943504571914673\n",
      "after 692 traning the loss is 0.6438471674919128\n",
      "after 693 traning the loss is 0.5509047508239746\n",
      "after 694 traning the loss is 0.6451646089553833\n",
      "after 695 traning the loss is 0.5754863023757935\n",
      "after 696 traning the loss is 0.6371697187423706\n",
      "after 697 traning the loss is 0.6031845808029175\n",
      "after 698 traning the loss is 0.5658622980117798\n",
      "after 699 traning the loss is 0.6210864782333374\n",
      "after 700 traning the loss is 0.5817365646362305\n",
      "after 701 traning the loss is 0.6469202637672424\n",
      "after 702 traning the loss is 0.5921921133995056\n",
      "after 703 traning the loss is 0.5310496687889099\n",
      "after 704 traning the loss is 0.6801823973655701\n",
      "after 705 traning the loss is 0.6573996543884277\n",
      "after 706 traning the loss is 0.6757867932319641\n",
      "after 707 traning the loss is 0.6803158521652222\n",
      "after 708 traning the loss is 0.6181145906448364\n",
      "after 709 traning the loss is 0.6280555129051208\n",
      "after 710 traning the loss is 0.6403875350952148\n",
      "after 711 traning the loss is 0.6259371638298035\n",
      "after 712 traning the loss is 0.6089718341827393\n",
      "after 713 traning the loss is 0.6344667673110962\n",
      "after 714 traning the loss is 0.6537470817565918\n",
      "after 715 traning the loss is 0.6597760915756226\n",
      "after 716 traning the loss is 0.5754228830337524\n",
      "after 717 traning the loss is 0.70705246925354\n",
      "after 718 traning the loss is 0.5874800682067871\n",
      "after 719 traning the loss is 0.5716040134429932\n",
      "after 720 traning the loss is 0.5766183733940125\n",
      "after 721 traning the loss is 0.6328887939453125\n",
      "after 722 traning the loss is 0.6253284811973572\n",
      "after 723 traning the loss is 0.6516757607460022\n",
      "after 724 traning the loss is 0.6294692754745483\n",
      "after 725 traning the loss is 0.6209694147109985\n",
      "after 726 traning the loss is 0.6583414077758789\n",
      "after 727 traning the loss is 0.6959357261657715\n",
      "after 728 traning the loss is 0.6777044534683228\n",
      "after 729 traning the loss is 0.6025019884109497\n",
      "after 730 traning the loss is 0.6175560355186462\n",
      "after 731 traning the loss is 0.5935017466545105\n",
      "after 732 traning the loss is 0.7261263132095337\n",
      "after 733 traning the loss is 0.6678667068481445\n",
      "after 734 traning the loss is 0.7095247507095337\n",
      "after 735 traning the loss is 0.621178150177002\n",
      "after 736 traning the loss is 0.6065250635147095\n",
      "after 737 traning the loss is 0.6624364852905273\n",
      "after 738 traning the loss is 0.6343344449996948\n",
      "after 739 traning the loss is 0.6659364104270935\n",
      "after 740 traning the loss is 0.6766335964202881\n",
      "after 741 traning the loss is 0.6611291170120239\n",
      "after 742 traning the loss is 0.6522558927536011\n",
      "after 743 traning the loss is 0.6373083591461182\n",
      "after 744 traning the loss is 0.6279641389846802\n",
      "after 745 traning the loss is 0.5551031827926636\n",
      "after 746 traning the loss is 0.5594909191131592\n",
      "after 747 traning the loss is 0.5896239876747131\n",
      "after 748 traning the loss is 0.5644404888153076\n",
      "after 749 traning the loss is 0.6922473311424255\n",
      "after 750 traning the loss is 0.609599232673645\n",
      "after 751 traning the loss is 0.6275455355644226\n",
      "after 752 traning the loss is 0.624194860458374\n",
      "after 753 traning the loss is 0.5588561296463013\n",
      "after 754 traning the loss is 0.7331498861312866\n",
      "after 755 traning the loss is 0.5457712411880493\n",
      "after 756 traning the loss is 0.5987297892570496\n",
      "after 757 traning the loss is 0.5505133867263794\n",
      "after 758 traning the loss is 0.563894510269165\n",
      "after 759 traning the loss is 0.6221370697021484\n",
      "after 760 traning the loss is 0.7266319990158081\n",
      "after 761 traning the loss is 0.6943238377571106\n",
      "after 762 traning the loss is 0.6402121782302856\n",
      "after 763 traning the loss is 0.6379104256629944\n",
      "after 764 traning the loss is 0.6447731256484985\n",
      "after 765 traning the loss is 0.6110343933105469\n",
      "after 766 traning the loss is 0.5701852440834045\n",
      "after 767 traning the loss is 0.5991893410682678\n",
      "after 768 traning the loss is 0.6049323081970215\n",
      "after 769 traning the loss is 0.6019071340560913\n",
      "after 770 traning the loss is 0.5112060308456421\n",
      "after 771 traning the loss is 0.62824946641922\n",
      "after 772 traning the loss is 0.5902097225189209\n",
      "after 773 traning the loss is 0.5927832722663879\n",
      "after 774 traning the loss is 0.7040480375289917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 775 traning the loss is 0.6256996393203735\n",
      "after 776 traning the loss is 0.6071149706840515\n",
      "after 777 traning the loss is 0.6843563318252563\n",
      "after 778 traning the loss is 0.5917681455612183\n",
      "after 779 traning the loss is 0.5890934467315674\n",
      "after 780 traning the loss is 0.6474389433860779\n",
      "after 781 traning the loss is 0.6075507402420044\n",
      "after 782 traning the loss is 0.555250883102417\n",
      "after 783 traning the loss is 0.6805926561355591\n",
      "after 784 traning the loss is 0.6371171474456787\n",
      "after 785 traning the loss is 0.716791033744812\n",
      "after 786 traning the loss is 0.6113636493682861\n",
      "after 787 traning the loss is 0.7176439762115479\n",
      "after 788 traning the loss is 0.628766655921936\n",
      "after 789 traning the loss is 0.5671062469482422\n",
      "after 790 traning the loss is 0.5893896818161011\n",
      "after 791 traning the loss is 0.5622996091842651\n",
      "after 792 traning the loss is 0.6045490503311157\n",
      "after 793 traning the loss is 0.6361314058303833\n",
      "after 794 traning the loss is 0.566297173500061\n",
      "after 795 traning the loss is 0.5689097046852112\n",
      "after 796 traning the loss is 0.4899253249168396\n",
      "after 797 traning the loss is 0.6602005958557129\n",
      "after 798 traning the loss is 0.6657582521438599\n",
      "after 799 traning the loss is 0.6089135408401489\n",
      "after 800 traning the loss is 0.6533170938491821\n",
      "after 801 traning the loss is 0.605363130569458\n",
      "after 802 traning the loss is 0.6226562261581421\n",
      "after 803 traning the loss is 0.5951347351074219\n",
      "after 804 traning the loss is 0.5772914290428162\n",
      "after 805 traning the loss is 0.6237208843231201\n",
      "after 806 traning the loss is 0.6184777021408081\n",
      "after 807 traning the loss is 0.5525296926498413\n",
      "after 808 traning the loss is 0.5967119932174683\n",
      "after 809 traning the loss is 0.629809558391571\n",
      "after 810 traning the loss is 0.622381329536438\n",
      "after 811 traning the loss is 0.5695292949676514\n",
      "after 812 traning the loss is 0.5291774272918701\n",
      "after 813 traning the loss is 0.573399543762207\n",
      "after 814 traning the loss is 0.6302140355110168\n",
      "after 815 traning the loss is 0.644420862197876\n",
      "after 816 traning the loss is 0.5773721933364868\n",
      "after 817 traning the loss is 0.6114887595176697\n",
      "after 818 traning the loss is 0.5215471982955933\n",
      "after 819 traning the loss is 0.6470510959625244\n",
      "after 820 traning the loss is 0.6465751528739929\n",
      "after 821 traning the loss is 0.6089246869087219\n",
      "after 822 traning the loss is 0.6424815058708191\n",
      "after 823 traning the loss is 0.613225519657135\n",
      "after 824 traning the loss is 0.6130306720733643\n",
      "after 825 traning the loss is 0.6456211805343628\n",
      "after 826 traning the loss is 0.7098114490509033\n",
      "after 827 traning the loss is 0.6133502721786499\n",
      "after 828 traning the loss is 0.6391922235488892\n",
      "after 829 traning the loss is 0.6673392057418823\n",
      "after 830 traning the loss is 0.6200787425041199\n",
      "after 831 traning the loss is 0.5857837796211243\n",
      "after 832 traning the loss is 0.5434677600860596\n",
      "after 833 traning the loss is 0.6210890412330627\n",
      "after 834 traning the loss is 0.6055805087089539\n",
      "after 835 traning the loss is 0.5839780569076538\n",
      "after 836 traning the loss is 0.5963751077651978\n",
      "after 837 traning the loss is 0.7352635860443115\n",
      "after 838 traning the loss is 0.5505890250205994\n",
      "after 839 traning the loss is 0.5694525241851807\n",
      "after 840 traning the loss is 0.5235686302185059\n",
      "after 841 traning the loss is 0.7146604061126709\n",
      "after 842 traning the loss is 0.6079757809638977\n",
      "after 843 traning the loss is 0.6162738800048828\n",
      "after 844 traning the loss is 0.6593561172485352\n",
      "after 845 traning the loss is 0.5958081483840942\n",
      "after 846 traning the loss is 0.5630890130996704\n",
      "after 847 traning the loss is 0.6157923340797424\n",
      "after 848 traning the loss is 0.5934385061264038\n",
      "after 849 traning the loss is 0.5780471563339233\n",
      "after 850 traning the loss is 0.6226263046264648\n",
      "after 851 traning the loss is 0.5990390777587891\n",
      "after 852 traning the loss is 0.6111382246017456\n",
      "after 853 traning the loss is 0.6557517051696777\n",
      "after 854 traning the loss is 0.5783474445343018\n",
      "after 855 traning the loss is 0.5765312910079956\n",
      "after 856 traning the loss is 0.642219066619873\n",
      "after 857 traning the loss is 0.6010605096817017\n",
      "after 858 traning the loss is 0.6086341738700867\n",
      "after 859 traning the loss is 0.5578278303146362\n",
      "after 860 traning the loss is 0.6361516714096069\n",
      "after 861 traning the loss is 0.5738719701766968\n",
      "after 862 traning the loss is 0.6497935652732849\n",
      "after 863 traning the loss is 0.5430695414543152\n",
      "after 864 traning the loss is 0.5229474902153015\n",
      "after 865 traning the loss is 0.5200658440589905\n",
      "after 866 traning the loss is 0.5205037593841553\n",
      "after 867 traning the loss is 0.6622263193130493\n",
      "after 868 traning the loss is 0.413725882768631\n",
      "after 869 traning the loss is 0.6685663461685181\n",
      "after 870 traning the loss is 0.6094111204147339\n",
      "after 871 traning the loss is 0.5582785606384277\n",
      "after 872 traning the loss is 0.39927494525909424\n",
      "after 873 traning the loss is 0.4737454950809479\n",
      "after 874 traning the loss is 0.470631867647171\n",
      "after 875 traning the loss is 0.5144948959350586\n",
      "after 876 traning the loss is 0.5540102124214172\n",
      "after 877 traning the loss is 0.6541792154312134\n",
      "after 878 traning the loss is 0.5765790939331055\n",
      "after 879 traning the loss is 0.5567387342453003\n",
      "after 880 traning the loss is 0.34492745995521545\n",
      "after 881 traning the loss is 0.6128043532371521\n",
      "after 882 traning the loss is 0.30455583333969116\n",
      "after 883 traning the loss is 0.36248424649238586\n",
      "after 884 traning the loss is 0.39065879583358765\n",
      "after 885 traning the loss is 0.3208690285682678\n",
      "after 886 traning the loss is 0.29439887404441833\n",
      "after 887 traning the loss is 0.3928385376930237\n",
      "after 888 traning the loss is 0.3099634051322937\n",
      "after 889 traning the loss is 0.5889478921890259\n",
      "after 890 traning the loss is 0.5056841969490051\n",
      "after 891 traning the loss is 0.2829056978225708\n",
      "after 892 traning the loss is 0.48665234446525574\n",
      "after 893 traning the loss is 0.2893303334712982\n",
      "after 894 traning the loss is 0.2733050286769867\n",
      "after 895 traning the loss is 0.29458725452423096\n",
      "after 896 traning the loss is 0.42795661091804504\n",
      "after 897 traning the loss is 0.31791019439697266\n",
      "after 898 traning the loss is 0.33226463198661804\n",
      "after 899 traning the loss is 0.17172540724277496\n",
      "after 900 traning the loss is 0.19304108619689941\n",
      "after 901 traning the loss is 0.23241165280342102\n",
      "after 902 traning the loss is 0.28058966994285583\n",
      "after 903 traning the loss is 0.24598833918571472\n",
      "after 904 traning the loss is 0.33063581585884094\n",
      "after 905 traning the loss is 0.15599527955055237\n",
      "after 906 traning the loss is 0.1976589858531952\n",
      "after 907 traning the loss is 0.20345690846443176\n",
      "after 908 traning the loss is 0.21655437350273132\n",
      "after 909 traning the loss is 0.2850220799446106\n",
      "after 910 traning the loss is 0.26826679706573486\n",
      "after 911 traning the loss is 0.14217650890350342\n",
      "after 912 traning the loss is 0.17763523757457733\n",
      "after 913 traning the loss is 0.1205204576253891\n",
      "after 914 traning the loss is 0.20227685570716858\n",
      "after 915 traning the loss is 0.28113842010498047\n",
      "after 916 traning the loss is 0.1775168627500534\n",
      "after 917 traning the loss is 0.07739055901765823\n",
      "after 918 traning the loss is 0.162178635597229\n",
      "after 919 traning the loss is 0.1866651177406311\n",
      "after 920 traning the loss is 0.12014137208461761\n",
      "after 921 traning the loss is 0.1323845386505127\n",
      "after 922 traning the loss is 0.09660421311855316\n",
      "after 923 traning the loss is 0.23042185604572296\n",
      "after 924 traning the loss is 0.16635501384735107\n",
      "after 925 traning the loss is 0.23522618412971497\n",
      "after 926 traning the loss is 0.17009501159191132\n",
      "after 927 traning the loss is 0.14848953485488892\n",
      "after 928 traning the loss is 0.17913185060024261\n",
      "after 929 traning the loss is 0.1512654721736908\n",
      "after 930 traning the loss is 0.2028939425945282\n",
      "after 931 traning the loss is 0.227638840675354\n",
      "after 932 traning the loss is 0.11295004189014435\n",
      "after 933 traning the loss is 0.062269389629364014\n",
      "after 934 traning the loss is 0.04958212375640869\n",
      "after 935 traning the loss is 0.1375996470451355\n",
      "after 936 traning the loss is 0.1621486097574234\n",
      "after 937 traning the loss is 0.10216780006885529\n",
      "after 938 traning the loss is 0.046767108142375946\n",
      "after 939 traning the loss is 0.05452209338545799\n",
      "after 940 traning the loss is 0.05678444355726242\n",
      "after 941 traning the loss is 0.1223934143781662\n",
      "after 942 traning the loss is 0.12213170528411865\n",
      "after 943 traning the loss is 0.17882952094078064\n",
      "after 944 traning the loss is 0.17554835975170135\n",
      "after 945 traning the loss is 0.10071015357971191\n",
      "after 946 traning the loss is 0.1704004853963852\n",
      "after 947 traning the loss is 0.1412144899368286\n",
      "after 948 traning the loss is 0.1010003536939621\n",
      "after 949 traning the loss is 0.1496824324131012\n",
      "after 950 traning the loss is 0.0978841632604599\n",
      "after 951 traning the loss is 0.0943760797381401\n",
      "after 952 traning the loss is 0.26955825090408325\n",
      "after 953 traning the loss is 0.2199752926826477\n",
      "after 954 traning the loss is 0.1070094034075737\n",
      "after 955 traning the loss is 0.18932688236236572\n",
      "after 956 traning the loss is 0.1788501739501953\n",
      "after 957 traning the loss is 0.1368633508682251\n",
      "after 958 traning the loss is 0.06002209335565567\n",
      "after 959 traning the loss is 0.07518325746059418\n",
      "after 960 traning the loss is 0.03982303664088249\n",
      "after 961 traning the loss is 0.059340860694646835\n",
      "after 962 traning the loss is 0.1611856371164322\n",
      "after 963 traning the loss is 0.08918575197458267\n",
      "after 964 traning the loss is 0.17809823155403137\n",
      "after 965 traning the loss is 0.20100274682044983\n",
      "after 966 traning the loss is 0.053703710436820984\n",
      "after 967 traning the loss is 0.16814884543418884\n",
      "after 968 traning the loss is 0.05577044188976288\n",
      "after 969 traning the loss is 0.07209262251853943\n",
      "after 970 traning the loss is 0.16188214719295502\n",
      "after 971 traning the loss is 0.0565868616104126\n",
      "after 972 traning the loss is 0.06553278118371964\n",
      "after 973 traning the loss is 0.03424765169620514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 974 traning the loss is 0.07876235991716385\n",
      "after 975 traning the loss is 0.0883495882153511\n",
      "after 976 traning the loss is 0.07133475691080093\n",
      "after 977 traning the loss is 0.051672693341970444\n",
      "after 978 traning the loss is 0.10432988405227661\n",
      "after 979 traning the loss is 0.13651086390018463\n",
      "after 980 traning the loss is 0.06822342425584793\n",
      "after 981 traning the loss is 0.0569705069065094\n",
      "after 982 traning the loss is 0.07670076191425323\n",
      "after 983 traning the loss is 0.04868021234869957\n",
      "after 984 traning the loss is 0.06648087501525879\n",
      "after 985 traning the loss is 0.07160566002130508\n",
      "after 986 traning the loss is 0.060060542076826096\n",
      "after 987 traning the loss is 0.07309666275978088\n",
      "after 988 traning the loss is 0.06165265664458275\n",
      "after 989 traning the loss is 0.1259453296661377\n",
      "after 990 traning the loss is 0.05393443629145622\n",
      "after 991 traning the loss is 0.042208537459373474\n",
      "after 992 traning the loss is 0.09396934509277344\n",
      "after 993 traning the loss is 0.0980188250541687\n",
      "after 994 traning the loss is 0.0851607695221901\n",
      "after 995 traning the loss is 0.06475940346717834\n",
      "after 996 traning the loss is 0.11697367578744888\n",
      "after 997 traning the loss is 0.04755569249391556\n",
      "after 998 traning the loss is 0.031146394088864326\n",
      "after 999 traning the loss is 0.05671010911464691\n",
      "after 1000 traning the loss is 0.10829339921474457\n",
      "after 1001 traning the loss is 0.3299770951271057\n",
      "after 1002 traning the loss is 0.039333175867795944\n",
      "after 1003 traning the loss is 0.14718326926231384\n",
      "after 1004 traning the loss is 0.11594660580158234\n",
      "after 1005 traning the loss is 0.08938167244195938\n",
      "after 1006 traning the loss is 0.14503535628318787\n",
      "after 1007 traning the loss is 0.1017339900135994\n",
      "after 1008 traning the loss is 0.04234115779399872\n",
      "after 1009 traning the loss is 0.11617153882980347\n",
      "after 1010 traning the loss is 0.06409148871898651\n",
      "after 1011 traning the loss is 0.1082717776298523\n",
      "after 1012 traning the loss is 0.14523211121559143\n",
      "after 1013 traning the loss is 0.12404405325651169\n",
      "after 1014 traning the loss is 0.1099766194820404\n",
      "after 1015 traning the loss is 0.05472922325134277\n",
      "after 1016 traning the loss is 0.08681775629520416\n",
      "after 1017 traning the loss is 0.043772630393505096\n",
      "after 1018 traning the loss is 0.025195013731718063\n",
      "after 1019 traning the loss is 0.03991173952817917\n",
      "after 1020 traning the loss is 0.03742396831512451\n",
      "after 1021 traning the loss is 0.04397307336330414\n",
      "after 1022 traning the loss is 0.034385405480861664\n",
      "after 1023 traning the loss is 0.0881437361240387\n",
      "after 1024 traning the loss is 0.06904257833957672\n",
      "after 1025 traning the loss is 0.0986625924706459\n",
      "after 1026 traning the loss is 0.05881737917661667\n",
      "after 1027 traning the loss is 0.04750923439860344\n",
      "after 1028 traning the loss is 0.10384749621152878\n",
      "after 1029 traning the loss is 0.07119773328304291\n",
      "after 1030 traning the loss is 0.13401664793491364\n",
      "after 1031 traning the loss is 0.03602820262312889\n",
      "after 1032 traning the loss is 0.07690715044736862\n",
      "after 1033 traning the loss is 0.04596434161067009\n",
      "after 1034 traning the loss is 0.0639997124671936\n",
      "after 1035 traning the loss is 0.117772676050663\n",
      "after 1036 traning the loss is 0.09162228554487228\n",
      "after 1037 traning the loss is 0.051267359405756\n",
      "after 1038 traning the loss is 0.0438031405210495\n",
      "after 1039 traning the loss is 0.16448229551315308\n",
      "after 1040 traning the loss is 0.09342020750045776\n",
      "after 1041 traning the loss is 0.1171785295009613\n",
      "after 1042 traning the loss is 0.053522054105997086\n",
      "after 1043 traning the loss is 0.052959851920604706\n",
      "after 1044 traning the loss is 0.020044604316353798\n",
      "after 1045 traning the loss is 0.014668958261609077\n",
      "after 1046 traning the loss is 0.09873079508543015\n",
      "after 1047 traning the loss is 0.07813303917646408\n",
      "after 1048 traning the loss is 0.028043022379279137\n",
      "after 1049 traning the loss is 0.04419954493641853\n",
      "after 1050 traning the loss is 0.14253568649291992\n",
      "after 1051 traning the loss is 0.038666702806949615\n",
      "after 1052 traning the loss is 0.041244056075811386\n",
      "after 1053 traning the loss is 0.10826930403709412\n",
      "after 1054 traning the loss is 0.06969749927520752\n",
      "after 1055 traning the loss is 0.13954246044158936\n",
      "after 1056 traning the loss is 0.09165696799755096\n",
      "after 1057 traning the loss is 0.033478882163763046\n",
      "after 1058 traning the loss is 0.15771540999412537\n",
      "after 1059 traning the loss is 0.06128131225705147\n",
      "after 1060 traning the loss is 0.07110543549060822\n",
      "after 1061 traning the loss is 0.1205875426530838\n",
      "after 1062 traning the loss is 0.044424138963222504\n",
      "after 1063 traning the loss is 0.05275481194257736\n",
      "after 1064 traning the loss is 0.02795943059027195\n",
      "after 1065 traning the loss is 0.048368487507104874\n",
      "after 1066 traning the loss is 0.09529905021190643\n",
      "after 1067 traning the loss is 0.07581660896539688\n",
      "after 1068 traning the loss is 0.033605486154556274\n",
      "after 1069 traning the loss is 0.06745212525129318\n",
      "after 1070 traning the loss is 0.030785268172621727\n",
      "after 1071 traning the loss is 0.03558097034692764\n",
      "after 1072 traning the loss is 0.023402530699968338\n",
      "after 1073 traning the loss is 0.08525417000055313\n",
      "after 1074 traning the loss is 0.055657584220170975\n",
      "after 1075 traning the loss is 0.09391412883996964\n",
      "after 1076 traning the loss is 0.03797190263867378\n",
      "after 1077 traning the loss is 0.04568253457546234\n",
      "after 1078 traning the loss is 0.11004293709993362\n",
      "after 1079 traning the loss is 0.05586160719394684\n",
      "after 1080 traning the loss is 0.06341321766376495\n",
      "after 1081 traning the loss is 0.04505900293588638\n",
      "after 1082 traning the loss is 0.06477706134319305\n",
      "after 1083 traning the loss is 0.06563906371593475\n",
      "after 1084 traning the loss is 0.022741934284567833\n",
      "after 1085 traning the loss is 0.04042552784085274\n",
      "after 1086 traning the loss is 0.026527438312768936\n",
      "after 1087 traning the loss is 0.05088934674859047\n",
      "after 1088 traning the loss is 0.033199429512023926\n",
      "after 1089 traning the loss is 0.008319216780364513\n",
      "after 1090 traning the loss is 0.03679843991994858\n",
      "after 1091 traning the loss is 0.05138377100229263\n",
      "after 1092 traning the loss is 0.03466237708926201\n",
      "after 1093 traning the loss is 0.01905500516295433\n",
      "after 1094 traning the loss is 0.05991619825363159\n",
      "after 1095 traning the loss is 0.02948639914393425\n",
      "after 1096 traning the loss is 0.04528578370809555\n",
      "after 1097 traning the loss is 0.08365007489919662\n",
      "after 1098 traning the loss is 0.0945744663476944\n",
      "after 1099 traning the loss is 0.029795026406645775\n",
      "after 1100 traning the loss is 0.04950982332229614\n",
      "after 1101 traning the loss is 0.04682907089591026\n",
      "after 1102 traning the loss is 0.08165496587753296\n",
      "after 1103 traning the loss is 0.01248293649405241\n",
      "after 1104 traning the loss is 0.045087702572345734\n",
      "after 1105 traning the loss is 0.04242405295372009\n",
      "after 1106 traning the loss is 0.011273772455751896\n",
      "after 1107 traning the loss is 0.010933078825473785\n",
      "after 1108 traning the loss is 0.01920926943421364\n",
      "after 1109 traning the loss is 0.028578802943229675\n",
      "after 1110 traning the loss is 0.01385376788675785\n",
      "after 1111 traning the loss is 0.12015271186828613\n",
      "after 1112 traning the loss is 0.04188265651464462\n",
      "after 1113 traning the loss is 0.03661167994141579\n",
      "after 1114 traning the loss is 0.10469075292348862\n",
      "after 1115 traning the loss is 0.09256221354007721\n",
      "after 1116 traning the loss is 0.06222379952669144\n",
      "after 1117 traning the loss is 0.03241858258843422\n",
      "after 1118 traning the loss is 0.013301309198141098\n",
      "after 1119 traning the loss is 0.01628607138991356\n",
      "after 1120 traning the loss is 0.05654086172580719\n",
      "after 1121 traning the loss is 0.049474213272333145\n",
      "after 1122 traning the loss is 0.06651380658149719\n",
      "after 1123 traning the loss is 0.009121372364461422\n",
      "after 1124 traning the loss is 0.026547733694314957\n",
      "after 1125 traning the loss is 0.048650480806827545\n",
      "after 1126 traning the loss is 0.06868775933980942\n",
      "after 1127 traning the loss is 0.016425419598817825\n",
      "after 1128 traning the loss is 0.021830163896083832\n",
      "after 1129 traning the loss is 0.023568883538246155\n",
      "after 1130 traning the loss is 0.02506069839000702\n",
      "after 1131 traning the loss is 0.050860095769166946\n",
      "after 1132 traning the loss is 0.015999281778931618\n",
      "after 1133 traning the loss is 0.008366698399186134\n",
      "after 1134 traning the loss is 0.018504614010453224\n",
      "after 1135 traning the loss is 0.05193636938929558\n",
      "after 1136 traning the loss is 0.027464013546705246\n",
      "after 1137 traning the loss is 0.012844175100326538\n",
      "after 1138 traning the loss is 0.05393272638320923\n",
      "after 1139 traning the loss is 0.02857890911400318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1140 traning the loss is 0.01152688730508089\n",
      "after 1141 traning the loss is 0.039903707802295685\n",
      "after 1142 traning the loss is 0.08914539217948914\n",
      "after 1143 traning the loss is 0.1187908798456192\n",
      "after 1144 traning the loss is 0.018622810021042824\n",
      "after 1145 traning the loss is 0.032619278877973557\n",
      "after 1146 traning the loss is 0.054345566779375076\n",
      "after 1147 traning the loss is 0.020564980804920197\n",
      "after 1148 traning the loss is 0.019649146124720573\n",
      "after 1149 traning the loss is 0.10194757580757141\n",
      "after 1150 traning the loss is 0.0988260805606842\n",
      "after 1151 traning the loss is 0.017796970903873444\n",
      "after 1152 traning the loss is 0.033109698444604874\n",
      "after 1153 traning the loss is 0.009221133776009083\n",
      "after 1154 traning the loss is 0.012305933982133865\n",
      "after 1155 traning the loss is 0.034576669335365295\n",
      "after 1156 traning the loss is 0.07183724641799927\n",
      "after 1157 traning the loss is 0.01984245330095291\n",
      "after 1158 traning the loss is 0.023100657388567924\n",
      "after 1159 traning the loss is 0.10186323523521423\n",
      "after 1160 traning the loss is 0.007995973341166973\n",
      "after 1161 traning the loss is 0.02345200814306736\n",
      "after 1162 traning the loss is 0.01097976416349411\n",
      "after 1163 traning the loss is 0.06618017703294754\n",
      "after 1164 traning the loss is 0.01115287747234106\n",
      "after 1165 traning the loss is 0.1527734100818634\n",
      "after 1166 traning the loss is 0.013980410993099213\n",
      "after 1167 traning the loss is 0.008317675441503525\n",
      "after 1168 traning the loss is 0.014493192546069622\n",
      "after 1169 traning the loss is 0.030569884926080704\n",
      "after 1170 traning the loss is 0.02552923932671547\n",
      "after 1171 traning the loss is 0.016126587986946106\n",
      "after 1172 traning the loss is 0.012187734246253967\n",
      "after 1173 traning the loss is 0.0658704936504364\n",
      "after 1174 traning the loss is 0.023640116676688194\n",
      "after 1175 traning the loss is 0.03581133484840393\n",
      "after 1176 traning the loss is 0.11098534613847733\n",
      "after 1177 traning the loss is 0.01041613332927227\n",
      "after 1178 traning the loss is 0.01867741346359253\n",
      "after 1179 traning the loss is 0.026876501739025116\n",
      "after 1180 traning the loss is 0.013324059545993805\n",
      "after 1181 traning the loss is 0.025208521634340286\n",
      "after 1182 traning the loss is 0.017778949812054634\n",
      "after 1183 traning the loss is 0.10141254961490631\n",
      "after 1184 traning the loss is 0.019316475838422775\n",
      "after 1185 traning the loss is 0.007883675396442413\n",
      "after 1186 traning the loss is 0.01809583604335785\n",
      "after 1187 traning the loss is 0.09219107776880264\n",
      "after 1188 traning the loss is 0.07464328408241272\n",
      "after 1189 traning the loss is 0.021177269518375397\n",
      "after 1190 traning the loss is 0.009484915994107723\n",
      "after 1191 traning the loss is 0.012267072685062885\n",
      "after 1192 traning the loss is 0.014905525371432304\n",
      "after 1193 traning the loss is 0.056627169251441956\n",
      "after 1194 traning the loss is 0.016173146665096283\n",
      "after 1195 traning the loss is 0.0531109943985939\n",
      "after 1196 traning the loss is 0.055167727172374725\n",
      "after 1197 traning the loss is 0.01369059644639492\n",
      "after 1198 traning the loss is 0.039841972291469574\n",
      "after 1199 traning the loss is 0.027134791016578674\n",
      "after 1200 traning the loss is 0.03311075642704964\n",
      "after 1201 traning the loss is 0.011480176821351051\n",
      "after 1202 traning the loss is 0.07979749888181686\n",
      "after 1203 traning the loss is 0.01628795638680458\n",
      "after 1204 traning the loss is 0.10186165571212769\n",
      "after 1205 traning the loss is 0.07994067668914795\n",
      "after 1206 traning the loss is 0.012023905292153358\n",
      "after 1207 traning the loss is 0.060527339577674866\n",
      "after 1208 traning the loss is 0.007831485010683537\n",
      "after 1209 traning the loss is 0.031455572694540024\n",
      "after 1210 traning the loss is 0.04351156949996948\n",
      "after 1211 traning the loss is 0.006262728478759527\n",
      "after 1212 traning the loss is 0.01188245415687561\n",
      "after 1213 traning the loss is 0.06432231515645981\n",
      "after 1214 traning the loss is 0.06798017770051956\n",
      "after 1215 traning the loss is 0.01185147650539875\n",
      "after 1216 traning the loss is 0.011718209832906723\n",
      "after 1217 traning the loss is 0.014272194355726242\n",
      "after 1218 traning the loss is 0.032526273280382156\n",
      "after 1219 traning the loss is 0.07768747210502625\n",
      "after 1220 traning the loss is 0.02673441171646118\n",
      "after 1221 traning the loss is 0.0844482034444809\n",
      "after 1222 traning the loss is 0.03934475779533386\n",
      "after 1223 traning the loss is 0.01110074482858181\n",
      "after 1224 traning the loss is 0.017120584845542908\n",
      "after 1225 traning the loss is 0.05743584409356117\n",
      "after 1226 traning the loss is 0.014014814980328083\n",
      "after 1227 traning the loss is 0.0344579853117466\n",
      "after 1228 traning the loss is 0.03757888078689575\n",
      "after 1229 traning the loss is 0.012075169011950493\n",
      "after 1230 traning the loss is 0.014969042502343655\n",
      "after 1231 traning the loss is 0.01676008477807045\n",
      "after 1232 traning the loss is 0.014230994507670403\n",
      "after 1233 traning the loss is 0.022598356008529663\n",
      "after 1234 traning the loss is 0.00632436852902174\n",
      "after 1235 traning the loss is 0.007991839200258255\n",
      "after 1236 traning the loss is 0.01852383464574814\n",
      "after 1237 traning the loss is 0.011425027623772621\n",
      "after 1238 traning the loss is 0.021858330816030502\n",
      "after 1239 traning the loss is 0.012136741541326046\n",
      "after 1240 traning the loss is 0.06349276751279831\n",
      "after 1241 traning the loss is 0.020210571587085724\n",
      "after 1242 traning the loss is 0.004485972225666046\n",
      "after 1243 traning the loss is 0.03974379971623421\n",
      "after 1244 traning the loss is 0.004990231711417437\n",
      "after 1245 traning the loss is 0.042888328433036804\n",
      "after 1246 traning the loss is 0.0077462028712034225\n",
      "after 1247 traning the loss is 0.011095644906163216\n",
      "after 1248 traning the loss is 0.016543366014957428\n",
      "after 1249 traning the loss is 0.031259555369615555\n",
      "after 1250 traning the loss is 0.008716020733118057\n",
      "after 1251 traning the loss is 0.1032174676656723\n",
      "after 1252 traning the loss is 0.021068084985017776\n",
      "after 1253 traning the loss is 0.09286953508853912\n",
      "after 1254 traning the loss is 0.020570948719978333\n",
      "after 1255 traning the loss is 0.005458872765302658\n",
      "after 1256 traning the loss is 0.0320698544383049\n",
      "after 1257 traning the loss is 0.016743116080760956\n",
      "after 1258 traning the loss is 0.05528867989778519\n",
      "after 1259 traning the loss is 0.054402031004428864\n",
      "after 1260 traning the loss is 0.015696145594120026\n",
      "after 1261 traning the loss is 0.060390688478946686\n",
      "after 1262 traning the loss is 0.012593034654855728\n",
      "after 1263 traning the loss is 0.08059577643871307\n",
      "after 1264 traning the loss is 0.028071822598576546\n",
      "after 1265 traning the loss is 0.004586078692227602\n",
      "after 1266 traning the loss is 0.011581428349018097\n",
      "after 1267 traning the loss is 0.0151558518409729\n",
      "after 1268 traning the loss is 0.07586093246936798\n",
      "after 1269 traning the loss is 0.006268023978918791\n",
      "after 1270 traning the loss is 0.012350009754300117\n",
      "after 1271 traning the loss is 0.09346698969602585\n",
      "after 1272 traning the loss is 0.01582340896129608\n",
      "after 1273 traning the loss is 0.08136329054832458\n",
      "after 1274 traning the loss is 0.11474397033452988\n",
      "after 1275 traning the loss is 0.006416995543986559\n",
      "after 1276 traning the loss is 0.02171238698065281\n",
      "after 1277 traning the loss is 0.08080029487609863\n",
      "after 1278 traning the loss is 0.010626416653394699\n",
      "after 1279 traning the loss is 0.041794706135988235\n",
      "after 1280 traning the loss is 0.04471518099308014\n",
      "after 1281 traning the loss is 0.021580426022410393\n",
      "after 1282 traning the loss is 0.020530566573143005\n",
      "after 1283 traning the loss is 0.010278374888002872\n",
      "after 1284 traning the loss is 0.01070350594818592\n",
      "after 1285 traning the loss is 0.003916433546692133\n",
      "after 1286 traning the loss is 0.04736092686653137\n",
      "after 1287 traning the loss is 0.017239851877093315\n",
      "after 1288 traning the loss is 0.02230423502624035\n",
      "after 1289 traning the loss is 0.006285780109465122\n",
      "after 1290 traning the loss is 0.012642400339245796\n",
      "after 1291 traning the loss is 0.017506714910268784\n",
      "after 1292 traning the loss is 0.018974807113409042\n",
      "after 1293 traning the loss is 0.005545858759433031\n",
      "after 1294 traning the loss is 0.0157456137239933\n",
      "after 1295 traning the loss is 0.011732225306332111\n",
      "after 1296 traning the loss is 0.03189709410071373\n",
      "after 1297 traning the loss is 0.023937128484249115\n",
      "after 1298 traning the loss is 0.014234622940421104\n",
      "after 1299 traning the loss is 0.015641752630472183\n",
      "after 1300 traning the loss is 0.06236207112669945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1301 traning the loss is 0.052433401346206665\n",
      "after 1302 traning the loss is 0.004357084631919861\n",
      "after 1303 traning the loss is 0.036321885883808136\n",
      "after 1304 traning the loss is 0.06457405537366867\n",
      "after 1305 traning the loss is 0.025661852210760117\n",
      "after 1306 traning the loss is 0.01684282347559929\n",
      "after 1307 traning the loss is 0.013982689939439297\n",
      "after 1308 traning the loss is 0.07356075197458267\n",
      "after 1309 traning the loss is 0.005467669107019901\n",
      "after 1310 traning the loss is 0.009789071045815945\n",
      "after 1311 traning the loss is 0.005876882001757622\n",
      "after 1312 traning the loss is 0.008113812655210495\n",
      "after 1313 traning the loss is 0.09054844081401825\n",
      "after 1314 traning the loss is 0.01312886830419302\n",
      "after 1315 traning the loss is 0.006441938225179911\n",
      "after 1316 traning the loss is 0.005079516675323248\n",
      "after 1317 traning the loss is 0.004563216120004654\n",
      "after 1318 traning the loss is 0.025204095989465714\n",
      "after 1319 traning the loss is 0.007641228847205639\n",
      "after 1320 traning the loss is 0.10036525130271912\n",
      "after 1321 traning the loss is 0.005603653844445944\n",
      "after 1322 traning the loss is 0.016719717532396317\n",
      "after 1323 traning the loss is 0.04046785086393356\n",
      "after 1324 traning the loss is 0.017896359786391258\n",
      "after 1325 traning the loss is 0.004574792459607124\n",
      "after 1326 traning the loss is 0.06923027336597443\n",
      "after 1327 traning the loss is 0.07940288633108139\n",
      "after 1328 traning the loss is 0.020190205425024033\n",
      "after 1329 traning the loss is 0.06167227774858475\n",
      "after 1330 traning the loss is 0.009281076490879059\n",
      "after 1331 traning the loss is 0.06180974841117859\n",
      "after 1332 traning the loss is 0.01745358482003212\n",
      "after 1333 traning the loss is 0.006792761385440826\n",
      "after 1334 traning the loss is 0.017181435599923134\n",
      "after 1335 traning the loss is 0.06046121567487717\n",
      "after 1336 traning the loss is 0.018133535981178284\n",
      "after 1337 traning the loss is 0.014051483012735844\n",
      "after 1338 traning the loss is 0.008307158015668392\n",
      "after 1339 traning the loss is 0.06482516974210739\n",
      "after 1340 traning the loss is 0.033178675919771194\n",
      "after 1341 traning the loss is 0.009613321162760258\n",
      "after 1342 traning the loss is 0.022534111514687538\n",
      "after 1343 traning the loss is 0.01796380802989006\n",
      "after 1344 traning the loss is 0.02196204476058483\n",
      "after 1345 traning the loss is 0.008043227717280388\n",
      "after 1346 traning the loss is 0.016092371195554733\n",
      "after 1347 traning the loss is 0.01075109001249075\n",
      "after 1348 traning the loss is 0.01306325476616621\n",
      "after 1349 traning the loss is 0.0706903263926506\n",
      "after 1350 traning the loss is 0.05420096218585968\n",
      "after 1351 traning the loss is 0.00826361682265997\n",
      "after 1352 traning the loss is 0.0036806077696383\n",
      "after 1353 traning the loss is 0.00623612105846405\n",
      "after 1354 traning the loss is 0.0077841440215706825\n",
      "after 1355 traning the loss is 0.01162794977426529\n",
      "after 1356 traning the loss is 0.00580223323777318\n",
      "after 1357 traning the loss is 0.010894929990172386\n",
      "after 1358 traning the loss is 0.007271456532180309\n",
      "after 1359 traning the loss is 0.011642878875136375\n",
      "after 1360 traning the loss is 0.10353328287601471\n",
      "after 1361 traning the loss is 0.02030341885983944\n",
      "after 1362 traning the loss is 0.022945338860154152\n",
      "after 1363 traning the loss is 0.01900479570031166\n",
      "after 1364 traning the loss is 0.07105346769094467\n",
      "after 1365 traning the loss is 0.0051809982396662235\n",
      "after 1366 traning the loss is 0.006724127568304539\n",
      "after 1367 traning the loss is 0.007844056002795696\n",
      "after 1368 traning the loss is 0.006025343202054501\n",
      "after 1369 traning the loss is 0.10666114091873169\n",
      "after 1370 traning the loss is 0.028847824782133102\n",
      "after 1371 traning the loss is 0.06684976816177368\n",
      "after 1372 traning the loss is 0.014283069409430027\n",
      "after 1373 traning the loss is 0.01123778335750103\n",
      "after 1374 traning the loss is 0.011196069419384003\n",
      "after 1375 traning the loss is 0.06299091130495071\n",
      "after 1376 traning the loss is 0.009535033255815506\n",
      "after 1377 traning the loss is 0.02614494599401951\n",
      "after 1378 traning the loss is 0.004725596867501736\n",
      "after 1379 traning the loss is 0.08889976888895035\n",
      "after 1380 traning the loss is 0.0476495660841465\n",
      "after 1381 traning the loss is 0.009585313498973846\n",
      "after 1382 traning the loss is 0.01995803415775299\n",
      "after 1383 traning the loss is 0.0040699029341340065\n",
      "after 1384 traning the loss is 0.012747591361403465\n",
      "after 1385 traning the loss is 0.012516092509031296\n",
      "after 1386 traning the loss is 0.00966552458703518\n",
      "after 1387 traning the loss is 0.01216064766049385\n",
      "after 1388 traning the loss is 0.01717786118388176\n",
      "after 1389 traning the loss is 0.025457704439759254\n",
      "after 1390 traning the loss is 0.011375206522643566\n",
      "after 1391 traning the loss is 0.0032742926850914955\n",
      "after 1392 traning the loss is 0.009426696226000786\n",
      "after 1393 traning the loss is 0.0044590989127755165\n",
      "after 1394 traning the loss is 0.023257803171873093\n",
      "after 1395 traning the loss is 0.06265869736671448\n",
      "after 1396 traning the loss is 0.007407439406961203\n",
      "after 1397 traning the loss is 0.0071398536674678326\n",
      "after 1398 traning the loss is 0.024537738412618637\n",
      "after 1399 traning the loss is 0.008095569908618927\n",
      "after 1400 traning the loss is 0.005571507848799229\n",
      "after 1401 traning the loss is 0.007937565445899963\n",
      "after 1402 traning the loss is 0.004082054365426302\n",
      "after 1403 traning the loss is 0.037598226219415665\n",
      "after 1404 traning the loss is 0.005873760208487511\n",
      "after 1405 traning the loss is 0.004543988034129143\n",
      "after 1406 traning the loss is 0.003855312243103981\n",
      "after 1407 traning the loss is 0.009168652817606926\n",
      "after 1408 traning the loss is 0.0063564712181687355\n",
      "after 1409 traning the loss is 0.01211819052696228\n",
      "after 1410 traning the loss is 0.00863737240433693\n",
      "after 1411 traning the loss is 0.022632062435150146\n",
      "after 1412 traning the loss is 0.006572007201611996\n",
      "after 1413 traning the loss is 0.008985049091279507\n",
      "after 1414 traning the loss is 0.006605159491300583\n",
      "after 1415 traning the loss is 0.005111637059599161\n",
      "after 1416 traning the loss is 0.00648106262087822\n",
      "after 1417 traning the loss is 0.009742816910147667\n",
      "after 1418 traning the loss is 0.007035171613097191\n",
      "after 1419 traning the loss is 0.05792422965168953\n",
      "after 1420 traning the loss is 0.0069864774122834206\n",
      "after 1421 traning the loss is 0.0043875714763998985\n",
      "after 1422 traning the loss is 0.01081771869212389\n",
      "after 1423 traning the loss is 0.014498196542263031\n",
      "after 1424 traning the loss is 0.011158840730786324\n",
      "after 1425 traning the loss is 0.004350622184574604\n",
      "after 1426 traning the loss is 0.06582832336425781\n",
      "after 1427 traning the loss is 0.02136591635644436\n",
      "after 1428 traning the loss is 0.0046010324731469154\n",
      "after 1429 traning the loss is 0.052832044661045074\n",
      "after 1430 traning the loss is 0.008463142439723015\n",
      "after 1431 traning the loss is 0.017319833859801292\n",
      "after 1432 traning the loss is 0.009279807098209858\n",
      "after 1433 traning the loss is 0.016095919534564018\n",
      "after 1434 traning the loss is 0.00749894930049777\n",
      "after 1435 traning the loss is 0.006239748559892178\n",
      "after 1436 traning the loss is 0.004084411542862654\n",
      "after 1437 traning the loss is 0.005418865010142326\n",
      "after 1438 traning the loss is 0.010749580338597298\n",
      "after 1439 traning the loss is 0.010237213224172592\n",
      "after 1440 traning the loss is 0.004287684801965952\n",
      "after 1441 traning the loss is 0.0046088253147900105\n",
      "after 1442 traning the loss is 0.016505975276231766\n",
      "after 1443 traning the loss is 0.0070407455787062645\n",
      "after 1444 traning the loss is 0.0338137224316597\n",
      "after 1445 traning the loss is 0.022109031677246094\n",
      "after 1446 traning the loss is 0.008470559492707253\n",
      "after 1447 traning the loss is 0.062236957252025604\n",
      "after 1448 traning the loss is 0.007843861356377602\n",
      "after 1449 traning the loss is 0.006038450635969639\n",
      "after 1450 traning the loss is 0.00802230928093195\n",
      "after 1451 traning the loss is 0.07380997389554977\n",
      "after 1452 traning the loss is 0.013266160152852535\n",
      "after 1453 traning the loss is 0.005389824043959379\n",
      "after 1454 traning the loss is 0.005789278075098991\n",
      "after 1455 traning the loss is 0.007690056227147579\n",
      "after 1456 traning the loss is 0.07659021764993668\n",
      "after 1457 traning the loss is 0.02991132065653801\n",
      "after 1458 traning the loss is 0.01678423397243023\n",
      "after 1459 traning the loss is 0.02915753796696663\n",
      "after 1460 traning the loss is 0.004347409587353468\n",
      "after 1461 traning the loss is 0.014410752803087234\n",
      "after 1462 traning the loss is 0.002955521224066615\n",
      "after 1463 traning the loss is 0.0025575398467481136\n",
      "after 1464 traning the loss is 0.013828190043568611\n",
      "after 1465 traning the loss is 0.002573528327047825\n",
      "after 1466 traning the loss is 0.008404649794101715\n",
      "after 1467 traning the loss is 0.0027312333695590496\n",
      "after 1468 traning the loss is 0.005590536631643772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1469 traning the loss is 0.013803716748952866\n",
      "after 1470 traning the loss is 0.003242005128413439\n",
      "after 1471 traning the loss is 0.008624810725450516\n",
      "after 1472 traning the loss is 0.013225777074694633\n",
      "after 1473 traning the loss is 0.08372534811496735\n",
      "after 1474 traning the loss is 0.00801757350564003\n",
      "after 1475 traning the loss is 0.04136915132403374\n",
      "after 1476 traning the loss is 0.008409046567976475\n",
      "after 1477 traning the loss is 0.008059268817305565\n",
      "after 1478 traning the loss is 0.004037326201796532\n",
      "after 1479 traning the loss is 0.04786469042301178\n",
      "after 1480 traning the loss is 0.006574586965143681\n",
      "after 1481 traning the loss is 0.012346138246357441\n",
      "after 1482 traning the loss is 0.020176513120532036\n",
      "after 1483 traning the loss is 0.041952475905418396\n",
      "after 1484 traning the loss is 0.008038213476538658\n",
      "after 1485 traning the loss is 0.0061230529099702835\n",
      "after 1486 traning the loss is 0.002064034342765808\n",
      "after 1487 traning the loss is 0.08625553548336029\n",
      "after 1488 traning the loss is 0.0040914928540587425\n",
      "after 1489 traning the loss is 0.010629070922732353\n",
      "after 1490 traning the loss is 0.017917145043611526\n",
      "after 1491 traning the loss is 0.013442641124129295\n",
      "after 1492 traning the loss is 0.0046195825561881065\n",
      "after 1493 traning the loss is 0.010701347142457962\n",
      "after 1494 traning the loss is 0.020312463864684105\n",
      "after 1495 traning the loss is 0.005078530870378017\n",
      "after 1496 traning the loss is 0.005361370742321014\n",
      "after 1497 traning the loss is 0.004126053303480148\n",
      "after 1498 traning the loss is 0.004826655611395836\n",
      "after 1499 traning the loss is 0.11199906468391418\n",
      "after 1500 traning the loss is 0.01134120300412178\n",
      "after 1501 traning the loss is 0.004899654071778059\n",
      "after 1502 traning the loss is 0.02388567477464676\n",
      "after 1503 traning the loss is 0.05213017761707306\n",
      "after 1504 traning the loss is 0.006540833041071892\n",
      "after 1505 traning the loss is 0.00968296267092228\n",
      "after 1506 traning the loss is 0.022658297792077065\n",
      "after 1507 traning the loss is 0.0578707680106163\n",
      "after 1508 traning the loss is 0.02390442043542862\n",
      "after 1509 traning the loss is 0.00706443702802062\n",
      "after 1510 traning the loss is 0.006879173219203949\n",
      "after 1511 traning the loss is 0.007540605030953884\n",
      "after 1512 traning the loss is 0.032704658806324005\n",
      "after 1513 traning the loss is 0.025668581947684288\n",
      "after 1514 traning the loss is 0.0768134593963623\n",
      "after 1515 traning the loss is 0.07171779870986938\n",
      "after 1516 traning the loss is 0.003484634216874838\n",
      "after 1517 traning the loss is 0.011447378434240818\n",
      "after 1518 traning the loss is 0.012711962684988976\n",
      "after 1519 traning the loss is 0.0030191694386303425\n",
      "after 1520 traning the loss is 0.007218116894364357\n",
      "after 1521 traning the loss is 0.01391506101936102\n",
      "after 1522 traning the loss is 0.032137271016836166\n",
      "after 1523 traning the loss is 0.0025494657456874847\n",
      "after 1524 traning the loss is 0.004508041776716709\n",
      "after 1525 traning the loss is 0.011374899186193943\n",
      "after 1526 traning the loss is 0.0033528408966958523\n",
      "after 1527 traning the loss is 0.019058963283896446\n",
      "after 1528 traning the loss is 0.0048968177288770676\n",
      "after 1529 traning the loss is 0.004090247675776482\n",
      "after 1530 traning the loss is 0.0047269160859286785\n",
      "after 1531 traning the loss is 0.0036794187035411596\n",
      "after 1532 traning the loss is 0.007375024724751711\n",
      "after 1533 traning the loss is 0.0031768600456416607\n",
      "after 1534 traning the loss is 0.003297193208709359\n",
      "after 1535 traning the loss is 0.005235254764556885\n",
      "after 1536 traning the loss is 0.002456297166645527\n",
      "after 1537 traning the loss is 0.08348038792610168\n",
      "after 1538 traning the loss is 0.0036387790460139513\n",
      "after 1539 traning the loss is 0.01700560376048088\n",
      "after 1540 traning the loss is 0.09891624748706818\n",
      "after 1541 traning the loss is 0.060822922736406326\n",
      "after 1542 traning the loss is 0.003531678579747677\n",
      "after 1543 traning the loss is 0.0037428950890898705\n",
      "after 1544 traning the loss is 0.008129752241075039\n",
      "after 1545 traning the loss is 0.018887368962168694\n",
      "after 1546 traning the loss is 0.02938612550497055\n",
      "after 1547 traning the loss is 0.002492109779268503\n",
      "after 1548 traning the loss is 0.046130143105983734\n",
      "after 1549 traning the loss is 0.09063845872879028\n",
      "after 1550 traning the loss is 0.007914452813565731\n",
      "after 1551 traning the loss is 0.0027779461815953255\n",
      "after 1552 traning the loss is 0.034240417182445526\n",
      "after 1553 traning the loss is 0.007786094676703215\n",
      "after 1554 traning the loss is 0.10122063010931015\n",
      "after 1555 traning the loss is 0.0029509910382330418\n",
      "after 1556 traning the loss is 0.03176316246390343\n",
      "after 1557 traning the loss is 0.0035416819155216217\n",
      "after 1558 traning the loss is 0.003555544186383486\n",
      "after 1559 traning the loss is 0.011675411835312843\n",
      "after 1560 traning the loss is 0.004755704663693905\n",
      "after 1561 traning the loss is 0.027103658765554428\n",
      "after 1562 traning the loss is 0.004327844362705946\n",
      "after 1563 traning the loss is 0.005426429677754641\n",
      "after 1564 traning the loss is 0.003999464213848114\n",
      "after 1565 traning the loss is 0.003192934673279524\n",
      "after 1566 traning the loss is 0.032536596059799194\n",
      "after 1567 traning the loss is 0.011904105544090271\n",
      "after 1568 traning the loss is 0.011665073223412037\n",
      "after 1569 traning the loss is 0.0018523698672652245\n",
      "after 1570 traning the loss is 0.0068146828562021255\n",
      "after 1571 traning the loss is 0.011259132996201515\n",
      "after 1572 traning the loss is 0.0018482570303604007\n",
      "after 1573 traning the loss is 0.002122378209605813\n",
      "after 1574 traning the loss is 0.009857313707470894\n",
      "after 1575 traning the loss is 0.03487798944115639\n",
      "after 1576 traning the loss is 0.031865183264017105\n",
      "after 1577 traning the loss is 0.020519433543086052\n",
      "after 1578 traning the loss is 0.047393836081027985\n",
      "after 1579 traning the loss is 0.01776834949851036\n",
      "after 1580 traning the loss is 0.0062690433114767075\n",
      "after 1581 traning the loss is 0.015925677493214607\n",
      "after 1582 traning the loss is 0.008815212175250053\n",
      "after 1583 traning the loss is 0.04224067181348801\n",
      "after 1584 traning the loss is 0.0076459916308522224\n",
      "after 1585 traning the loss is 0.0023773396387696266\n",
      "after 1586 traning the loss is 0.003098183311522007\n",
      "after 1587 traning the loss is 0.0014660480665042996\n",
      "after 1588 traning the loss is 0.0018438375554978848\n",
      "after 1589 traning the loss is 0.006853487342596054\n",
      "after 1590 traning the loss is 0.0021721201483160257\n",
      "after 1591 traning the loss is 0.00915431883186102\n",
      "after 1592 traning the loss is 0.00215167342685163\n",
      "after 1593 traning the loss is 0.09913764894008636\n",
      "after 1594 traning the loss is 0.004661081358790398\n",
      "after 1595 traning the loss is 0.0025135588366538286\n",
      "after 1596 traning the loss is 0.0036746838595718145\n",
      "after 1597 traning the loss is 0.004957643803209066\n",
      "after 1598 traning the loss is 0.0037547703832387924\n",
      "after 1599 traning the loss is 0.004710996989160776\n",
      "after 1600 traning the loss is 0.005252059083431959\n",
      "after 1601 traning the loss is 0.010942675173282623\n",
      "after 1602 traning the loss is 0.011585459113121033\n",
      "after 1603 traning the loss is 0.001797536970116198\n",
      "after 1604 traning the loss is 0.0018807400483638048\n",
      "after 1605 traning the loss is 0.007896940223872662\n",
      "after 1606 traning the loss is 0.004341285675764084\n",
      "after 1607 traning the loss is 0.004749704618006945\n",
      "after 1608 traning the loss is 0.003969773184508085\n",
      "after 1609 traning the loss is 0.004404995124787092\n",
      "after 1610 traning the loss is 0.0354144461452961\n",
      "after 1611 traning the loss is 0.004799916874617338\n",
      "after 1612 traning the loss is 0.0276260394603014\n",
      "after 1613 traning the loss is 0.0019184501143172383\n",
      "after 1614 traning the loss is 0.026051372289657593\n",
      "after 1615 traning the loss is 0.018459750339388847\n",
      "after 1616 traning the loss is 0.006868601776659489\n",
      "after 1617 traning the loss is 0.002785344608128071\n",
      "after 1618 traning the loss is 0.009289316833019257\n",
      "after 1619 traning the loss is 0.04409118741750717\n",
      "after 1620 traning the loss is 0.014341581612825394\n",
      "after 1621 traning the loss is 0.00462921429425478\n",
      "after 1622 traning the loss is 0.06382875144481659\n",
      "after 1623 traning the loss is 0.010182357393205166\n",
      "after 1624 traning the loss is 0.0059875743463635445\n",
      "after 1625 traning the loss is 0.004090515431016684\n",
      "after 1626 traning the loss is 0.0021262916270643473\n",
      "after 1627 traning the loss is 0.002603225177153945\n",
      "after 1628 traning the loss is 0.01845870353281498\n",
      "after 1629 traning the loss is 0.005043519660830498\n",
      "after 1630 traning the loss is 0.0033183188643306494\n",
      "after 1631 traning the loss is 0.011557357385754585\n",
      "after 1632 traning the loss is 0.04122132435441017\n",
      "after 1633 traning the loss is 0.009261127561330795\n",
      "after 1634 traning the loss is 0.005854962393641472\n",
      "after 1635 traning the loss is 0.0020997088868170977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1636 traning the loss is 0.0040802545845508575\n",
      "after 1637 traning the loss is 0.07422708719968796\n",
      "after 1638 traning the loss is 0.002095217118039727\n",
      "after 1639 traning the loss is 0.0033535724505782127\n",
      "after 1640 traning the loss is 0.045644283294677734\n",
      "after 1641 traning the loss is 0.003095644060522318\n",
      "after 1642 traning the loss is 0.024659765884280205\n",
      "after 1643 traning the loss is 0.008503059856593609\n",
      "after 1644 traning the loss is 0.004620587453246117\n",
      "after 1645 traning the loss is 0.005562883801758289\n",
      "after 1646 traning the loss is 0.011229969561100006\n",
      "after 1647 traning the loss is 0.04591472074389458\n",
      "after 1648 traning the loss is 0.009449098259210587\n",
      "after 1649 traning the loss is 0.044463977217674255\n",
      "after 1650 traning the loss is 0.004264736548066139\n",
      "after 1651 traning the loss is 0.004294076468795538\n",
      "after 1652 traning the loss is 0.07582759112119675\n",
      "after 1653 traning the loss is 0.018887288868427277\n",
      "after 1654 traning the loss is 0.005742825102061033\n",
      "after 1655 traning the loss is 0.05188925191760063\n",
      "after 1656 traning the loss is 0.002767267869785428\n",
      "after 1657 traning the loss is 0.0012166589731350541\n",
      "after 1658 traning the loss is 0.002028997987508774\n",
      "after 1659 traning the loss is 0.0029278357978910208\n",
      "after 1660 traning the loss is 0.0015753486659377813\n",
      "after 1661 traning the loss is 0.001892640721052885\n",
      "after 1662 traning the loss is 0.012114492245018482\n",
      "after 1663 traning the loss is 0.04815605282783508\n",
      "after 1664 traning the loss is 0.007367048412561417\n",
      "after 1665 traning the loss is 0.006565444637089968\n",
      "after 1666 traning the loss is 0.004801998380571604\n",
      "after 1667 traning the loss is 0.005695926956832409\n",
      "after 1668 traning the loss is 0.0022035841830074787\n",
      "after 1669 traning the loss is 0.002640350488945842\n",
      "after 1670 traning the loss is 0.002762573305517435\n",
      "after 1671 traning the loss is 0.005233370698988438\n",
      "after 1672 traning the loss is 0.06567667424678802\n",
      "after 1673 traning the loss is 0.019066868349909782\n",
      "after 1674 traning the loss is 0.0066660987213253975\n",
      "after 1675 traning the loss is 0.003091407474130392\n",
      "after 1676 traning the loss is 0.019536715000867844\n",
      "after 1677 traning the loss is 0.030762996524572372\n",
      "after 1678 traning the loss is 0.00452551431953907\n",
      "after 1679 traning the loss is 0.011247726157307625\n",
      "after 1680 traning the loss is 0.018249453976750374\n",
      "after 1681 traning the loss is 0.002546170726418495\n",
      "after 1682 traning the loss is 0.022357037290930748\n",
      "after 1683 traning the loss is 0.0028288390021771193\n",
      "after 1684 traning the loss is 0.006951277144253254\n",
      "after 1685 traning the loss is 0.047281309962272644\n",
      "after 1686 traning the loss is 0.001738041639328003\n",
      "after 1687 traning the loss is 0.015358134172856808\n",
      "after 1688 traning the loss is 0.0019251704216003418\n",
      "after 1689 traning the loss is 0.01028823759406805\n",
      "after 1690 traning the loss is 0.010626603849232197\n",
      "after 1691 traning the loss is 0.010283291339874268\n",
      "after 1692 traning the loss is 0.018936537206172943\n",
      "after 1693 traning the loss is 0.004842345602810383\n",
      "after 1694 traning the loss is 0.000987876788713038\n",
      "after 1695 traning the loss is 0.0019047011155635118\n",
      "after 1696 traning the loss is 0.0056691281497478485\n",
      "after 1697 traning the loss is 0.0025272583588957787\n",
      "after 1698 traning the loss is 0.009239807724952698\n",
      "after 1699 traning the loss is 0.00410833302885294\n",
      "after 1700 traning the loss is 0.002688557608053088\n",
      "after 1701 traning the loss is 0.014718228951096535\n",
      "after 1702 traning the loss is 0.04400770738720894\n",
      "after 1703 traning the loss is 0.0032891621813178062\n",
      "after 1704 traning the loss is 0.006462956313043833\n",
      "after 1705 traning the loss is 0.0021071399096399546\n",
      "after 1706 traning the loss is 0.004746623802930117\n",
      "after 1707 traning the loss is 0.0023205161560326815\n",
      "after 1708 traning the loss is 0.06348546594381332\n",
      "after 1709 traning the loss is 0.03602110594511032\n",
      "after 1710 traning the loss is 0.0028392206877470016\n",
      "after 1711 traning the loss is 0.014985381625592709\n",
      "after 1712 traning the loss is 0.0043436745181679726\n",
      "after 1713 traning the loss is 0.003177837934345007\n",
      "after 1714 traning the loss is 0.0018008498009294271\n",
      "after 1715 traning the loss is 0.009653478860855103\n",
      "after 1716 traning the loss is 0.00500138197094202\n",
      "after 1717 traning the loss is 0.0027896566316485405\n",
      "after 1718 traning the loss is 0.0019547631964087486\n",
      "after 1719 traning the loss is 0.0030906544998288155\n",
      "after 1720 traning the loss is 0.0019235019572079182\n",
      "after 1721 traning the loss is 0.0023500663228332996\n",
      "after 1722 traning the loss is 0.0056656356900930405\n",
      "after 1723 traning the loss is 0.0014103685971349478\n",
      "after 1724 traning the loss is 0.0051196240819990635\n",
      "after 1725 traning the loss is 0.001210580812767148\n",
      "after 1726 traning the loss is 0.012868724763393402\n",
      "after 1727 traning the loss is 0.04777650162577629\n",
      "after 1728 traning the loss is 0.007559685036540031\n",
      "after 1729 traning the loss is 0.0018374482169747353\n",
      "after 1730 traning the loss is 0.0015960149466991425\n",
      "after 1731 traning the loss is 0.001407179282978177\n",
      "after 1732 traning the loss is 0.0016549667343497276\n",
      "after 1733 traning the loss is 0.014265991747379303\n",
      "after 1734 traning the loss is 0.003013725159689784\n",
      "after 1735 traning the loss is 0.006789832375943661\n",
      "after 1736 traning the loss is 0.006116565782576799\n",
      "after 1737 traning the loss is 0.0020466968417167664\n",
      "after 1738 traning the loss is 0.009088300168514252\n",
      "after 1739 traning the loss is 0.0026653956156224012\n",
      "after 1740 traning the loss is 0.004603191278874874\n",
      "after 1741 traning the loss is 0.07300199568271637\n",
      "after 1742 traning the loss is 0.004184534307569265\n",
      "after 1743 traning the loss is 0.0017261499306187034\n",
      "after 1744 traning the loss is 0.0027708611451089382\n",
      "after 1745 traning the loss is 0.0049080029129981995\n",
      "after 1746 traning the loss is 0.0029673627577722073\n",
      "after 1747 traning the loss is 0.03215412795543671\n",
      "after 1748 traning the loss is 0.00997188314795494\n",
      "after 1749 traning the loss is 0.016325144097208977\n",
      "after 1750 traning the loss is 0.003368029836565256\n",
      "after 1751 traning the loss is 0.04845474287867546\n",
      "after 1752 traning the loss is 0.00882139801979065\n",
      "after 1753 traning the loss is 0.03759169206023216\n",
      "after 1754 traning the loss is 0.0017474946798756719\n",
      "after 1755 traning the loss is 0.0010854476131498814\n",
      "after 1756 traning the loss is 0.0010252177016809583\n",
      "after 1757 traning the loss is 0.004256551153957844\n",
      "after 1758 traning the loss is 0.010699458420276642\n",
      "after 1759 traning the loss is 0.0276027861982584\n",
      "after 1760 traning the loss is 0.0036623505875468254\n",
      "after 1761 traning the loss is 0.1470552235841751\n",
      "after 1762 traning the loss is 0.003670475212857127\n",
      "after 1763 traning the loss is 0.004849170800298452\n",
      "after 1764 traning the loss is 0.005197769030928612\n",
      "after 1765 traning the loss is 0.06588363647460938\n",
      "after 1766 traning the loss is 0.0034570484422147274\n",
      "after 1767 traning the loss is 0.061274830251932144\n",
      "after 1768 traning the loss is 0.004897547420114279\n",
      "after 1769 traning the loss is 0.0009548616944812238\n",
      "after 1770 traning the loss is 0.0018835831433534622\n",
      "after 1771 traning the loss is 0.001020342344418168\n",
      "after 1772 traning the loss is 0.0063897292129695415\n",
      "after 1773 traning the loss is 0.005429144948720932\n",
      "after 1774 traning the loss is 0.007161121815443039\n",
      "after 1775 traning the loss is 0.0011039383243769407\n",
      "after 1776 traning the loss is 0.03178698197007179\n",
      "after 1777 traning the loss is 0.00362545158714056\n",
      "after 1778 traning the loss is 0.0016869953833520412\n",
      "after 1779 traning the loss is 0.003279660828411579\n",
      "after 1780 traning the loss is 0.002903550863265991\n",
      "after 1781 traning the loss is 0.0030387365259230137\n",
      "after 1782 traning the loss is 0.0032470556907355785\n",
      "after 1783 traning the loss is 0.007530985865741968\n",
      "after 1784 traning the loss is 0.0009927238570526242\n",
      "after 1785 traning the loss is 0.001318728318437934\n",
      "after 1786 traning the loss is 0.003743672976270318\n",
      "after 1787 traning the loss is 0.048884473741054535\n",
      "after 1788 traning the loss is 0.001610303996130824\n",
      "after 1789 traning the loss is 0.0767645612359047\n",
      "after 1790 traning the loss is 0.005961306393146515\n",
      "after 1791 traning the loss is 0.001723838271573186\n",
      "after 1792 traning the loss is 0.004180266056209803\n",
      "after 1793 traning the loss is 0.0033165072090923786\n",
      "after 1794 traning the loss is 0.000946005224250257\n",
      "after 1795 traning the loss is 0.007435855455696583\n",
      "after 1796 traning the loss is 0.0030841936822980642\n",
      "after 1797 traning the loss is 0.005884440615773201\n",
      "after 1798 traning the loss is 0.0019763296004384756\n",
      "after 1799 traning the loss is 0.04608549177646637\n",
      "after 1800 traning the loss is 0.01895042508840561\n",
      "after 1801 traning the loss is 0.002913079224526882\n",
      "after 1802 traning the loss is 0.06351407617330551\n",
      "after 1803 traning the loss is 0.004084721207618713\n",
      "after 1804 traning the loss is 0.039708469063043594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1805 traning the loss is 0.03282187134027481\n",
      "after 1806 traning the loss is 0.004241220187395811\n",
      "after 1807 traning the loss is 0.0033600577153265476\n",
      "after 1808 traning the loss is 0.01854385994374752\n",
      "after 1809 traning the loss is 0.004866030067205429\n",
      "after 1810 traning the loss is 0.002449215389788151\n",
      "after 1811 traning the loss is 0.010674693621695042\n",
      "after 1812 traning the loss is 0.05562600493431091\n",
      "after 1813 traning the loss is 0.002333373064175248\n",
      "after 1814 traning the loss is 0.01700427010655403\n",
      "after 1815 traning the loss is 0.008980746380984783\n",
      "after 1816 traning the loss is 0.007885006256401539\n",
      "after 1817 traning the loss is 0.00884985364973545\n",
      "after 1818 traning the loss is 0.053661148995161057\n",
      "after 1819 traning the loss is 0.002903761574998498\n",
      "after 1820 traning the loss is 0.0027912419755011797\n",
      "after 1821 traning the loss is 0.007084941025823355\n",
      "after 1822 traning the loss is 0.022066030651330948\n",
      "after 1823 traning the loss is 0.004858997650444508\n",
      "after 1824 traning the loss is 0.02757577784359455\n",
      "after 1825 traning the loss is 0.0011328072287142277\n",
      "after 1826 traning the loss is 0.0011904470156878233\n",
      "after 1827 traning the loss is 0.0030860661063343287\n",
      "after 1828 traning the loss is 0.0015449650818482041\n",
      "after 1829 traning the loss is 0.07269347459077835\n",
      "after 1830 traning the loss is 0.09771725535392761\n",
      "after 1831 traning the loss is 0.0061770249158144\n",
      "after 1832 traning the loss is 0.009302235208451748\n",
      "after 1833 traning the loss is 0.047393325716257095\n",
      "after 1834 traning the loss is 0.0042906953021883965\n",
      "after 1835 traning the loss is 0.007070630788803101\n",
      "after 1836 traning the loss is 0.0273720845580101\n",
      "after 1837 traning the loss is 0.009784188121557236\n",
      "after 1838 traning the loss is 0.0046607134863734245\n",
      "after 1839 traning the loss is 0.002849701326340437\n",
      "after 1840 traning the loss is 0.002370506525039673\n",
      "after 1841 traning the loss is 0.12219022214412689\n",
      "after 1842 traning the loss is 0.0016486805398017168\n",
      "after 1843 traning the loss is 0.006266596261411905\n",
      "after 1844 traning the loss is 0.0028789122588932514\n",
      "after 1845 traning the loss is 0.012639476917684078\n",
      "after 1846 traning the loss is 0.0017892135074362159\n",
      "after 1847 traning the loss is 0.018637273460626602\n",
      "after 1848 traning the loss is 0.0017296376172453165\n",
      "after 1849 traning the loss is 0.0010777335846796632\n",
      "after 1850 traning the loss is 0.006028030999004841\n",
      "after 1851 traning the loss is 0.003667720127850771\n",
      "after 1852 traning the loss is 0.0011627874337136745\n",
      "after 1853 traning the loss is 0.0016741907456889749\n",
      "after 1854 traning the loss is 0.01212235540151596\n",
      "after 1855 traning the loss is 0.003067453857511282\n",
      "after 1856 traning the loss is 0.054608821868896484\n",
      "after 1857 traning the loss is 0.05077105388045311\n",
      "after 1858 traning the loss is 0.00460679130628705\n",
      "after 1859 traning the loss is 0.002359716221690178\n",
      "after 1860 traning the loss is 0.002790073398500681\n",
      "after 1861 traning the loss is 0.005354991648346186\n",
      "after 1862 traning the loss is 0.11262092739343643\n",
      "after 1863 traning the loss is 0.01856091618537903\n",
      "after 1864 traning the loss is 0.006896081380546093\n",
      "after 1865 traning the loss is 0.029867010191082954\n",
      "after 1866 traning the loss is 0.013893772847950459\n",
      "after 1867 traning the loss is 0.002889263676479459\n",
      "after 1868 traning the loss is 0.002902011154219508\n",
      "after 1869 traning the loss is 0.0030711456201970577\n",
      "after 1870 traning the loss is 0.0017456860514357686\n",
      "after 1871 traning the loss is 0.03392497077584267\n",
      "after 1872 traning the loss is 0.035851042717695236\n",
      "after 1873 traning the loss is 0.008842998184263706\n",
      "after 1874 traning the loss is 0.002846480580046773\n",
      "after 1875 traning the loss is 0.003703376743942499\n",
      "after 1876 traning the loss is 0.01240023784339428\n",
      "after 1877 traning the loss is 0.004538132343441248\n",
      "after 1878 traning the loss is 0.016161980107426643\n",
      "after 1879 traning the loss is 0.002267009112983942\n",
      "after 1880 traning the loss is 0.0016631614416837692\n",
      "after 1881 traning the loss is 0.0023679479490965605\n",
      "after 1882 traning the loss is 0.0016042070928961039\n",
      "after 1883 traning the loss is 0.04212728887796402\n",
      "after 1884 traning the loss is 0.021911652758717537\n",
      "after 1885 traning the loss is 0.0028694840148091316\n",
      "after 1886 traning the loss is 0.00439867377281189\n",
      "after 1887 traning the loss is 0.006864163093268871\n",
      "after 1888 traning the loss is 0.07472740113735199\n",
      "after 1889 traning the loss is 0.005947324447333813\n",
      "after 1890 traning the loss is 0.003177745034918189\n",
      "after 1891 traning the loss is 0.0031269234605133533\n",
      "after 1892 traning the loss is 0.008328069932758808\n",
      "after 1893 traning the loss is 0.0025896597653627396\n",
      "after 1894 traning the loss is 0.0781010240316391\n",
      "after 1895 traning the loss is 0.0029663853347301483\n",
      "after 1896 traning the loss is 0.0013710996136069298\n",
      "after 1897 traning the loss is 0.012998235411942005\n",
      "after 1898 traning the loss is 0.0027983826585114002\n",
      "after 1899 traning the loss is 0.0038247168995440006\n",
      "after 1900 traning the loss is 0.005212839692831039\n",
      "after 1901 traning the loss is 0.001744778361171484\n",
      "after 1902 traning the loss is 0.002540767891332507\n",
      "after 1903 traning the loss is 0.024043383076786995\n",
      "after 1904 traning the loss is 0.0015204199589788914\n",
      "after 1905 traning the loss is 0.0025243801064789295\n",
      "after 1906 traning the loss is 0.007548635825514793\n",
      "after 1907 traning the loss is 0.002902694046497345\n",
      "after 1908 traning the loss is 0.002112698508426547\n",
      "after 1909 traning the loss is 0.0025203265249729156\n",
      "after 1910 traning the loss is 0.008579245768487453\n",
      "after 1911 traning the loss is 0.00444616237655282\n",
      "after 1912 traning the loss is 0.004122099839150906\n",
      "after 1913 traning the loss is 0.014229141175746918\n",
      "after 1914 traning the loss is 0.006029630545526743\n",
      "after 1915 traning the loss is 0.0033664824441075325\n",
      "after 1916 traning the loss is 0.002010923344641924\n",
      "after 1917 traning the loss is 0.002218076027929783\n",
      "after 1918 traning the loss is 0.003337225178256631\n",
      "after 1919 traning the loss is 0.0010012894636020064\n",
      "after 1920 traning the loss is 0.00262535666115582\n",
      "after 1921 traning the loss is 0.03653005510568619\n",
      "after 1922 traning the loss is 0.0008095783414319158\n",
      "after 1923 traning the loss is 0.0013207359006628394\n",
      "after 1924 traning the loss is 0.0034615849144756794\n",
      "after 1925 traning the loss is 0.004927216097712517\n",
      "after 1926 traning the loss is 0.01793338917195797\n",
      "after 1927 traning the loss is 0.0025922772474586964\n",
      "after 1928 traning the loss is 0.02146349474787712\n",
      "after 1929 traning the loss is 0.00801877025514841\n",
      "after 1930 traning the loss is 0.00188224739395082\n",
      "after 1931 traning the loss is 0.036004018038511276\n",
      "after 1932 traning the loss is 0.035127148032188416\n",
      "after 1933 traning the loss is 0.0029116710647940636\n",
      "after 1934 traning the loss is 0.010126695036888123\n",
      "after 1935 traning the loss is 0.006782406009733677\n",
      "after 1936 traning the loss is 0.0032023864332586527\n",
      "after 1937 traning the loss is 0.0027218731120228767\n",
      "after 1938 traning the loss is 0.003214108757674694\n",
      "after 1939 traning the loss is 0.005050524603575468\n",
      "after 1940 traning the loss is 0.0748511329293251\n",
      "after 1941 traning the loss is 0.005884723737835884\n",
      "after 1942 traning the loss is 0.0008650655508972704\n",
      "after 1943 traning the loss is 0.0013334940886124969\n",
      "after 1944 traning the loss is 0.014930392615497112\n",
      "after 1945 traning the loss is 0.0010028171818703413\n",
      "after 1946 traning the loss is 0.0028841858729720116\n",
      "after 1947 traning the loss is 0.0025920309126377106\n",
      "after 1948 traning the loss is 0.002234218642115593\n",
      "after 1949 traning the loss is 0.004154519643634558\n",
      "after 1950 traning the loss is 0.004617351107299328\n",
      "after 1951 traning the loss is 0.000709077634382993\n",
      "after 1952 traning the loss is 0.0037064470816403627\n",
      "after 1953 traning the loss is 0.005768784787505865\n",
      "after 1954 traning the loss is 0.002722053788602352\n",
      "after 1955 traning the loss is 0.0029323548078536987\n",
      "after 1956 traning the loss is 0.012448837980628014\n",
      "after 1957 traning the loss is 0.0010572461178526282\n",
      "after 1958 traning the loss is 0.004625704605132341\n",
      "after 1959 traning the loss is 0.0021753967739641666\n",
      "after 1960 traning the loss is 0.0318070724606514\n",
      "after 1961 traning the loss is 0.0012427327455952764\n",
      "after 1962 traning the loss is 0.0033465796150267124\n",
      "after 1963 traning the loss is 0.002142362529411912\n",
      "after 1964 traning the loss is 0.003266685176640749\n",
      "after 1965 traning the loss is 0.002524140290915966\n",
      "after 1966 traning the loss is 0.0022623154800385237\n",
      "after 1967 traning the loss is 0.003345703473314643\n",
      "after 1968 traning the loss is 0.06661205738782883\n",
      "after 1969 traning the loss is 0.0037154594901949167\n",
      "after 1970 traning the loss is 0.004188145510852337\n",
      "after 1971 traning the loss is 0.005430464632809162\n",
      "after 1972 traning the loss is 0.026966333389282227\n",
      "after 1973 traning the loss is 0.00645561795681715\n",
      "after 1974 traning the loss is 0.02061665616929531\n",
      "after 1975 traning the loss is 0.0013442510971799493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1976 traning the loss is 0.001162274507805705\n",
      "after 1977 traning the loss is 0.06585368514060974\n",
      "after 1978 traning the loss is 0.0012229823041707277\n",
      "after 1979 traning the loss is 0.0028703731950372458\n",
      "after 1980 traning the loss is 0.0042979102581739426\n",
      "after 1981 traning the loss is 0.0027069919742643833\n",
      "after 1982 traning the loss is 0.08069252222776413\n",
      "after 1983 traning the loss is 0.0014685472706332803\n",
      "after 1984 traning the loss is 0.0040704854764044285\n",
      "after 1985 traning the loss is 0.0028766412287950516\n",
      "after 1986 traning the loss is 0.002320081926882267\n",
      "after 1987 traning the loss is 0.016545802354812622\n",
      "after 1988 traning the loss is 0.0025164196267724037\n",
      "after 1989 traning the loss is 0.0026614652015268803\n",
      "after 1990 traning the loss is 0.008034924045205116\n",
      "after 1991 traning the loss is 0.002475822577252984\n",
      "after 1992 traning the loss is 0.0025318774860352278\n",
      "after 1993 traning the loss is 0.024446561932563782\n",
      "after 1994 traning the loss is 0.0019496276509016752\n",
      "after 1995 traning the loss is 0.02188742533326149\n",
      "after 1996 traning the loss is 0.00936304870992899\n",
      "after 1997 traning the loss is 0.00529115367680788\n",
      "after 1998 traning the loss is 0.04018263518810272\n",
      "after 1999 traning the loss is 0.0012918839929625392\n",
      "after 2000 traning the loss is 0.034373167902231216\n",
      "after 2001 traning the loss is 0.0022286574821919203\n",
      "after 2002 traning the loss is 0.0011815991019830108\n",
      "after 2003 traning the loss is 0.005069384351372719\n",
      "after 2004 traning the loss is 0.019846756011247635\n",
      "after 2005 traning the loss is 0.0027176435105502605\n",
      "after 2006 traning the loss is 0.0010766577906906605\n",
      "after 2007 traning the loss is 0.09743686765432358\n",
      "after 2008 traning the loss is 0.0010845721699297428\n",
      "after 2009 traning the loss is 0.0021804114803671837\n",
      "after 2010 traning the loss is 0.019404828548431396\n",
      "after 2011 traning the loss is 0.005729790776968002\n",
      "after 2012 traning the loss is 0.04199739918112755\n",
      "after 2013 traning the loss is 0.0149319963529706\n",
      "after 2014 traning the loss is 0.05110268294811249\n",
      "after 2015 traning the loss is 0.0219283327460289\n",
      "after 2016 traning the loss is 0.00675239646807313\n",
      "after 2017 traning the loss is 0.016629323363304138\n",
      "after 2018 traning the loss is 0.010992374271154404\n",
      "after 2019 traning the loss is 0.004859846085309982\n",
      "after 2020 traning the loss is 0.004706174600869417\n",
      "after 2021 traning the loss is 0.02431231550872326\n",
      "after 2022 traning the loss is 0.008152494207024574\n",
      "after 2023 traning the loss is 0.003687904682010412\n",
      "after 2024 traning the loss is 0.17468878626823425\n",
      "after 2025 traning the loss is 0.0031344208400696516\n",
      "after 2026 traning the loss is 0.0024567521177232265\n",
      "after 2027 traning the loss is 0.0025620691012591124\n",
      "after 2028 traning the loss is 0.0017534856451675296\n",
      "after 2029 traning the loss is 0.0006103893392719328\n",
      "after 2030 traning the loss is 0.0029071439057588577\n",
      "after 2031 traning the loss is 0.025474799796938896\n",
      "after 2032 traning the loss is 0.012527569197118282\n",
      "after 2033 traning the loss is 0.0051247598603367805\n",
      "after 2034 traning the loss is 0.005288795102387667\n",
      "after 2035 traning the loss is 0.001391407917253673\n",
      "after 2036 traning the loss is 0.0026535289362072945\n",
      "after 2037 traning the loss is 0.00490659149363637\n",
      "after 2038 traning the loss is 0.013618635013699532\n",
      "after 2039 traning the loss is 0.004442786332219839\n",
      "after 2040 traning the loss is 0.001308509148657322\n",
      "after 2041 traning the loss is 0.0037471819669008255\n",
      "after 2042 traning the loss is 0.001180169521830976\n",
      "after 2043 traning the loss is 0.006536832079291344\n",
      "after 2044 traning the loss is 0.03597099706530571\n",
      "after 2045 traning the loss is 0.0019534574821591377\n",
      "after 2046 traning the loss is 0.0032318616285920143\n",
      "after 2047 traning the loss is 0.0028959426563233137\n",
      "after 2048 traning the loss is 0.0028593260794878006\n",
      "after 2049 traning the loss is 0.0011608945205807686\n",
      "after 2050 traning the loss is 0.002695889677852392\n",
      "after 2051 traning the loss is 0.0015495088882744312\n",
      "after 2052 traning the loss is 0.0009171298006549478\n",
      "after 2053 traning the loss is 0.03245552256703377\n",
      "after 2054 traning the loss is 0.001569052692502737\n",
      "after 2055 traning the loss is 0.004294207319617271\n",
      "after 2056 traning the loss is 0.0018276285845786333\n",
      "after 2057 traning the loss is 0.01020267978310585\n",
      "after 2058 traning the loss is 0.00411317078396678\n",
      "after 2059 traning the loss is 0.0013042989885434508\n",
      "after 2060 traning the loss is 0.0036108202766627073\n",
      "after 2061 traning the loss is 0.004280798137187958\n",
      "after 2062 traning the loss is 0.06542707234621048\n",
      "after 2063 traning the loss is 0.0019434327259659767\n",
      "after 2064 traning the loss is 0.00948867667466402\n",
      "after 2065 traning the loss is 0.0017593610100448132\n",
      "after 2066 traning the loss is 0.003492885734885931\n",
      "after 2067 traning the loss is 0.004104706458747387\n",
      "after 2068 traning the loss is 0.0013349258806556463\n",
      "after 2069 traning the loss is 0.020627113059163094\n",
      "after 2070 traning the loss is 0.0022934875451028347\n",
      "after 2071 traning the loss is 0.0055251047015190125\n",
      "after 2072 traning the loss is 0.01917886920273304\n",
      "after 2073 traning the loss is 0.0018194636795669794\n",
      "after 2074 traning the loss is 0.00292174331843853\n",
      "after 2075 traning the loss is 0.0654909536242485\n",
      "after 2076 traning the loss is 0.004674749448895454\n",
      "after 2077 traning the loss is 0.01750156655907631\n",
      "after 2078 traning the loss is 0.0011412418680265546\n",
      "after 2079 traning the loss is 0.0017132520442828536\n",
      "after 2080 traning the loss is 0.0017365317326039076\n",
      "after 2081 traning the loss is 0.0020179287530481815\n",
      "after 2082 traning the loss is 0.0013041312340646982\n",
      "after 2083 traning the loss is 0.001698044827207923\n",
      "after 2084 traning the loss is 0.054741740226745605\n",
      "after 2085 traning the loss is 0.0007774341502226889\n",
      "after 2086 traning the loss is 0.0015128713566809893\n",
      "after 2087 traning the loss is 0.0019565224647521973\n",
      "after 2088 traning the loss is 0.005593507084995508\n",
      "after 2089 traning the loss is 0.009021577425301075\n",
      "after 2090 traning the loss is 0.011964695528149605\n",
      "after 2091 traning the loss is 0.0022791444789618254\n",
      "after 2092 traning the loss is 0.0016042962670326233\n",
      "after 2093 traning the loss is 0.0022770266514271498\n",
      "after 2094 traning the loss is 0.0036327505949884653\n",
      "after 2095 traning the loss is 0.004317085724323988\n",
      "after 2096 traning the loss is 0.005056602880358696\n",
      "after 2097 traning the loss is 0.001762972678989172\n",
      "after 2098 traning the loss is 0.06145131215453148\n",
      "after 2099 traning the loss is 0.019900962710380554\n",
      "after 2100 traning the loss is 0.006773730739951134\n",
      "after 2101 traning the loss is 0.0005432894104160368\n",
      "after 2102 traning the loss is 0.0026220823638141155\n",
      "after 2103 traning the loss is 0.0029412962030619383\n",
      "after 2104 traning the loss is 0.003947453573346138\n",
      "after 2105 traning the loss is 0.001895046909339726\n",
      "after 2106 traning the loss is 0.007800966035574675\n",
      "after 2107 traning the loss is 0.0006070580566301942\n",
      "after 2108 traning the loss is 0.0012524951016530395\n",
      "after 2109 traning the loss is 0.008367260918021202\n",
      "after 2110 traning the loss is 0.13098213076591492\n",
      "after 2111 traning the loss is 0.002052729483693838\n",
      "after 2112 traning the loss is 0.0022290495689958334\n",
      "after 2113 traning the loss is 0.027623550966382027\n",
      "after 2114 traning the loss is 0.02282807230949402\n",
      "after 2115 traning the loss is 0.0023930654861032963\n",
      "after 2116 traning the loss is 0.001871580258011818\n",
      "after 2117 traning the loss is 0.030806779861450195\n",
      "after 2118 traning the loss is 0.004096668213605881\n",
      "after 2119 traning the loss is 0.01951581984758377\n",
      "after 2120 traning the loss is 0.007267816923558712\n",
      "after 2121 traning the loss is 0.004626022186130285\n",
      "after 2122 traning the loss is 0.025458090007305145\n",
      "after 2123 traning the loss is 0.0018791193142533302\n",
      "after 2124 traning the loss is 0.0036031343042850494\n",
      "after 2125 traning the loss is 0.009240860119462013\n",
      "after 2126 traning the loss is 0.0053377943113446236\n",
      "after 2127 traning the loss is 0.001747852424159646\n",
      "after 2128 traning the loss is 0.002356681041419506\n",
      "after 2129 traning the loss is 0.00122468126937747\n",
      "after 2130 traning the loss is 0.004180078394711018\n",
      "after 2131 traning the loss is 0.0006552734412252903\n",
      "after 2132 traning the loss is 0.11861934512853622\n",
      "after 2133 traning the loss is 0.002344887237995863\n",
      "after 2134 traning the loss is 0.003576467977836728\n",
      "after 2135 traning the loss is 0.0010958602651953697\n",
      "after 2136 traning the loss is 0.0018419534899294376\n",
      "after 2137 traning the loss is 0.007605280261486769\n",
      "after 2138 traning the loss is 0.00099729944486171\n",
      "after 2139 traning the loss is 0.0017420751973986626\n",
      "after 2140 traning the loss is 0.0055300346575677395\n",
      "after 2141 traning the loss is 0.0036083112936466932\n",
      "after 2142 traning the loss is 0.0163742508739233\n",
      "after 2143 traning the loss is 0.002424638718366623\n",
      "after 2144 traning the loss is 0.010990546084940434\n",
      "after 2145 traning the loss is 0.001597429160028696\n",
      "after 2146 traning the loss is 0.0011747173266485333\n",
      "after 2147 traning the loss is 0.0449160598218441\n",
      "after 2148 traning the loss is 0.002372445072978735\n",
      "after 2149 traning the loss is 0.0013044079532846808\n",
      "after 2150 traning the loss is 0.002439605537801981\n",
      "after 2151 traning the loss is 0.0023100548423826694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2152 traning the loss is 0.0011207301868125796\n",
      "after 2153 traning the loss is 0.013722380623221397\n",
      "after 2154 traning the loss is 0.0008480802061967552\n",
      "after 2155 traning the loss is 0.0061517939902842045\n",
      "after 2156 traning the loss is 0.00829023215919733\n",
      "after 2157 traning the loss is 0.056744284927845\n",
      "after 2158 traning the loss is 0.008009267970919609\n",
      "after 2159 traning the loss is 0.016750188544392586\n",
      "after 2160 traning the loss is 0.0052624111995100975\n",
      "after 2161 traning the loss is 0.0007809999515302479\n",
      "after 2162 traning the loss is 0.001159509876742959\n",
      "after 2163 traning the loss is 0.004104721359908581\n",
      "after 2164 traning the loss is 0.0009815780213102698\n",
      "after 2165 traning the loss is 0.001471388735808432\n",
      "after 2166 traning the loss is 0.011198621243238449\n",
      "after 2167 traning the loss is 0.0023681423626840115\n",
      "after 2168 traning the loss is 0.0009131188853643835\n",
      "after 2169 traning the loss is 0.061688728630542755\n",
      "after 2170 traning the loss is 0.0528121255338192\n",
      "after 2171 traning the loss is 0.0007430600235238671\n",
      "after 2172 traning the loss is 0.0013434302527457476\n",
      "after 2173 traning the loss is 0.047148313373327255\n",
      "after 2174 traning the loss is 0.0038061034865677357\n",
      "after 2175 traning the loss is 0.0017993873916566372\n",
      "after 2176 traning the loss is 0.0034559499472379684\n",
      "after 2177 traning the loss is 0.000612118630670011\n",
      "after 2178 traning the loss is 0.0035989638417959213\n",
      "after 2179 traning the loss is 0.05209249258041382\n",
      "after 2180 traning the loss is 0.004952664021402597\n",
      "after 2181 traning the loss is 0.0028600089717656374\n",
      "after 2182 traning the loss is 0.0005398034700192511\n",
      "after 2183 traning the loss is 0.005442523863166571\n",
      "after 2184 traning the loss is 0.0008339720079675317\n",
      "after 2185 traning the loss is 0.001688293181359768\n",
      "after 2186 traning the loss is 0.010022534057497978\n",
      "after 2187 traning the loss is 0.0029107672162353992\n",
      "after 2188 traning the loss is 0.005067130550742149\n",
      "after 2189 traning the loss is 0.000933749892283231\n",
      "after 2190 traning the loss is 0.0017479644156992435\n",
      "after 2191 traning the loss is 0.0019259845139458776\n",
      "after 2192 traning the loss is 0.0008520182454958558\n",
      "after 2193 traning the loss is 0.0008099096594378352\n",
      "after 2194 traning the loss is 0.001418920699506998\n",
      "after 2195 traning the loss is 0.001943573821336031\n",
      "after 2196 traning the loss is 0.03263740986585617\n",
      "after 2197 traning the loss is 0.10026299953460693\n",
      "after 2198 traning the loss is 0.0004509467980824411\n",
      "after 2199 traning the loss is 0.006496245972812176\n",
      "after 2200 traning the loss is 0.010304803028702736\n",
      "after 2201 traning the loss is 0.0016898910980671644\n",
      "after 2202 traning the loss is 0.004511367995291948\n",
      "after 2203 traning the loss is 0.003351167542859912\n",
      "after 2204 traning the loss is 0.0022927955724298954\n",
      "after 2205 traning the loss is 0.002360123908147216\n",
      "after 2206 traning the loss is 0.0015799214597791433\n",
      "after 2207 traning the loss is 0.07571352273225784\n",
      "after 2208 traning the loss is 0.0010012396378442645\n",
      "after 2209 traning the loss is 0.0015187545213848352\n",
      "after 2210 traning the loss is 0.0011589191854000092\n",
      "after 2211 traning the loss is 0.0007493911543861032\n",
      "after 2212 traning the loss is 0.001679187873378396\n",
      "after 2213 traning the loss is 0.0038805713411420584\n",
      "after 2214 traning the loss is 0.002803575247526169\n",
      "after 2215 traning the loss is 0.0024029973428696394\n",
      "after 2216 traning the loss is 0.011991126462817192\n",
      "after 2217 traning the loss is 0.0006819262634962797\n",
      "after 2218 traning the loss is 0.001037860056385398\n",
      "after 2219 traning the loss is 0.0019430305110290647\n",
      "after 2220 traning the loss is 0.003584213787689805\n",
      "after 2221 traning the loss is 0.0009094241540879011\n",
      "after 2222 traning the loss is 0.002271456178277731\n",
      "after 2223 traning the loss is 0.014183624647557735\n",
      "after 2224 traning the loss is 0.0008368835551664233\n",
      "after 2225 traning the loss is 0.010790711268782616\n",
      "after 2226 traning the loss is 0.002036474645137787\n",
      "after 2227 traning the loss is 0.0021211854182183743\n",
      "after 2228 traning the loss is 0.0013217669911682606\n",
      "after 2229 traning the loss is 0.0027412292547523975\n",
      "after 2230 traning the loss is 0.013325189240276814\n",
      "after 2231 traning the loss is 0.012147996574640274\n",
      "after 2232 traning the loss is 0.006458712741732597\n",
      "after 2233 traning the loss is 0.000757243949919939\n",
      "after 2234 traning the loss is 0.001173083670437336\n",
      "after 2235 traning the loss is 0.0413135327398777\n",
      "after 2236 traning the loss is 0.0028732751961797476\n",
      "after 2237 traning the loss is 0.033187076449394226\n",
      "after 2238 traning the loss is 0.0016138899372890592\n",
      "after 2239 traning the loss is 0.0010129576548933983\n",
      "after 2240 traning the loss is 0.0005793235031887889\n",
      "after 2241 traning the loss is 0.004422336351126432\n",
      "after 2242 traning the loss is 0.02432204596698284\n",
      "after 2243 traning the loss is 0.01726420968770981\n",
      "after 2244 traning the loss is 0.004494073800742626\n",
      "after 2245 traning the loss is 0.0019984939135611057\n",
      "after 2246 traning the loss is 0.001909012207761407\n",
      "after 2247 traning the loss is 0.008288388140499592\n",
      "after 2248 traning the loss is 0.004120234865695238\n",
      "after 2249 traning the loss is 0.000929397065192461\n",
      "after 2250 traning the loss is 0.0018567168153822422\n",
      "after 2251 traning the loss is 0.001179331331513822\n",
      "after 2252 traning the loss is 0.000750989536754787\n",
      "after 2253 traning the loss is 0.00139910529833287\n",
      "after 2254 traning the loss is 0.0008026519208215177\n",
      "after 2255 traning the loss is 0.040427763015031815\n",
      "after 2256 traning the loss is 0.0005157727282494307\n",
      "after 2257 traning the loss is 0.08012507110834122\n",
      "after 2258 traning the loss is 0.0011259946040809155\n",
      "after 2259 traning the loss is 0.0007231126655824482\n",
      "after 2260 traning the loss is 0.0008090777555480599\n",
      "after 2261 traning the loss is 0.15964967012405396\n",
      "after 2262 traning the loss is 0.0029765875078737736\n",
      "after 2263 traning the loss is 0.002218230627477169\n",
      "after 2264 traning the loss is 0.0023654489777982235\n",
      "after 2265 traning the loss is 0.000643498613499105\n",
      "after 2266 traning the loss is 0.06274168193340302\n",
      "after 2267 traning the loss is 0.0020565944723784924\n",
      "after 2268 traning the loss is 0.01812628097832203\n",
      "after 2269 traning the loss is 0.001432277960702777\n",
      "after 2270 traning the loss is 0.0009262796957045794\n",
      "after 2271 traning the loss is 0.0027570780366659164\n",
      "after 2272 traning the loss is 0.001589999650605023\n",
      "after 2273 traning the loss is 0.0012532470282167196\n",
      "after 2274 traning the loss is 0.003759189508855343\n",
      "after 2275 traning the loss is 0.0020147468894720078\n",
      "after 2276 traning the loss is 0.006998159922659397\n",
      "after 2277 traning the loss is 0.0024462644942104816\n",
      "after 2278 traning the loss is 0.0804184153676033\n",
      "after 2279 traning the loss is 0.0207432322204113\n",
      "after 2280 traning the loss is 0.0024717277847230434\n",
      "after 2281 traning the loss is 0.0011529703624546528\n",
      "after 2282 traning the loss is 0.036894164979457855\n",
      "after 2283 traning the loss is 0.0011054228525608778\n",
      "after 2284 traning the loss is 0.003205073531717062\n",
      "after 2285 traning the loss is 0.0019518684130162\n",
      "after 2286 traning the loss is 0.0008453816408291459\n",
      "after 2287 traning the loss is 0.003962777089327574\n",
      "after 2288 traning the loss is 0.0013226818991824985\n",
      "after 2289 traning the loss is 0.0038534230552613735\n",
      "after 2290 traning the loss is 0.0060064769349992275\n",
      "after 2291 traning the loss is 0.0015247623668983579\n",
      "after 2292 traning the loss is 0.0014320006594061852\n",
      "after 2293 traning the loss is 0.0015008806949481368\n",
      "after 2294 traning the loss is 0.001186921028420329\n",
      "after 2295 traning the loss is 0.0010272898944094777\n",
      "after 2296 traning the loss is 0.011477595195174217\n",
      "after 2297 traning the loss is 0.0011972745414823294\n",
      "after 2298 traning the loss is 0.0005388938006944954\n",
      "after 2299 traning the loss is 0.0007721373112872243\n",
      "after 2300 traning the loss is 0.002206249628216028\n",
      "after 2301 traning the loss is 0.06207792088389397\n",
      "after 2302 traning the loss is 0.0017686125356703997\n",
      "after 2303 traning the loss is 0.010958955623209476\n",
      "after 2304 traning the loss is 0.001179445069283247\n",
      "after 2305 traning the loss is 0.009760656394064426\n",
      "after 2306 traning the loss is 0.007348854560405016\n",
      "after 2307 traning the loss is 0.002805361058562994\n",
      "after 2308 traning the loss is 0.007786459289491177\n",
      "after 2309 traning the loss is 0.0004479356575757265\n",
      "after 2310 traning the loss is 0.0024119801819324493\n",
      "after 2311 traning the loss is 0.01697685196995735\n",
      "after 2312 traning the loss is 0.0038406115490943193\n",
      "after 2313 traning the loss is 0.05810742825269699\n",
      "after 2314 traning the loss is 0.00268026115372777\n",
      "after 2315 traning the loss is 0.005457498133182526\n",
      "after 2316 traning the loss is 0.0008862093091011047\n",
      "after 2317 traning the loss is 0.0013375487178564072\n",
      "after 2318 traning the loss is 0.0007471251301467419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2319 traning the loss is 0.0010827276855707169\n",
      "after 2320 traning the loss is 0.0008283120114356279\n",
      "after 2321 traning the loss is 0.008882885798811913\n",
      "after 2322 traning the loss is 0.0017444104887545109\n",
      "after 2323 traning the loss is 0.08880214393138885\n",
      "after 2324 traning the loss is 0.0021126833744347095\n",
      "after 2325 traning the loss is 0.011493206024169922\n",
      "after 2326 traning the loss is 0.0005087433964945376\n",
      "after 2327 traning the loss is 0.019136304035782814\n",
      "after 2328 traning the loss is 0.0012441776925697923\n",
      "after 2329 traning the loss is 0.03346647322177887\n",
      "after 2330 traning the loss is 0.06091107428073883\n",
      "after 2331 traning the loss is 0.00578615628182888\n",
      "after 2332 traning the loss is 0.009119894355535507\n",
      "after 2333 traning the loss is 0.005656024906784296\n",
      "after 2334 traning the loss is 0.041245877742767334\n",
      "after 2335 traning the loss is 0.0022553089074790478\n",
      "after 2336 traning the loss is 0.0012306811986491084\n",
      "after 2337 traning the loss is 0.002190528204664588\n",
      "after 2338 traning the loss is 0.012700964696705341\n",
      "after 2339 traning the loss is 0.009409569203853607\n",
      "after 2340 traning the loss is 0.003622795455157757\n",
      "after 2341 traning the loss is 0.002433622721582651\n",
      "after 2342 traning the loss is 0.06918609142303467\n",
      "after 2343 traning the loss is 0.0019876593723893166\n",
      "after 2344 traning the loss is 0.005296418908983469\n",
      "after 2345 traning the loss is 0.0018513425020501018\n",
      "after 2346 traning the loss is 0.0018423455767333508\n",
      "after 2347 traning the loss is 0.006106562912464142\n",
      "after 2348 traning the loss is 0.0018028713529929519\n",
      "after 2349 traning the loss is 0.0004270496719982475\n",
      "after 2350 traning the loss is 0.0025996442418545485\n",
      "after 2351 traning the loss is 0.001180584542453289\n",
      "after 2352 traning the loss is 0.01671196147799492\n",
      "after 2353 traning the loss is 0.0009989114478230476\n",
      "after 2354 traning the loss is 0.0011028936132788658\n",
      "after 2355 traning the loss is 0.024774912744760513\n",
      "after 2356 traning the loss is 0.000880998617503792\n",
      "after 2357 traning the loss is 0.0007621801923960447\n",
      "after 2358 traning the loss is 0.004926749505102634\n",
      "after 2359 traning the loss is 0.00044095367775298655\n",
      "after 2360 traning the loss is 0.0018066724296659231\n",
      "after 2361 traning the loss is 0.008990480564534664\n",
      "after 2362 traning the loss is 0.008130038157105446\n",
      "after 2363 traning the loss is 0.032919496297836304\n",
      "after 2364 traning the loss is 0.002040248364210129\n",
      "after 2365 traning the loss is 0.0009249443537555635\n",
      "after 2366 traning the loss is 0.060955170542001724\n",
      "after 2367 traning the loss is 0.005466844886541367\n",
      "after 2368 traning the loss is 0.002463557990267873\n",
      "after 2369 traning the loss is 0.03515465185046196\n",
      "after 2370 traning the loss is 0.015167213045060635\n",
      "after 2371 traning the loss is 0.00912498775869608\n",
      "after 2372 traning the loss is 0.022494014352560043\n",
      "after 2373 traning the loss is 0.011296947486698627\n",
      "after 2374 traning the loss is 0.015037201344966888\n",
      "after 2375 traning the loss is 0.021005582064390182\n",
      "after 2376 traning the loss is 0.0013702582800760865\n",
      "after 2377 traning the loss is 0.0024238131009042263\n",
      "after 2378 traning the loss is 0.0023062077816575766\n",
      "after 2379 traning the loss is 0.0089000528678298\n",
      "after 2380 traning the loss is 0.005212541203945875\n",
      "after 2381 traning the loss is 0.0006361985579133034\n",
      "after 2382 traning the loss is 0.0007964539108797908\n",
      "after 2383 traning the loss is 0.0004282220033928752\n",
      "after 2384 traning the loss is 0.000990445027127862\n",
      "after 2385 traning the loss is 0.0024948976933956146\n",
      "after 2386 traning the loss is 0.0008102632127702236\n",
      "after 2387 traning the loss is 0.000609491253271699\n",
      "after 2388 traning the loss is 0.0021430146880447865\n",
      "after 2389 traning the loss is 0.0064934357069432735\n",
      "after 2390 traning the loss is 0.009607489220798016\n",
      "after 2391 traning the loss is 0.005375480744987726\n",
      "after 2392 traning the loss is 0.028333643451333046\n",
      "after 2393 traning the loss is 0.0018455812241882086\n",
      "after 2394 traning the loss is 0.014395331963896751\n",
      "after 2395 traning the loss is 0.03647222742438316\n",
      "after 2396 traning the loss is 0.0012809669133275747\n",
      "after 2397 traning the loss is 0.030035313218832016\n",
      "after 2398 traning the loss is 0.14247126877307892\n",
      "after 2399 traning the loss is 0.0019254337530583143\n",
      "after 2400 traning the loss is 0.004061575513333082\n",
      "after 2401 traning the loss is 0.013820071704685688\n",
      "after 2402 traning the loss is 0.005810384638607502\n",
      "after 2403 traning the loss is 0.003211165312677622\n",
      "after 2404 traning the loss is 0.0030925848986953497\n",
      "after 2405 traning the loss is 0.019273897632956505\n",
      "after 2406 traning the loss is 0.006041598040610552\n",
      "after 2407 traning the loss is 0.03506392985582352\n",
      "after 2408 traning the loss is 0.006299546919763088\n",
      "after 2409 traning the loss is 0.002437514252960682\n",
      "after 2410 traning the loss is 0.0007670304039493203\n",
      "after 2411 traning the loss is 0.0012081981403753161\n",
      "after 2412 traning the loss is 0.0008118742844089866\n",
      "after 2413 traning the loss is 0.0023105621803551912\n",
      "after 2414 traning the loss is 0.0025065564550459385\n",
      "after 2415 traning the loss is 0.0009259920916520059\n",
      "after 2416 traning the loss is 0.002212361665442586\n",
      "after 2417 traning the loss is 0.0013348619686439633\n",
      "after 2418 traning the loss is 0.07994198054075241\n",
      "after 2419 traning the loss is 0.009954271838068962\n",
      "after 2420 traning the loss is 0.0010998446960002184\n",
      "after 2421 traning the loss is 0.05828443169593811\n",
      "after 2422 traning the loss is 0.0009126480435952544\n",
      "after 2423 traning the loss is 0.0019655930809676647\n",
      "after 2424 traning the loss is 0.0009567200322635472\n",
      "after 2425 traning the loss is 0.006718873046338558\n",
      "after 2426 traning the loss is 0.0031150737777352333\n",
      "after 2427 traning the loss is 0.00526975654065609\n",
      "after 2428 traning the loss is 0.022657126188278198\n",
      "after 2429 traning the loss is 0.04330642521381378\n",
      "after 2430 traning the loss is 0.001599507057107985\n",
      "after 2431 traning the loss is 0.0024964804761111736\n",
      "after 2432 traning the loss is 0.0071226367726922035\n",
      "after 2433 traning the loss is 0.006978300400078297\n",
      "after 2434 traning the loss is 0.0038754171691834927\n",
      "after 2435 traning the loss is 0.0027772760950028896\n",
      "after 2436 traning the loss is 0.0018555973656475544\n",
      "after 2437 traning the loss is 0.0012475671246647835\n",
      "after 2438 traning the loss is 0.0009112358675338328\n",
      "after 2439 traning the loss is 0.045762043446302414\n",
      "after 2440 traning the loss is 0.0023609360214322805\n",
      "after 2441 traning the loss is 0.0791764035820961\n",
      "after 2442 traning the loss is 0.000802811118774116\n",
      "after 2443 traning the loss is 0.0008864868432283401\n",
      "after 2444 traning the loss is 0.00123688078019768\n",
      "after 2445 traning the loss is 0.00246847583912313\n",
      "after 2446 traning the loss is 0.04021883010864258\n",
      "after 2447 traning the loss is 0.0005665549542754889\n",
      "after 2448 traning the loss is 0.002065389882773161\n",
      "after 2449 traning the loss is 0.0007634685607627034\n",
      "after 2450 traning the loss is 0.0027671651914715767\n",
      "after 2451 traning the loss is 0.0014768174150958657\n",
      "after 2452 traning the loss is 0.0007207570597529411\n",
      "after 2453 traning the loss is 0.00066864158725366\n",
      "after 2454 traning the loss is 0.0031257341615855694\n",
      "after 2455 traning the loss is 0.0017121040727943182\n",
      "after 2456 traning the loss is 0.006125611253082752\n",
      "after 2457 traning the loss is 0.0008129366906359792\n",
      "after 2458 traning the loss is 0.0007438206812366843\n",
      "after 2459 traning the loss is 0.0009414133382961154\n",
      "after 2460 traning the loss is 0.0014307284727692604\n",
      "after 2461 traning the loss is 0.0008068145252764225\n",
      "after 2462 traning the loss is 0.0004094362957403064\n",
      "after 2463 traning the loss is 0.0012981173349544406\n",
      "after 2464 traning the loss is 0.016392333433032036\n",
      "after 2465 traning the loss is 0.001027367077767849\n",
      "after 2466 traning the loss is 0.014896852895617485\n",
      "after 2467 traning the loss is 0.0024284112732857466\n",
      "after 2468 traning the loss is 0.0005624672630801797\n",
      "after 2469 traning the loss is 0.0011498378589749336\n",
      "after 2470 traning the loss is 0.0015455305110663176\n",
      "after 2471 traning the loss is 0.02091887779533863\n",
      "after 2472 traning the loss is 0.011003954336047173\n",
      "after 2473 traning the loss is 0.0524548664689064\n",
      "after 2474 traning the loss is 0.0012089164229109883\n",
      "after 2475 traning the loss is 0.01655501499772072\n",
      "after 2476 traning the loss is 0.003968012519180775\n",
      "after 2477 traning the loss is 0.0011051635956391692\n",
      "after 2478 traning the loss is 0.009312394075095654\n",
      "after 2479 traning the loss is 0.0022032049018889666\n",
      "after 2480 traning the loss is 0.0018384321592748165\n",
      "after 2481 traning the loss is 0.004891989752650261\n",
      "after 2482 traning the loss is 0.0024696143809705973\n",
      "after 2483 traning the loss is 0.0063784485682845116\n",
      "after 2484 traning the loss is 0.14032426476478577\n",
      "after 2485 traning the loss is 0.02015756070613861\n",
      "after 2486 traning the loss is 0.0015322505496442318\n",
      "after 2487 traning the loss is 0.0032498864457011223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2488 traning the loss is 0.0038347707595676184\n",
      "after 2489 traning the loss is 0.006330209318548441\n",
      "after 2490 traning the loss is 0.00043640995863825083\n",
      "after 2491 traning the loss is 0.0026557452511042356\n",
      "after 2492 traning the loss is 0.0029225354082882404\n",
      "after 2493 traning the loss is 0.0024863106664270163\n",
      "after 2494 traning the loss is 0.0038363547064363956\n",
      "after 2495 traning the loss is 0.04200601205229759\n",
      "after 2496 traning the loss is 0.0024901614524424076\n",
      "after 2497 traning the loss is 0.0637255385518074\n",
      "after 2498 traning the loss is 0.005034696776419878\n",
      "after 2499 traning the loss is 0.0027394620701670647\n",
      "after 2500 traning the loss is 0.003946551121771336\n",
      "after 2501 traning the loss is 0.020346976816654205\n",
      "after 2502 traning the loss is 0.2884587347507477\n",
      "after 2503 traning the loss is 0.00209794077090919\n",
      "after 2504 traning the loss is 0.002969448221847415\n",
      "after 2505 traning the loss is 0.002456353511661291\n",
      "after 2506 traning the loss is 0.0018647239776328206\n",
      "after 2507 traning the loss is 0.029552841559052467\n",
      "after 2508 traning the loss is 0.0007988960715010762\n",
      "after 2509 traning the loss is 0.012984631583094597\n",
      "after 2510 traning the loss is 0.004042723681777716\n",
      "after 2511 traning the loss is 0.0030647465027868748\n",
      "after 2512 traning the loss is 0.0005103872972540557\n",
      "after 2513 traning the loss is 0.003573762718588114\n",
      "after 2514 traning the loss is 0.0034525697119534016\n",
      "after 2515 traning the loss is 0.004362419247627258\n",
      "after 2516 traning the loss is 0.0008091091876849532\n",
      "after 2517 traning the loss is 0.00289531028829515\n",
      "after 2518 traning the loss is 0.0008585512405261397\n",
      "after 2519 traning the loss is 0.11530289053916931\n",
      "after 2520 traning the loss is 0.007623839657753706\n",
      "after 2521 traning the loss is 0.0011119880946353078\n",
      "after 2522 traning the loss is 0.004345185589045286\n",
      "after 2523 traning the loss is 0.022398952394723892\n",
      "after 2524 traning the loss is 0.07765766978263855\n",
      "after 2525 traning the loss is 0.004319242667406797\n",
      "after 2526 traning the loss is 0.0047566830180585384\n",
      "after 2527 traning the loss is 0.0007523295935243368\n",
      "after 2528 traning the loss is 0.002051052637398243\n",
      "after 2529 traning the loss is 0.0088246650993824\n",
      "after 2530 traning the loss is 0.0023839387577027082\n",
      "after 2531 traning the loss is 0.0011481408728286624\n",
      "after 2532 traning the loss is 0.0009603983489796519\n",
      "after 2533 traning the loss is 0.0024558301083743572\n",
      "after 2534 traning the loss is 0.0009408679325133562\n",
      "after 2535 traning the loss is 0.0005431153695099056\n",
      "after 2536 traning the loss is 0.010955012403428555\n",
      "after 2537 traning the loss is 0.003168623661622405\n",
      "after 2538 traning the loss is 0.0009103221818804741\n",
      "after 2539 traning the loss is 0.01279941014945507\n",
      "after 2540 traning the loss is 0.0007265114109031856\n",
      "after 2541 traning the loss is 0.0014744348591193557\n",
      "after 2542 traning the loss is 0.0762840285897255\n",
      "after 2543 traning the loss is 0.0008568839984945953\n",
      "after 2544 traning the loss is 0.0026970510371029377\n",
      "after 2545 traning the loss is 0.007175859995186329\n",
      "after 2546 traning the loss is 0.0018991647521033883\n",
      "after 2547 traning the loss is 0.0021769588347524405\n",
      "after 2548 traning the loss is 0.0021914562676101923\n",
      "after 2549 traning the loss is 0.001405618037097156\n",
      "after 2550 traning the loss is 0.0014689185190945864\n",
      "after 2551 traning the loss is 0.03617388382554054\n",
      "after 2552 traning the loss is 0.005185275338590145\n",
      "after 2553 traning the loss is 0.0009027491323649883\n",
      "after 2554 traning the loss is 0.0008837472414597869\n",
      "after 2555 traning the loss is 0.005786916706711054\n",
      "after 2556 traning the loss is 0.0040120347402989864\n",
      "after 2557 traning the loss is 0.0008500489639118314\n",
      "after 2558 traning the loss is 0.0004641361883841455\n",
      "after 2559 traning the loss is 0.0030106641352176666\n",
      "after 2560 traning the loss is 0.016774700954556465\n",
      "after 2561 traning the loss is 0.0022402701433748007\n",
      "after 2562 traning the loss is 0.001387832686305046\n",
      "after 2563 traning the loss is 0.00767666008323431\n",
      "after 2564 traning the loss is 0.0003884512116201222\n",
      "after 2565 traning the loss is 0.0010751703521236777\n",
      "after 2566 traning the loss is 0.0006269717123359442\n",
      "after 2567 traning the loss is 0.000651467707939446\n",
      "after 2568 traning the loss is 0.0025139078497886658\n",
      "after 2569 traning the loss is 0.0015471181832253933\n",
      "after 2570 traning the loss is 0.01509984489530325\n",
      "after 2571 traning the loss is 0.001500020851381123\n",
      "after 2572 traning the loss is 0.001223709899932146\n",
      "after 2573 traning the loss is 0.0017804477829486132\n",
      "after 2574 traning the loss is 0.0007295145187526941\n",
      "after 2575 traning the loss is 0.0009794759098440409\n",
      "after 2576 traning the loss is 0.0009293879847973585\n",
      "after 2577 traning the loss is 0.0006963781197555363\n",
      "after 2578 traning the loss is 0.0011117755202576518\n",
      "after 2579 traning the loss is 0.0024832780472934246\n",
      "after 2580 traning the loss is 0.0015887741465121508\n",
      "after 2581 traning the loss is 0.0006598271429538727\n",
      "after 2582 traning the loss is 0.004914558958262205\n",
      "after 2583 traning the loss is 0.0008229518425650895\n",
      "after 2584 traning the loss is 0.0017821447690948844\n",
      "after 2585 traning the loss is 0.0013761923182755709\n",
      "after 2586 traning the loss is 0.0020127021707594395\n",
      "after 2587 traning the loss is 0.0024418458342552185\n",
      "after 2588 traning the loss is 0.0013576410710811615\n",
      "after 2589 traning the loss is 0.0061315083876252174\n",
      "after 2590 traning the loss is 0.005436789244413376\n",
      "after 2591 traning the loss is 0.0006128370296210051\n",
      "after 2592 traning the loss is 0.0021703580860048532\n",
      "after 2593 traning the loss is 0.0029419048223644495\n",
      "after 2594 traning the loss is 0.0004304208268877119\n",
      "after 2595 traning the loss is 0.002672130474820733\n",
      "after 2596 traning the loss is 0.0022501740604639053\n",
      "after 2597 traning the loss is 0.0007325181504711509\n",
      "after 2598 traning the loss is 0.0010924432426691055\n",
      "after 2599 traning the loss is 0.00033779378281906247\n",
      "after 2600 traning the loss is 0.00046345783630385995\n",
      "after 2601 traning the loss is 0.0011859890073537827\n",
      "after 2602 traning the loss is 0.0005172053934074938\n",
      "after 2603 traning the loss is 0.0003368953475728631\n",
      "after 2604 traning the loss is 0.0006159899639897048\n",
      "after 2605 traning the loss is 0.0005048386519774795\n",
      "after 2606 traning the loss is 0.0005616721464321017\n",
      "after 2607 traning the loss is 0.0007034589070826769\n",
      "after 2608 traning the loss is 0.0007672450155951083\n",
      "after 2609 traning the loss is 0.0006297086365520954\n",
      "after 2610 traning the loss is 0.0005587422056123614\n",
      "after 2611 traning the loss is 0.0011514995712786913\n",
      "after 2612 traning the loss is 0.0009151212871074677\n",
      "after 2613 traning the loss is 0.0016838726587593555\n",
      "after 2614 traning the loss is 0.08996713161468506\n",
      "after 2615 traning the loss is 0.03011813387274742\n",
      "after 2616 traning the loss is 0.0062631880864501\n",
      "after 2617 traning the loss is 0.001790029346011579\n",
      "after 2618 traning the loss is 0.0024475606624037027\n",
      "after 2619 traning the loss is 0.0008683204650878906\n",
      "after 2620 traning the loss is 0.003831187030300498\n",
      "after 2621 traning the loss is 0.005121412221342325\n",
      "after 2622 traning the loss is 0.0022037671878933907\n",
      "after 2623 traning the loss is 0.010209158062934875\n",
      "after 2624 traning the loss is 0.0038372946437448263\n",
      "after 2625 traning the loss is 0.004008112475275993\n",
      "after 2626 traning the loss is 0.0023931751493364573\n",
      "after 2627 traning the loss is 0.0018846404273062944\n",
      "after 2628 traning the loss is 0.005628447514027357\n",
      "after 2629 traning the loss is 0.007647397927939892\n",
      "after 2630 traning the loss is 0.02279488928616047\n",
      "after 2631 traning the loss is 0.001853252062574029\n",
      "after 2632 traning the loss is 0.05064576119184494\n",
      "after 2633 traning the loss is 0.0015302726533263922\n",
      "after 2634 traning the loss is 0.0014562902506440878\n",
      "after 2635 traning the loss is 0.0016987487906590104\n",
      "after 2636 traning the loss is 0.005816114135086536\n",
      "after 2637 traning the loss is 0.0009055545087903738\n",
      "after 2638 traning the loss is 0.018683558329939842\n",
      "after 2639 traning the loss is 0.007499888073652983\n",
      "after 2640 traning the loss is 0.00873439759016037\n",
      "after 2641 traning the loss is 0.0004946078406646848\n",
      "after 2642 traning the loss is 0.0020313356071710587\n",
      "after 2643 traning the loss is 0.0008123156148940325\n",
      "after 2644 traning the loss is 0.0006387388566508889\n",
      "after 2645 traning the loss is 0.0008391853189095855\n",
      "after 2646 traning the loss is 0.0016924823867157102\n",
      "after 2647 traning the loss is 0.007794099859893322\n",
      "after 2648 traning the loss is 0.0013586821733042598\n",
      "after 2649 traning the loss is 0.004204069264233112\n",
      "after 2650 traning the loss is 0.0011377406772226095\n",
      "after 2651 traning the loss is 0.0014057164080440998\n",
      "after 2652 traning the loss is 0.0020351815037429333\n",
      "after 2653 traning the loss is 0.0015996061265468597\n",
      "after 2654 traning the loss is 0.09409607946872711\n",
      "after 2655 traning the loss is 0.0004049410636071116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2656 traning the loss is 0.0010896995663642883\n",
      "after 2657 traning the loss is 0.0005915007786825299\n",
      "after 2658 traning the loss is 0.0011669285595417023\n",
      "after 2659 traning the loss is 0.0008431374444626272\n",
      "after 2660 traning the loss is 0.03078087419271469\n",
      "after 2661 traning the loss is 0.0006016255356371403\n",
      "after 2662 traning the loss is 0.0012412285432219505\n",
      "after 2663 traning the loss is 0.0008685921784490347\n",
      "after 2664 traning the loss is 0.01836639642715454\n",
      "after 2665 traning the loss is 0.002847584430128336\n",
      "after 2666 traning the loss is 0.0010991126764565706\n",
      "after 2667 traning the loss is 0.0013920688070356846\n",
      "after 2668 traning the loss is 0.021207988262176514\n",
      "after 2669 traning the loss is 0.0009738268563523889\n",
      "after 2670 traning the loss is 0.29334211349487305\n",
      "after 2671 traning the loss is 0.0008358414052054286\n",
      "after 2672 traning the loss is 0.0011665360070765018\n",
      "after 2673 traning the loss is 0.0020145990420132875\n",
      "after 2674 traning the loss is 0.0022668074816465378\n",
      "after 2675 traning the loss is 0.000624095497187227\n",
      "after 2676 traning the loss is 0.0005504485452547669\n",
      "after 2677 traning the loss is 0.00036725305835716426\n",
      "after 2678 traning the loss is 0.003990629687905312\n",
      "after 2679 traning the loss is 0.0005054654320701957\n",
      "after 2680 traning the loss is 0.00073668995173648\n",
      "after 2681 traning the loss is 0.0003515905700623989\n",
      "after 2682 traning the loss is 0.0037632586900144815\n",
      "after 2683 traning the loss is 0.03544545918703079\n",
      "after 2684 traning the loss is 0.008006075397133827\n",
      "after 2685 traning the loss is 0.002446421654894948\n",
      "after 2686 traning the loss is 0.0011577685363590717\n",
      "after 2687 traning the loss is 0.0015691319713369012\n",
      "after 2688 traning the loss is 0.014991428703069687\n",
      "after 2689 traning the loss is 0.007591931615024805\n",
      "after 2690 traning the loss is 0.012625407427549362\n",
      "after 2691 traning the loss is 0.005694281775504351\n",
      "after 2692 traning the loss is 0.004132088273763657\n",
      "after 2693 traning the loss is 0.0030954100657254457\n",
      "after 2694 traning the loss is 0.005047473590821028\n",
      "after 2695 traning the loss is 0.0031648161821067333\n",
      "after 2696 traning the loss is 0.001446288195438683\n",
      "after 2697 traning the loss is 0.0013975921319797635\n",
      "after 2698 traning the loss is 0.003685153555124998\n",
      "after 2699 traning the loss is 0.04970953240990639\n",
      "after 2700 traning the loss is 0.001565073849633336\n",
      "after 2701 traning the loss is 0.00893922708928585\n",
      "after 2702 traning the loss is 0.00294822221621871\n",
      "after 2703 traning the loss is 0.001337359077297151\n",
      "after 2704 traning the loss is 0.002122003585100174\n",
      "after 2705 traning the loss is 0.0012604690855368972\n",
      "after 2706 traning the loss is 0.000779708381742239\n",
      "after 2707 traning the loss is 0.0036435681395232677\n",
      "after 2708 traning the loss is 0.002416683826595545\n",
      "after 2709 traning the loss is 0.0028666334692388773\n",
      "after 2710 traning the loss is 0.0011697378940880299\n",
      "after 2711 traning the loss is 0.019703691825270653\n",
      "after 2712 traning the loss is 0.0021736198104918003\n",
      "after 2713 traning the loss is 0.0007467333925887942\n",
      "after 2714 traning the loss is 0.0005607721977867186\n",
      "after 2715 traning the loss is 0.0005587777122855186\n",
      "after 2716 traning the loss is 0.059901561588048935\n",
      "after 2717 traning the loss is 0.001212085597217083\n",
      "after 2718 traning the loss is 0.0005815191543661058\n",
      "after 2719 traning the loss is 0.0006345883011817932\n",
      "after 2720 traning the loss is 0.001294654211960733\n",
      "after 2721 traning the loss is 0.0026248737704008818\n",
      "after 2722 traning the loss is 0.0009593524737283587\n",
      "after 2723 traning the loss is 0.001526502426713705\n",
      "after 2724 traning the loss is 0.007693908642977476\n",
      "after 2725 traning the loss is 0.001066730241291225\n",
      "after 2726 traning the loss is 0.0014662423636764288\n",
      "after 2727 traning the loss is 0.016305522993206978\n",
      "after 2728 traning the loss is 0.0043639084324240685\n",
      "after 2729 traning the loss is 0.006281768903136253\n",
      "after 2730 traning the loss is 0.006324909161776304\n",
      "after 2731 traning the loss is 0.001384068513289094\n",
      "after 2732 traning the loss is 0.0014271698892116547\n",
      "after 2733 traning the loss is 0.04237046465277672\n",
      "after 2734 traning the loss is 0.007366603706032038\n",
      "after 2735 traning the loss is 0.016485629603266716\n",
      "after 2736 traning the loss is 0.001475486671552062\n",
      "after 2737 traning the loss is 0.0008291716803796589\n",
      "after 2738 traning the loss is 0.001232774113304913\n",
      "after 2739 traning the loss is 0.0023566349409520626\n",
      "after 2740 traning the loss is 0.032737620174884796\n",
      "after 2741 traning the loss is 0.0007938555208966136\n",
      "after 2742 traning the loss is 0.0006541211041621864\n",
      "after 2743 traning the loss is 0.004109496716409922\n",
      "after 2744 traning the loss is 0.0008551491191610694\n",
      "after 2745 traning the loss is 0.00034561200300231576\n",
      "after 2746 traning the loss is 0.000489332596771419\n",
      "after 2747 traning the loss is 0.000838718842715025\n",
      "after 2748 traning the loss is 0.002498744521290064\n",
      "after 2749 traning the loss is 0.0026271443348377943\n",
      "after 2750 traning the loss is 0.10391101986169815\n",
      "after 2751 traning the loss is 0.03323257714509964\n",
      "after 2752 traning the loss is 0.02936704270541668\n",
      "after 2753 traning the loss is 0.0004977292264811695\n",
      "after 2754 traning the loss is 0.0022533086594194174\n",
      "after 2755 traning the loss is 0.00026641160366125405\n",
      "after 2756 traning the loss is 0.0008244403870776296\n",
      "after 2757 traning the loss is 0.0045694527216255665\n",
      "after 2758 traning the loss is 0.0020141657441854477\n",
      "after 2759 traning the loss is 0.009334934875369072\n",
      "after 2760 traning the loss is 0.005708762444555759\n",
      "after 2761 traning the loss is 0.00215033907443285\n",
      "after 2762 traning the loss is 0.0020215469412505627\n",
      "after 2763 traning the loss is 0.002393263392150402\n",
      "after 2764 traning the loss is 0.0023312103003263474\n",
      "after 2765 traning the loss is 0.0012427851324900985\n",
      "after 2766 traning the loss is 0.0039115771651268005\n",
      "after 2767 traning the loss is 0.0010537825291976333\n",
      "after 2768 traning the loss is 0.002230894286185503\n",
      "after 2769 traning the loss is 0.0007157436339184642\n",
      "after 2770 traning the loss is 0.0024027321487665176\n",
      "after 2771 traning the loss is 0.0022493326105177402\n",
      "after 2772 traning the loss is 0.0017085846047848463\n",
      "after 2773 traning the loss is 0.0011016079224646091\n",
      "after 2774 traning the loss is 0.001126239076256752\n",
      "after 2775 traning the loss is 0.0005869316519238055\n",
      "after 2776 traning the loss is 0.0004966767155565321\n",
      "after 2777 traning the loss is 0.00039887643652036786\n",
      "after 2778 traning the loss is 0.018372684717178345\n",
      "after 2779 traning the loss is 0.0007284440216608346\n",
      "after 2780 traning the loss is 0.0004841855843551457\n",
      "after 2781 traning the loss is 0.002059406600892544\n",
      "after 2782 traning the loss is 0.00247433059848845\n",
      "after 2783 traning the loss is 0.0005778116174042225\n",
      "after 2784 traning the loss is 0.0010144909610971808\n",
      "after 2785 traning the loss is 0.0015251310542225838\n",
      "after 2786 traning the loss is 0.009036255069077015\n",
      "after 2787 traning the loss is 0.0007390751270577312\n",
      "after 2788 traning the loss is 0.005576192867010832\n",
      "after 2789 traning the loss is 0.0023353754077106714\n",
      "after 2790 traning the loss is 0.0006180282216519117\n",
      "after 2791 traning the loss is 0.006837052293121815\n",
      "after 2792 traning the loss is 0.0019412043038755655\n",
      "after 2793 traning the loss is 0.0022276698146015406\n",
      "after 2794 traning the loss is 0.0005668101948685944\n",
      "after 2795 traning the loss is 0.006759423762559891\n",
      "after 2796 traning the loss is 0.0007280395948328078\n",
      "after 2797 traning the loss is 0.0044865682721138\n",
      "after 2798 traning the loss is 0.0017395287286490202\n",
      "after 2799 traning the loss is 0.02586500160396099\n",
      "after 2800 traning the loss is 0.0017024821136146784\n",
      "after 2801 traning the loss is 0.0006930507952347398\n",
      "after 2802 traning the loss is 0.0027857848908752203\n",
      "after 2803 traning the loss is 0.0015422957949340343\n",
      "after 2804 traning the loss is 0.0010813204571604729\n",
      "after 2805 traning the loss is 0.0005299766780808568\n",
      "after 2806 traning the loss is 0.0013341910671442747\n",
      "after 2807 traning the loss is 0.00280682067386806\n",
      "after 2808 traning the loss is 0.0007601754041388631\n",
      "after 2809 traning the loss is 0.0006254661129787564\n",
      "after 2810 traning the loss is 0.0024532517418265343\n",
      "after 2811 traning the loss is 0.0029058728832751513\n",
      "after 2812 traning the loss is 0.0004490304854698479\n",
      "after 2813 traning the loss is 0.0002864373382180929\n",
      "after 2814 traning the loss is 0.003591875545680523\n",
      "after 2815 traning the loss is 0.0007879872573539615\n",
      "after 2816 traning the loss is 0.1267160326242447\n",
      "after 2817 traning the loss is 0.003857264295220375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2818 traning the loss is 0.00242160027846694\n",
      "after 2819 traning the loss is 0.0004419456818141043\n",
      "after 2820 traning the loss is 0.001137676415964961\n",
      "after 2821 traning the loss is 0.00047895239549688995\n",
      "after 2822 traning the loss is 0.000514162820763886\n",
      "after 2823 traning the loss is 0.007542337290942669\n",
      "after 2824 traning the loss is 0.0009507309878244996\n",
      "after 2825 traning the loss is 0.0009393866639584303\n",
      "after 2826 traning the loss is 0.00033233087742701173\n",
      "after 2827 traning the loss is 0.00047819624887779355\n",
      "after 2828 traning the loss is 0.0011712395353242755\n",
      "after 2829 traning the loss is 0.0025204960256814957\n",
      "after 2830 traning the loss is 0.0002727624087128788\n",
      "after 2831 traning the loss is 0.0011960238916799426\n",
      "after 2832 traning the loss is 0.001058501424267888\n",
      "after 2833 traning the loss is 0.00042491554631851614\n",
      "after 2834 traning the loss is 0.0009654315072111785\n",
      "after 2835 traning the loss is 0.00030200337641872466\n",
      "after 2836 traning the loss is 0.0010154165793210268\n",
      "after 2837 traning the loss is 0.001654907362535596\n",
      "after 2838 traning the loss is 0.0009800286497920752\n",
      "after 2839 traning the loss is 0.0011422899551689625\n",
      "after 2840 traning the loss is 0.0009398313704878092\n",
      "after 2841 traning the loss is 0.0006279215449467301\n",
      "after 2842 traning the loss is 0.0007811755058355629\n",
      "after 2843 traning the loss is 0.001178722595795989\n",
      "after 2844 traning the loss is 0.0007851999835111201\n",
      "after 2845 traning the loss is 0.016969194635748863\n",
      "after 2846 traning the loss is 0.0037461603060364723\n",
      "after 2847 traning the loss is 0.0007096205954439938\n",
      "after 2848 traning the loss is 0.0007209506002254784\n",
      "after 2849 traning the loss is 0.0004194787470623851\n",
      "after 2850 traning the loss is 0.00043315874063409865\n",
      "after 2851 traning the loss is 0.0010718901176005602\n",
      "after 2852 traning the loss is 0.00030704622622579336\n",
      "after 2853 traning the loss is 0.0007403458585031331\n",
      "after 2854 traning the loss is 0.00053203827701509\n",
      "after 2855 traning the loss is 0.006209803279489279\n",
      "after 2856 traning the loss is 0.08594700694084167\n",
      "after 2857 traning the loss is 0.00043050310341641307\n",
      "after 2858 traning the loss is 0.000244022739934735\n",
      "after 2859 traning the loss is 0.002435520989820361\n",
      "after 2860 traning the loss is 0.04011286422610283\n",
      "after 2861 traning the loss is 0.0007730808574706316\n",
      "after 2862 traning the loss is 0.002446805825456977\n",
      "after 2863 traning the loss is 0.0011787292314693332\n",
      "after 2864 traning the loss is 0.005431240890175104\n",
      "after 2865 traning the loss is 0.20177008211612701\n",
      "after 2866 traning the loss is 0.017855878919363022\n",
      "after 2867 traning the loss is 0.0027367258444428444\n",
      "after 2868 traning the loss is 0.011393971741199493\n",
      "after 2869 traning the loss is 0.007585430517792702\n",
      "after 2870 traning the loss is 0.006221896968781948\n",
      "after 2871 traning the loss is 0.0033544590696692467\n",
      "after 2872 traning the loss is 0.0012692741584032774\n",
      "after 2873 traning the loss is 0.002671725582331419\n",
      "after 2874 traning the loss is 0.0002017530641751364\n",
      "after 2875 traning the loss is 0.0009210502030327916\n",
      "after 2876 traning the loss is 0.0012837836984544992\n",
      "after 2877 traning the loss is 0.00046870065852999687\n",
      "after 2878 traning the loss is 0.0009614884620532393\n",
      "after 2879 traning the loss is 0.13569045066833496\n",
      "after 2880 traning the loss is 0.00206854403950274\n",
      "after 2881 traning the loss is 0.0008164478931576014\n",
      "after 2882 traning the loss is 0.031079920008778572\n",
      "after 2883 traning the loss is 0.0011534478981047869\n",
      "after 2884 traning the loss is 0.0021575663704425097\n",
      "after 2885 traning the loss is 0.0005091975326649845\n",
      "after 2886 traning the loss is 0.011729538440704346\n",
      "after 2887 traning the loss is 0.0027271765284240246\n",
      "after 2888 traning the loss is 0.0017525614239275455\n",
      "after 2889 traning the loss is 0.002902519190683961\n",
      "after 2890 traning the loss is 0.001893875072710216\n",
      "after 2891 traning the loss is 0.002343210158869624\n",
      "after 2892 traning the loss is 0.0007457109168171883\n",
      "after 2893 traning the loss is 0.0008905830327421427\n",
      "after 2894 traning the loss is 0.0014907479053363204\n",
      "after 2895 traning the loss is 0.014423711225390434\n",
      "after 2896 traning the loss is 0.03737301751971245\n",
      "after 2897 traning the loss is 0.0009811765048652887\n",
      "after 2898 traning the loss is 0.0073607368394732475\n",
      "after 2899 traning the loss is 0.001376170082949102\n",
      "after 2900 traning the loss is 0.011161831207573414\n",
      "after 2901 traning the loss is 0.006594193167984486\n",
      "after 2902 traning the loss is 0.006353328935801983\n",
      "after 2903 traning the loss is 0.0033307222183793783\n",
      "after 2904 traning the loss is 0.002896640682592988\n",
      "after 2905 traning the loss is 0.004391364753246307\n",
      "after 2906 traning the loss is 0.0012709373841062188\n",
      "after 2907 traning the loss is 0.00040811774670146406\n",
      "after 2908 traning the loss is 0.001128369360230863\n",
      "after 2909 traning the loss is 0.0005104524316266179\n",
      "after 2910 traning the loss is 0.0013812368270009756\n",
      "after 2911 traning the loss is 0.0013054318260401487\n",
      "after 2912 traning the loss is 0.0012944696936756372\n",
      "after 2913 traning the loss is 0.0011807199334725738\n",
      "after 2914 traning the loss is 0.006812051869928837\n",
      "after 2915 traning the loss is 0.006807402707636356\n",
      "after 2916 traning the loss is 0.0006342678098008037\n",
      "after 2917 traning the loss is 0.009866379201412201\n",
      "after 2918 traning the loss is 0.014844337478280067\n",
      "after 2919 traning the loss is 0.00030183803755789995\n",
      "after 2920 traning the loss is 0.002837918233126402\n",
      "after 2921 traning the loss is 0.000719178409781307\n",
      "after 2922 traning the loss is 0.0013787178322672844\n",
      "after 2923 traning the loss is 0.00040849883225746453\n",
      "after 2924 traning the loss is 0.0006322099361568689\n",
      "after 2925 traning the loss is 0.0007871502311900258\n",
      "after 2926 traning the loss is 0.0020443350076675415\n",
      "after 2927 traning the loss is 0.000621531973592937\n",
      "after 2928 traning the loss is 0.0005024612764827907\n",
      "after 2929 traning the loss is 0.002682555466890335\n",
      "after 2930 traning the loss is 0.0005170863005332649\n",
      "after 2931 traning the loss is 0.028248365968465805\n",
      "after 2932 traning the loss is 0.0009237657650373876\n",
      "after 2933 traning the loss is 0.0006892266683280468\n",
      "after 2934 traning the loss is 0.0009518314036540687\n",
      "after 2935 traning the loss is 0.005450939293950796\n",
      "after 2936 traning the loss is 0.007257171906530857\n",
      "after 2937 traning the loss is 0.07937470078468323\n",
      "after 2938 traning the loss is 0.013307686895132065\n",
      "after 2939 traning the loss is 0.004228675737977028\n",
      "after 2940 traning the loss is 0.0007063114317134023\n",
      "after 2941 traning the loss is 0.0011573763331398368\n",
      "after 2942 traning the loss is 0.0007684237789362669\n",
      "after 2943 traning the loss is 0.07685568928718567\n",
      "after 2944 traning the loss is 0.001133967423811555\n",
      "after 2945 traning the loss is 0.0013292004587128758\n",
      "after 2946 traning the loss is 0.0005707582458853722\n",
      "after 2947 traning the loss is 0.0005935482913628221\n",
      "after 2948 traning the loss is 0.06043924763798714\n",
      "after 2949 traning the loss is 0.0011576092801988125\n",
      "after 2950 traning the loss is 0.0008131503127515316\n",
      "after 2951 traning the loss is 0.021954750642180443\n",
      "after 2952 traning the loss is 0.19253438711166382\n",
      "after 2953 traning the loss is 0.0018014502711594105\n",
      "after 2954 traning the loss is 0.018693367019295692\n",
      "after 2955 traning the loss is 0.0019492597784847021\n",
      "after 2956 traning the loss is 0.0005246078362688422\n",
      "after 2957 traning the loss is 0.02734348736703396\n",
      "after 2958 traning the loss is 0.0003175277670379728\n",
      "after 2959 traning the loss is 0.03644613176584244\n",
      "after 2960 traning the loss is 0.0008361248765140772\n",
      "after 2961 traning the loss is 0.0003607594408094883\n",
      "after 2962 traning the loss is 0.0005950195482000709\n",
      "after 2963 traning the loss is 0.002064282074570656\n",
      "after 2964 traning the loss is 0.0052684759721159935\n",
      "after 2965 traning the loss is 0.0588451586663723\n",
      "after 2966 traning the loss is 0.004794837906956673\n",
      "after 2967 traning the loss is 0.0008192754467017949\n",
      "after 2968 traning the loss is 0.00039406545693054795\n",
      "after 2969 traning the loss is 0.0007197349332273006\n",
      "after 2970 traning the loss is 0.00034703308483585715\n",
      "after 2971 traning the loss is 0.0008692382252775133\n",
      "after 2972 traning the loss is 0.0007395024294964969\n",
      "after 2973 traning the loss is 0.000900331768207252\n",
      "after 2974 traning the loss is 0.008575815707445145\n",
      "after 2975 traning the loss is 0.0007644328870810568\n",
      "after 2976 traning the loss is 0.10051392763853073\n",
      "after 2977 traning the loss is 0.001080962480045855\n",
      "after 2978 traning the loss is 0.0008500706171616912\n",
      "after 2979 traning the loss is 0.0006613607401959598\n",
      "after 2980 traning the loss is 0.003478612285107374\n",
      "after 2981 traning the loss is 0.0011026621796190739\n",
      "after 2982 traning the loss is 0.05582958087325096\n",
      "after 2983 traning the loss is 0.0008146959007717669\n",
      "after 2984 traning the loss is 0.015208832919597626\n",
      "after 2985 traning the loss is 0.0033300674986094236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 2986 traning the loss is 0.0038529890589416027\n",
      "after 2987 traning the loss is 0.004334553610533476\n",
      "after 2988 traning the loss is 0.0022561070509254932\n",
      "after 2989 traning the loss is 0.003319626674056053\n",
      "after 2990 traning the loss is 0.007142472546547651\n",
      "after 2991 traning the loss is 0.0018066087504848838\n",
      "after 2992 traning the loss is 0.0022890912368893623\n",
      "after 2993 traning the loss is 0.002537303604185581\n",
      "after 2994 traning the loss is 0.003589319996535778\n",
      "after 2995 traning the loss is 0.0012209555134177208\n",
      "after 2996 traning the loss is 0.0007914320449344814\n",
      "after 2997 traning the loss is 0.0005382148665376008\n",
      "after 2998 traning the loss is 0.001556734787300229\n",
      "after 2999 traning the loss is 0.0014545179437845945\n",
      "after 3000 traning the loss is 0.06750575453042984\n",
      "after 3001 traning the loss is 0.0010191089240834117\n",
      "after 3002 traning the loss is 0.0005414191982708871\n",
      "after 3003 traning the loss is 0.0007094623288139701\n",
      "after 3004 traning the loss is 0.0004345707129687071\n",
      "after 3005 traning the loss is 0.0007300401921384037\n",
      "after 3006 traning the loss is 0.0005215499550104141\n",
      "after 3007 traning the loss is 0.0006529837846755981\n",
      "after 3008 traning the loss is 0.000862378568854183\n",
      "after 3009 traning the loss is 0.0005542516009882092\n",
      "after 3010 traning the loss is 0.0010446002706885338\n",
      "after 3011 traning the loss is 0.002046749461442232\n",
      "after 3012 traning the loss is 0.0015816837549209595\n",
      "after 3013 traning the loss is 0.0008495072252117097\n",
      "after 3014 traning the loss is 0.001998237334191799\n",
      "after 3015 traning the loss is 0.002231040969491005\n",
      "after 3016 traning the loss is 0.000942837679758668\n",
      "after 3017 traning the loss is 0.0017797290347516537\n",
      "after 3018 traning the loss is 0.0004270383215043694\n",
      "after 3019 traning the loss is 0.00045316849718801677\n",
      "after 3020 traning the loss is 0.014377915300428867\n",
      "after 3021 traning the loss is 0.0007667356403544545\n",
      "after 3022 traning the loss is 0.017779219895601273\n",
      "after 3023 traning the loss is 0.011492508463561535\n",
      "after 3024 traning the loss is 0.0005805474938824773\n",
      "after 3025 traning the loss is 0.002397692296653986\n",
      "after 3026 traning the loss is 0.0013021855847910047\n",
      "after 3027 traning the loss is 0.0010028945980593562\n",
      "after 3028 traning the loss is 0.0017137153772637248\n",
      "after 3029 traning the loss is 0.0003074575215578079\n",
      "after 3030 traning the loss is 0.0007268124609254301\n",
      "after 3031 traning the loss is 0.004356428049504757\n",
      "after 3032 traning the loss is 0.0004680791462305933\n",
      "after 3033 traning the loss is 0.0032654060050845146\n",
      "after 3034 traning the loss is 0.0013460238697007298\n",
      "after 3035 traning the loss is 0.0005668677040375769\n",
      "after 3036 traning the loss is 0.0011101365089416504\n",
      "after 3037 traning the loss is 0.0017037156503647566\n",
      "after 3038 traning the loss is 0.00040747260209172964\n",
      "after 3039 traning the loss is 0.001628513098694384\n",
      "after 3040 traning the loss is 0.0007989650475792587\n",
      "after 3041 traning the loss is 0.0008754550945013762\n",
      "after 3042 traning the loss is 0.0010281692957505584\n",
      "after 3043 traning the loss is 0.0006330085452646017\n",
      "after 3044 traning the loss is 0.0005905869184061885\n",
      "after 3045 traning the loss is 0.000880806299392134\n",
      "after 3046 traning the loss is 0.0028626148123294115\n",
      "after 3047 traning the loss is 0.0008376450859941542\n",
      "after 3048 traning the loss is 0.0888720229268074\n",
      "after 3049 traning the loss is 0.00017723016208037734\n",
      "after 3050 traning the loss is 0.0012545404024422169\n",
      "after 3051 traning the loss is 0.0012676154728978872\n",
      "after 3052 traning the loss is 0.0015179282054305077\n",
      "after 3053 traning the loss is 0.0014449777081608772\n",
      "after 3054 traning the loss is 0.0021315203048288822\n",
      "after 3055 traning the loss is 0.003279638011008501\n",
      "after 3056 traning the loss is 0.007541467435657978\n",
      "after 3057 traning the loss is 0.002106409054249525\n",
      "after 3058 traning the loss is 0.0017144131707027555\n",
      "after 3059 traning the loss is 0.0018302623648196459\n",
      "after 3060 traning the loss is 0.005530364345759153\n",
      "after 3061 traning the loss is 0.004673948511481285\n",
      "after 3062 traning the loss is 0.0007821801118552685\n",
      "after 3063 traning the loss is 0.0006938808946870267\n",
      "after 3064 traning the loss is 0.0016158074140548706\n",
      "after 3065 traning the loss is 0.0020232778042554855\n",
      "after 3066 traning the loss is 0.0016427560476586223\n",
      "after 3067 traning the loss is 0.004051326308399439\n",
      "after 3068 traning the loss is 0.0013559071812778711\n",
      "after 3069 traning the loss is 0.000659245066344738\n",
      "after 3070 traning the loss is 0.00042481973650865257\n",
      "after 3071 traning the loss is 0.0013939929194748402\n",
      "after 3072 traning the loss is 0.0011911566834896803\n",
      "after 3073 traning the loss is 0.0034127039834856987\n",
      "after 3074 traning the loss is 0.0007854908471927047\n",
      "after 3075 traning the loss is 0.011710681952536106\n",
      "after 3076 traning the loss is 0.001878627692349255\n",
      "after 3077 traning the loss is 0.0006233512540347874\n",
      "after 3078 traning the loss is 0.00039642839692533016\n",
      "after 3079 traning the loss is 0.021236911416053772\n",
      "after 3080 traning the loss is 0.0016833387780934572\n",
      "after 3081 traning the loss is 0.0002186595811508596\n",
      "after 3082 traning the loss is 0.0003126777883153409\n",
      "after 3083 traning the loss is 0.016318300738930702\n",
      "after 3084 traning the loss is 0.05855678394436836\n",
      "after 3085 traning the loss is 0.00043786861351691186\n",
      "after 3086 traning the loss is 0.00044079736107960343\n",
      "after 3087 traning the loss is 0.003527622437104583\n",
      "after 3088 traning the loss is 0.0004884331719949841\n",
      "after 3089 traning the loss is 0.0004318685387261212\n",
      "after 3090 traning the loss is 0.00024129457597155124\n",
      "after 3091 traning the loss is 0.02545235864818096\n",
      "after 3092 traning the loss is 0.0016207847511395812\n",
      "after 3093 traning the loss is 0.00042495079105719924\n",
      "after 3094 traning the loss is 0.000963864556979388\n",
      "after 3095 traning the loss is 0.0007393494015559554\n",
      "after 3096 traning the loss is 0.020494915544986725\n",
      "after 3097 traning the loss is 0.003443865804001689\n",
      "after 3098 traning the loss is 0.0015252024168148637\n",
      "after 3099 traning the loss is 0.002498654881492257\n",
      "after 3100 traning the loss is 0.002386902691796422\n",
      "after 3101 traning the loss is 0.007412143982946873\n",
      "after 3102 traning the loss is 0.00043039603042416275\n",
      "after 3103 traning the loss is 0.000503169430885464\n",
      "after 3104 traning the loss is 0.00047727071796543896\n",
      "after 3105 traning the loss is 0.0010515560861676931\n",
      "after 3106 traning the loss is 0.0012334451312199235\n",
      "after 3107 traning the loss is 0.0030857257079333067\n",
      "after 3108 traning the loss is 0.0029345694929361343\n",
      "after 3109 traning the loss is 0.00045316354953683913\n",
      "after 3110 traning the loss is 0.00040169863495975733\n",
      "after 3111 traning the loss is 0.0005178906721994281\n",
      "after 3112 traning the loss is 0.00027843372663483024\n",
      "after 3113 traning the loss is 0.001994076184928417\n",
      "after 3114 traning the loss is 0.00027128710644319654\n",
      "after 3115 traning the loss is 0.018262827768921852\n",
      "after 3116 traning the loss is 0.002053328324109316\n",
      "after 3117 traning the loss is 0.001990647753700614\n",
      "after 3118 traning the loss is 0.000363868719432503\n",
      "after 3119 traning the loss is 0.0006983306957408786\n",
      "after 3120 traning the loss is 0.0004787671787198633\n",
      "after 3121 traning the loss is 0.0006358947139233351\n",
      "after 3122 traning the loss is 0.0004278003179933876\n",
      "after 3123 traning the loss is 0.0006802662392146885\n",
      "after 3124 traning the loss is 0.007216618396341801\n",
      "after 3125 traning the loss is 0.0010606282157823443\n",
      "after 3126 traning the loss is 0.0007356585119850934\n",
      "after 3127 traning the loss is 0.005089507903903723\n",
      "after 3128 traning the loss is 0.12893083691596985\n",
      "after 3129 traning the loss is 0.006607286166399717\n",
      "after 3130 traning the loss is 0.0011050538159906864\n",
      "after 3131 traning the loss is 0.0009144130162894726\n",
      "after 3132 traning the loss is 0.0007207883172668517\n",
      "after 3133 traning the loss is 0.00047101540258154273\n",
      "after 3134 traning the loss is 0.0007984270923770964\n",
      "after 3135 traning the loss is 0.04914110153913498\n",
      "after 3136 traning the loss is 0.0006578987231478095\n",
      "after 3137 traning the loss is 0.0007467136019840837\n",
      "after 3138 traning the loss is 0.0007003324571996927\n",
      "after 3139 traning the loss is 0.002030438045039773\n",
      "after 3140 traning the loss is 0.0006044373731128871\n",
      "after 3141 traning the loss is 0.0011162376031279564\n",
      "after 3142 traning the loss is 0.0007517295889556408\n",
      "after 3143 traning the loss is 0.011091002263128757\n",
      "after 3144 traning the loss is 0.0015507818898186088\n",
      "after 3145 traning the loss is 0.07631902396678925\n",
      "after 3146 traning the loss is 0.0380636565387249\n",
      "after 3147 traning the loss is 0.0027537187561392784\n",
      "after 3148 traning the loss is 0.004728816449642181\n",
      "after 3149 traning the loss is 0.0028049019165337086\n",
      "after 3150 traning the loss is 0.008399956859648228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3151 traning the loss is 0.0026775647420436144\n",
      "after 3152 traning the loss is 0.0040642330422997475\n",
      "after 3153 traning the loss is 0.00202182587236166\n",
      "after 3154 traning the loss is 0.0010383272310718894\n",
      "after 3155 traning the loss is 0.00239698332734406\n",
      "after 3156 traning the loss is 0.0012372995261102915\n",
      "after 3157 traning the loss is 0.0012821231503039598\n",
      "after 3158 traning the loss is 0.0019578319042921066\n",
      "after 3159 traning the loss is 0.0017329850234091282\n",
      "after 3160 traning the loss is 0.0008375463075935841\n",
      "after 3161 traning the loss is 0.0011669807136058807\n",
      "after 3162 traning the loss is 0.0006380496779456735\n",
      "after 3163 traning the loss is 0.004705218132585287\n",
      "after 3164 traning the loss is 0.0005000642850063741\n",
      "after 3165 traning the loss is 0.0034531422425061464\n",
      "after 3166 traning the loss is 0.00934379268437624\n",
      "after 3167 traning the loss is 0.0005780482897534966\n",
      "after 3168 traning the loss is 0.00036561075830832124\n",
      "after 3169 traning the loss is 0.0003879875876009464\n",
      "after 3170 traning the loss is 0.0008139577694237232\n",
      "after 3171 traning the loss is 0.00018758396618068218\n",
      "after 3172 traning the loss is 0.0010090916184708476\n",
      "after 3173 traning the loss is 0.001818853779695928\n",
      "after 3174 traning the loss is 0.000305636553093791\n",
      "after 3175 traning the loss is 0.0011603562161326408\n",
      "after 3176 traning the loss is 0.003302845871075988\n",
      "after 3177 traning the loss is 0.000301048276014626\n",
      "after 3178 traning the loss is 0.001035911962389946\n",
      "after 3179 traning the loss is 0.007699682377278805\n",
      "after 3180 traning the loss is 0.001440041116438806\n",
      "after 3181 traning the loss is 0.0036426011938601732\n",
      "after 3182 traning the loss is 0.000244112205109559\n",
      "after 3183 traning the loss is 0.0009308791486546397\n",
      "after 3184 traning the loss is 0.08064263314008713\n",
      "after 3185 traning the loss is 0.0002124380407622084\n",
      "after 3186 traning the loss is 0.00036838414962403476\n",
      "after 3187 traning the loss is 0.0008628461509943008\n",
      "after 3188 traning the loss is 0.0033580674789845943\n",
      "after 3189 traning the loss is 0.0008690397371537983\n",
      "after 3190 traning the loss is 0.005396428517997265\n",
      "after 3191 traning the loss is 0.0009357379167340696\n",
      "after 3192 traning the loss is 0.0005993919330649078\n",
      "after 3193 traning the loss is 0.0034094920847564936\n",
      "after 3194 traning the loss is 0.001294736284762621\n",
      "after 3195 traning the loss is 0.0008207004284486175\n",
      "after 3196 traning the loss is 0.0018221040954813361\n",
      "after 3197 traning the loss is 0.0025784794706851244\n",
      "after 3198 traning the loss is 0.0004948570276610553\n",
      "after 3199 traning the loss is 0.0007967399433255196\n",
      "after 3200 traning the loss is 0.06895510107278824\n",
      "after 3201 traning the loss is 0.0008431107271462679\n",
      "after 3202 traning the loss is 0.0005965789896436036\n",
      "after 3203 traning the loss is 0.015808919444680214\n",
      "after 3204 traning the loss is 0.00591270299628377\n",
      "after 3205 traning the loss is 0.0031096411403268576\n",
      "after 3206 traning the loss is 0.024868160486221313\n",
      "after 3207 traning the loss is 0.000709196028765291\n",
      "after 3208 traning the loss is 0.000965591287240386\n",
      "after 3209 traning the loss is 0.001908091246150434\n",
      "after 3210 traning the loss is 0.0022823913022875786\n",
      "after 3211 traning the loss is 0.03417695686221123\n",
      "after 3212 traning the loss is 0.0027825685683637857\n",
      "after 3213 traning the loss is 0.0017441026866436005\n",
      "after 3214 traning the loss is 0.026508809998631477\n",
      "after 3215 traning the loss is 0.0032022730447351933\n",
      "after 3216 traning the loss is 0.0013732967199757695\n",
      "after 3217 traning the loss is 0.006881267763674259\n",
      "after 3218 traning the loss is 0.0010870638070628047\n",
      "after 3219 traning the loss is 0.002657949924468994\n",
      "after 3220 traning the loss is 0.004027990624308586\n",
      "after 3221 traning the loss is 0.15877944231033325\n",
      "after 3222 traning the loss is 0.005329802166670561\n",
      "after 3223 traning the loss is 0.0006491364329122007\n",
      "after 3224 traning the loss is 0.0020774859003722668\n",
      "after 3225 traning the loss is 0.004096270073205233\n",
      "after 3226 traning the loss is 0.00074510567355901\n",
      "after 3227 traning the loss is 0.00013757811393588781\n",
      "after 3228 traning the loss is 0.0008621672168374062\n",
      "after 3229 traning the loss is 0.0028622345998883247\n",
      "after 3230 traning the loss is 0.0005331674474291503\n",
      "after 3231 traning the loss is 0.001383488648571074\n",
      "after 3232 traning the loss is 0.012328725308179855\n",
      "after 3233 traning the loss is 0.0010516939219087362\n",
      "after 3234 traning the loss is 0.0007709030760452151\n",
      "after 3235 traning the loss is 0.0007234921213239431\n",
      "after 3236 traning the loss is 0.004192132968455553\n",
      "after 3237 traning the loss is 0.00024997733999043703\n",
      "after 3238 traning the loss is 0.0005676172440871596\n",
      "after 3239 traning the loss is 0.00035441722138784826\n",
      "after 3240 traning the loss is 0.003877511713653803\n",
      "after 3241 traning the loss is 0.00011792477744165808\n",
      "after 3242 traning the loss is 0.00014831626322120428\n",
      "after 3243 traning the loss is 0.0012011206708848476\n",
      "after 3244 traning the loss is 0.0005947833997197449\n",
      "after 3245 traning the loss is 0.002787506440654397\n",
      "after 3246 traning the loss is 0.0005625691846944392\n",
      "after 3247 traning the loss is 0.0005749560659751296\n",
      "after 3248 traning the loss is 0.001649211160838604\n",
      "after 3249 traning the loss is 0.0017088414169847965\n",
      "after 3250 traning the loss is 0.00033401421387679875\n",
      "after 3251 traning the loss is 0.0005058972747065127\n",
      "after 3252 traning the loss is 0.0003333953791297972\n",
      "after 3253 traning the loss is 0.00039526185719296336\n",
      "after 3254 traning the loss is 0.0009147475939244032\n",
      "after 3255 traning the loss is 0.0007560913800261915\n",
      "after 3256 traning the loss is 0.0006465126061812043\n",
      "after 3257 traning the loss is 0.0011527970200404525\n",
      "after 3258 traning the loss is 0.0006190657150000334\n",
      "after 3259 traning the loss is 0.00043750432087108493\n",
      "after 3260 traning the loss is 0.0008307662792503834\n",
      "after 3261 traning the loss is 0.0004543409449979663\n",
      "after 3262 traning the loss is 0.00047249835915863514\n",
      "after 3263 traning the loss is 0.0003707183641381562\n",
      "after 3264 traning the loss is 0.0011181347072124481\n",
      "after 3265 traning the loss is 0.002193113323301077\n",
      "after 3266 traning the loss is 0.00020593976660165936\n",
      "after 3267 traning the loss is 0.007338452618569136\n",
      "after 3268 traning the loss is 0.001133620971813798\n",
      "after 3269 traning the loss is 0.0010015468578785658\n",
      "after 3270 traning the loss is 0.000547094619832933\n",
      "after 3271 traning the loss is 0.0018376304069533944\n",
      "after 3272 traning the loss is 0.00368851562961936\n",
      "after 3273 traning the loss is 0.0010128854773938656\n",
      "after 3274 traning the loss is 0.0010303119197487831\n",
      "after 3275 traning the loss is 0.0006043647299520671\n",
      "after 3276 traning the loss is 0.0008342189248651266\n",
      "after 3277 traning the loss is 0.0008626291528344154\n",
      "after 3278 traning the loss is 0.03451082110404968\n",
      "after 3279 traning the loss is 0.0008451149333268404\n",
      "after 3280 traning the loss is 0.0005466528818942606\n",
      "after 3281 traning the loss is 0.00018943157920148224\n",
      "after 3282 traning the loss is 0.0007457166211679578\n",
      "after 3283 traning the loss is 0.0011137105757370591\n",
      "after 3284 traning the loss is 0.0017984432633966208\n",
      "after 3285 traning the loss is 0.0011816257610917091\n",
      "after 3286 traning the loss is 0.00027085060719400644\n",
      "after 3287 traning the loss is 0.023683905601501465\n",
      "after 3288 traning the loss is 0.002722320146858692\n",
      "after 3289 traning the loss is 0.0006796926027163863\n",
      "after 3290 traning the loss is 0.000570906326174736\n",
      "after 3291 traning the loss is 0.0010210649343207479\n",
      "after 3292 traning the loss is 0.00031716859666630626\n",
      "after 3293 traning the loss is 0.0002467810409143567\n",
      "after 3294 traning the loss is 0.0016952697187662125\n",
      "after 3295 traning the loss is 0.0005043142009526491\n",
      "after 3296 traning the loss is 0.00021910651412326843\n",
      "after 3297 traning the loss is 0.02596697211265564\n",
      "after 3298 traning the loss is 0.0003529071109369397\n",
      "after 3299 traning the loss is 0.06118462607264519\n",
      "after 3300 traning the loss is 0.0002856424544006586\n",
      "after 3301 traning the loss is 0.0013812107499688864\n",
      "after 3302 traning the loss is 0.0013322911690920591\n",
      "after 3303 traning the loss is 0.0025980800855904818\n",
      "after 3304 traning the loss is 0.01057068444788456\n",
      "after 3305 traning the loss is 0.012501278892159462\n",
      "after 3306 traning the loss is 0.001005941303446889\n",
      "after 3307 traning the loss is 0.0008193292887881398\n",
      "after 3308 traning the loss is 0.010709891095757484\n",
      "after 3309 traning the loss is 0.001371390768326819\n",
      "after 3310 traning the loss is 0.0002745455130934715\n",
      "after 3311 traning the loss is 0.0006235644686967134\n",
      "after 3312 traning the loss is 0.0003277728392276913\n",
      "after 3313 traning the loss is 0.0003817527904175222\n",
      "after 3314 traning the loss is 0.012197851203382015\n",
      "after 3315 traning the loss is 0.0007578185177408159\n",
      "after 3316 traning the loss is 0.0011213060934096575\n",
      "after 3317 traning the loss is 0.0003237258060835302\n",
      "after 3318 traning the loss is 0.00040229526348412037\n",
      "after 3319 traning the loss is 0.0004502844822127372\n",
      "after 3320 traning the loss is 0.0034878524020314217\n",
      "after 3321 traning the loss is 0.00022772510419599712\n",
      "after 3322 traning the loss is 0.0011760091874748468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3323 traning the loss is 0.00020396594482008368\n",
      "after 3324 traning the loss is 0.00015347960288636386\n",
      "after 3325 traning the loss is 0.0005899504176340997\n",
      "after 3326 traning the loss is 0.0006069471128284931\n",
      "after 3327 traning the loss is 0.0005679455352947116\n",
      "after 3328 traning the loss is 0.2395877242088318\n",
      "after 3329 traning the loss is 0.2199506312608719\n",
      "after 3330 traning the loss is 0.0003247427521273494\n",
      "after 3331 traning the loss is 0.0004284303868189454\n",
      "after 3332 traning the loss is 0.0012598390458151698\n",
      "after 3333 traning the loss is 0.0031780670396983624\n",
      "after 3334 traning the loss is 0.0008738651522435248\n",
      "after 3335 traning the loss is 0.006048062816262245\n",
      "after 3336 traning the loss is 0.0008020630921237171\n",
      "after 3337 traning the loss is 0.0006469243671745062\n",
      "after 3338 traning the loss is 0.006150998640805483\n",
      "after 3339 traning the loss is 0.008119253441691399\n",
      "after 3340 traning the loss is 0.028328802436590195\n",
      "after 3341 traning the loss is 0.003634425112977624\n",
      "after 3342 traning the loss is 0.0015543409390375018\n",
      "after 3343 traning the loss is 0.0004750745138153434\n",
      "after 3344 traning the loss is 0.00038390947156585753\n",
      "after 3345 traning the loss is 0.00044924308895133436\n",
      "after 3346 traning the loss is 0.06906772404909134\n",
      "after 3347 traning the loss is 0.003666071919724345\n",
      "after 3348 traning the loss is 0.0002599424042273313\n",
      "after 3349 traning the loss is 0.17932726442813873\n",
      "after 3350 traning the loss is 0.00019088602857664227\n",
      "after 3351 traning the loss is 0.0016530533321201801\n",
      "after 3352 traning the loss is 0.00021753048349637538\n",
      "after 3353 traning the loss is 0.005644834600389004\n",
      "after 3354 traning the loss is 0.0005578332347795367\n",
      "after 3355 traning the loss is 0.003191234078258276\n",
      "after 3356 traning the loss is 0.00020629177743103355\n",
      "after 3357 traning the loss is 0.01152380183339119\n",
      "after 3358 traning the loss is 0.003571013920009136\n",
      "after 3359 traning the loss is 0.004822881892323494\n",
      "after 3360 traning the loss is 0.009559339843690395\n",
      "after 3361 traning the loss is 0.0011595358373597264\n",
      "after 3362 traning the loss is 0.00026873068418353796\n",
      "after 3363 traning the loss is 0.01857697032392025\n",
      "after 3364 traning the loss is 0.00034635362681001425\n",
      "after 3365 traning the loss is 0.0009691503364592791\n",
      "after 3366 traning the loss is 0.00043458573054522276\n",
      "after 3367 traning the loss is 0.015843281522393227\n",
      "after 3368 traning the loss is 0.0007289519999176264\n",
      "after 3369 traning the loss is 0.0014035184867680073\n",
      "after 3370 traning the loss is 0.001675727660767734\n",
      "after 3371 traning the loss is 0.008095093071460724\n",
      "after 3372 traning the loss is 0.0037121151108294725\n",
      "after 3373 traning the loss is 0.0018550980603322387\n",
      "after 3374 traning the loss is 0.001787498826161027\n",
      "after 3375 traning the loss is 0.0037926961667835712\n",
      "after 3376 traning the loss is 0.0010387168731540442\n",
      "after 3377 traning the loss is 0.0004464346566237509\n",
      "after 3378 traning the loss is 0.0008349746931344271\n",
      "after 3379 traning the loss is 0.00034405128099024296\n",
      "after 3380 traning the loss is 0.02398321032524109\n",
      "after 3381 traning the loss is 0.0021479723509401083\n",
      "after 3382 traning the loss is 0.00018628957332111895\n",
      "after 3383 traning the loss is 0.0016652117483317852\n",
      "after 3384 traning the loss is 0.0008685354259796441\n",
      "after 3385 traning the loss is 0.05711067467927933\n",
      "after 3386 traning the loss is 0.003248870838433504\n",
      "after 3387 traning the loss is 0.0001787936344044283\n",
      "after 3388 traning the loss is 0.0017904090927913785\n",
      "after 3389 traning the loss is 0.0004843584029003978\n",
      "after 3390 traning the loss is 0.00027389966999180615\n",
      "after 3391 traning the loss is 0.0009045271435752511\n",
      "after 3392 traning the loss is 0.0001273002417292446\n",
      "after 3393 traning the loss is 0.00030518975108861923\n",
      "after 3394 traning the loss is 0.1375121772289276\n",
      "after 3395 traning the loss is 0.0008041122346185148\n",
      "after 3396 traning the loss is 0.0003233686147723347\n",
      "after 3397 traning the loss is 0.0002561831788625568\n",
      "after 3398 traning the loss is 0.00026050375890918076\n",
      "after 3399 traning the loss is 0.0008689951500855386\n",
      "after 3400 traning the loss is 0.009027262218296528\n",
      "after 3401 traning the loss is 0.13004609942436218\n",
      "after 3402 traning the loss is 0.0027107074856758118\n",
      "after 3403 traning the loss is 0.002878463827073574\n",
      "after 3404 traning the loss is 0.002891476033255458\n",
      "after 3405 traning the loss is 0.005679246503859758\n",
      "after 3406 traning the loss is 5.87844115216285e-05\n",
      "after 3407 traning the loss is 0.0005108918994665146\n",
      "after 3408 traning the loss is 0.0015374175272881985\n",
      "after 3409 traning the loss is 0.01643981784582138\n",
      "after 3410 traning the loss is 0.00033209568937309086\n",
      "after 3411 traning the loss is 0.0021027838811278343\n",
      "after 3412 traning the loss is 0.0002459973911754787\n",
      "after 3413 traning the loss is 0.0009074397967197001\n",
      "after 3414 traning the loss is 0.0015758017543703318\n",
      "after 3415 traning the loss is 0.00039162422763183713\n",
      "after 3416 traning the loss is 0.0013430643593892455\n",
      "after 3417 traning the loss is 0.00029209512285888195\n",
      "after 3418 traning the loss is 0.0019206806318834424\n",
      "after 3419 traning the loss is 0.017683612182736397\n",
      "after 3420 traning the loss is 0.0015728985890746117\n",
      "after 3421 traning the loss is 0.000811904901638627\n",
      "after 3422 traning the loss is 0.015848778188228607\n",
      "after 3423 traning the loss is 0.0025793896056711674\n",
      "after 3424 traning the loss is 0.0023119025863707066\n",
      "after 3425 traning the loss is 0.0008720114128664136\n",
      "after 3426 traning the loss is 0.0005276412703096867\n",
      "after 3427 traning the loss is 0.002917530480772257\n",
      "after 3428 traning the loss is 0.001224674517288804\n",
      "after 3429 traning the loss is 0.001048815669491887\n",
      "after 3430 traning the loss is 0.0016900694463402033\n",
      "after 3431 traning the loss is 0.0012447916669771075\n",
      "after 3432 traning the loss is 0.011635388247668743\n",
      "after 3433 traning the loss is 0.0012000412680208683\n",
      "after 3434 traning the loss is 0.016903046518564224\n",
      "after 3435 traning the loss is 0.0010715732350945473\n",
      "after 3436 traning the loss is 0.00012125697685405612\n",
      "after 3437 traning the loss is 0.014631562866270542\n",
      "after 3438 traning the loss is 0.0007229158654808998\n",
      "after 3439 traning the loss is 0.0005810009315609932\n",
      "after 3440 traning the loss is 0.034270238131284714\n",
      "after 3441 traning the loss is 0.0020971521735191345\n",
      "after 3442 traning the loss is 0.00025292386999353766\n",
      "after 3443 traning the loss is 0.00288469810038805\n",
      "after 3444 traning the loss is 0.026386477053165436\n",
      "after 3445 traning the loss is 0.00013379174924921244\n",
      "after 3446 traning the loss is 0.03885107859969139\n",
      "after 3447 traning the loss is 0.0206844974309206\n",
      "after 3448 traning the loss is 0.0009028767817653716\n",
      "after 3449 traning the loss is 0.0004340680898167193\n",
      "after 3450 traning the loss is 0.0008609110955148935\n",
      "after 3451 traning the loss is 0.0038641076534986496\n",
      "after 3452 traning the loss is 0.005106549244374037\n",
      "after 3453 traning the loss is 0.00024179700994864106\n",
      "after 3454 traning the loss is 0.0002804021642077714\n",
      "after 3455 traning the loss is 0.0008920409600250423\n",
      "after 3456 traning the loss is 0.0002644225605763495\n",
      "after 3457 traning the loss is 0.00024342384131159633\n",
      "after 3458 traning the loss is 0.00035297812428325415\n",
      "after 3459 traning the loss is 0.00045332350418902934\n",
      "after 3460 traning the loss is 0.00017250602832064033\n",
      "after 3461 traning the loss is 0.0016417918959632516\n",
      "after 3462 traning the loss is 0.001537261763587594\n",
      "after 3463 traning the loss is 0.00020339488401077688\n",
      "after 3464 traning the loss is 0.0005344593664631248\n",
      "after 3465 traning the loss is 0.08490916341543198\n",
      "after 3466 traning the loss is 0.0006460711592808366\n",
      "after 3467 traning the loss is 0.0032665161415934563\n",
      "after 3468 traning the loss is 0.008472634479403496\n",
      "after 3469 traning the loss is 0.0011859731748700142\n",
      "after 3470 traning the loss is 0.0046410029754042625\n",
      "after 3471 traning the loss is 0.0006928513757884502\n",
      "after 3472 traning the loss is 0.0026410480495542288\n",
      "after 3473 traning the loss is 0.004631553310900927\n",
      "after 3474 traning the loss is 0.005965554155409336\n",
      "after 3475 traning the loss is 0.004802638664841652\n",
      "after 3476 traning the loss is 0.003025864018127322\n",
      "after 3477 traning the loss is 0.005725117400288582\n",
      "after 3478 traning the loss is 0.0010112596210092306\n",
      "after 3479 traning the loss is 0.0005585982580669224\n",
      "after 3480 traning the loss is 0.001913670334033668\n",
      "after 3481 traning the loss is 0.0003937791916541755\n",
      "after 3482 traning the loss is 0.00096745730843395\n",
      "after 3483 traning the loss is 0.0004904555389657617\n",
      "after 3484 traning the loss is 0.023793863132596016\n",
      "after 3485 traning the loss is 0.0002740305499173701\n",
      "after 3486 traning the loss is 0.001937592402100563\n",
      "after 3487 traning the loss is 0.06393703818321228\n",
      "after 3488 traning the loss is 0.0009119544411078095\n",
      "after 3489 traning the loss is 0.0025567025877535343\n",
      "after 3490 traning the loss is 0.0031997167970985174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3491 traning the loss is 0.003578880103304982\n",
      "after 3492 traning the loss is 0.011728896759450436\n",
      "after 3493 traning the loss is 0.009264916181564331\n",
      "after 3494 traning the loss is 0.0017631647642701864\n",
      "after 3495 traning the loss is 0.0481719970703125\n",
      "after 3496 traning the loss is 0.004931075032800436\n",
      "after 3497 traning the loss is 0.002762970980256796\n",
      "after 3498 traning the loss is 0.0025699124671518803\n",
      "after 3499 traning the loss is 0.0008720649057067931\n",
      "after 3500 traning the loss is 0.0008113554213196039\n",
      "after 3501 traning the loss is 0.0019576766062527895\n",
      "after 3502 traning the loss is 0.0031927544623613358\n",
      "after 3503 traning the loss is 0.0010573500767350197\n",
      "after 3504 traning the loss is 0.0005140217253938317\n",
      "after 3505 traning the loss is 0.0008356237667612731\n",
      "after 3506 traning the loss is 0.0007116168271750212\n",
      "after 3507 traning the loss is 0.0009524142951704562\n",
      "after 3508 traning the loss is 0.0009272356983274221\n",
      "after 3509 traning the loss is 0.0028787071350961924\n",
      "after 3510 traning the loss is 0.00025211554020643234\n",
      "after 3511 traning the loss is 0.00023884962138254195\n",
      "after 3512 traning the loss is 0.0010361397871747613\n",
      "after 3513 traning the loss is 0.0002611812378745526\n",
      "after 3514 traning the loss is 0.00035315146669745445\n",
      "after 3515 traning the loss is 0.00032655600807629526\n",
      "after 3516 traning the loss is 0.0016233508940786123\n",
      "after 3517 traning the loss is 0.007587753236293793\n",
      "after 3518 traning the loss is 0.0001820810721255839\n",
      "after 3519 traning the loss is 0.00024092887178994715\n",
      "after 3520 traning the loss is 0.0025058980099856853\n",
      "after 3521 traning the loss is 0.0006200263160280883\n",
      "after 3522 traning the loss is 0.000702540623024106\n",
      "after 3523 traning the loss is 0.00018635604646988213\n",
      "after 3524 traning the loss is 0.0002120610442943871\n",
      "after 3525 traning the loss is 0.02230711281299591\n",
      "after 3526 traning the loss is 0.0015876961406320333\n",
      "after 3527 traning the loss is 0.00047069249558262527\n",
      "after 3528 traning the loss is 0.0005582274170592427\n",
      "after 3529 traning the loss is 0.0003019747091457248\n",
      "after 3530 traning the loss is 0.00040008104406297207\n",
      "after 3531 traning the loss is 0.00038619828410446644\n",
      "after 3532 traning the loss is 0.000300222251098603\n",
      "after 3533 traning the loss is 0.0014750215923413634\n",
      "after 3534 traning the loss is 0.000811306294053793\n",
      "after 3535 traning the loss is 0.000633121351711452\n",
      "after 3536 traning the loss is 0.0002246800868306309\n",
      "after 3537 traning the loss is 0.023722106590867043\n",
      "after 3538 traning the loss is 0.0005248914239928126\n",
      "after 3539 traning the loss is 0.0009355228394269943\n",
      "after 3540 traning the loss is 0.01079594437032938\n",
      "after 3541 traning the loss is 0.0018599200993776321\n",
      "after 3542 traning the loss is 0.000759619870223105\n",
      "after 3543 traning the loss is 0.005246732849627733\n",
      "after 3544 traning the loss is 0.00437109125778079\n",
      "after 3545 traning the loss is 0.0034203357063233852\n",
      "after 3546 traning the loss is 0.0013449348043650389\n",
      "after 3547 traning the loss is 0.0037972694262862206\n",
      "after 3548 traning the loss is 0.005947061348706484\n",
      "after 3549 traning the loss is 0.009666220284998417\n",
      "after 3550 traning the loss is 0.0010925731621682644\n",
      "after 3551 traning the loss is 0.0019292975775897503\n",
      "after 3552 traning the loss is 0.0006531062535941601\n",
      "after 3553 traning the loss is 0.0009143282077275217\n",
      "after 3554 traning the loss is 0.0007330811349675059\n",
      "after 3555 traning the loss is 0.0023628955241292715\n",
      "after 3556 traning the loss is 0.0005900810938328505\n",
      "after 3557 traning the loss is 0.12754090130329132\n",
      "after 3558 traning the loss is 0.05153477191925049\n",
      "after 3559 traning the loss is 0.0001998625521082431\n",
      "after 3560 traning the loss is 0.030197620391845703\n",
      "after 3561 traning the loss is 0.0001828298845794052\n",
      "after 3562 traning the loss is 0.0002506580494809896\n",
      "after 3563 traning the loss is 0.00029868900310248137\n",
      "after 3564 traning the loss is 0.0005772494478151202\n",
      "after 3565 traning the loss is 0.007586217951029539\n",
      "after 3566 traning the loss is 0.0009466744959354401\n",
      "after 3567 traning the loss is 0.002750644227489829\n",
      "after 3568 traning the loss is 0.00024467636831104755\n",
      "after 3569 traning the loss is 0.000453743152320385\n",
      "after 3570 traning the loss is 0.0011628158390522003\n",
      "after 3571 traning the loss is 0.0006758000236004591\n",
      "after 3572 traning the loss is 0.0004915946628898382\n",
      "after 3573 traning the loss is 0.004505354445427656\n",
      "after 3574 traning the loss is 0.0005121047142893076\n",
      "after 3575 traning the loss is 0.00047725741751492023\n",
      "after 3576 traning the loss is 0.0006408476619981229\n",
      "after 3577 traning the loss is 0.0006337476661428809\n",
      "after 3578 traning the loss is 0.0005792205920442939\n",
      "after 3579 traning the loss is 0.0003544210339896381\n",
      "after 3580 traning the loss is 0.00041019520722329617\n",
      "after 3581 traning the loss is 0.0009629150154069066\n",
      "after 3582 traning the loss is 0.0003555579751264304\n",
      "after 3583 traning the loss is 0.004268937278538942\n",
      "after 3584 traning the loss is 0.00029612384969368577\n",
      "after 3585 traning the loss is 0.0011267336085438728\n",
      "after 3586 traning the loss is 0.0006377047393471003\n",
      "after 3587 traning the loss is 0.009989908896386623\n",
      "after 3588 traning the loss is 0.00029410040588118136\n",
      "after 3589 traning the loss is 0.008710653521120548\n",
      "after 3590 traning the loss is 0.00021437567193061113\n",
      "after 3591 traning the loss is 0.0005482255364768207\n",
      "after 3592 traning the loss is 0.0002965786843560636\n",
      "after 3593 traning the loss is 0.00031688762828707695\n",
      "after 3594 traning the loss is 0.0004081962979398668\n",
      "after 3595 traning the loss is 0.00208926759660244\n",
      "after 3596 traning the loss is 0.0008169127395376563\n",
      "after 3597 traning the loss is 0.005448215175420046\n",
      "after 3598 traning the loss is 0.005225994624197483\n",
      "after 3599 traning the loss is 0.0021262075752019882\n",
      "after 3600 traning the loss is 0.05045385658740997\n",
      "after 3601 traning the loss is 0.00042714044684544206\n",
      "after 3602 traning the loss is 0.000791950908023864\n",
      "after 3603 traning the loss is 0.0007644274737685919\n",
      "after 3604 traning the loss is 0.0005887848674319685\n",
      "after 3605 traning the loss is 0.04386062175035477\n",
      "after 3606 traning the loss is 0.0013948784908279777\n",
      "after 3607 traning the loss is 0.023072749376296997\n",
      "after 3608 traning the loss is 0.023829057812690735\n",
      "after 3609 traning the loss is 0.002346278168261051\n",
      "after 3610 traning the loss is 0.001499396632425487\n",
      "after 3611 traning the loss is 0.0014792288420721889\n",
      "after 3612 traning the loss is 0.0006078163278289139\n",
      "after 3613 traning the loss is 0.0006938850274309516\n",
      "after 3614 traning the loss is 0.0003303433477412909\n",
      "after 3615 traning the loss is 0.0007616585353389382\n",
      "after 3616 traning the loss is 0.00019445718498900533\n",
      "after 3617 traning the loss is 0.00032665507751517\n",
      "after 3618 traning the loss is 0.0018171507399529219\n",
      "after 3619 traning the loss is 0.009133433923125267\n",
      "after 3620 traning the loss is 0.0018473172094672918\n",
      "after 3621 traning the loss is 0.0004528784775175154\n",
      "after 3622 traning the loss is 0.09315507113933563\n",
      "after 3623 traning the loss is 0.000551341800019145\n",
      "after 3624 traning the loss is 0.00037613126914948225\n",
      "after 3625 traning the loss is 0.0008815225446596742\n",
      "after 3626 traning the loss is 0.0004514280008152127\n",
      "after 3627 traning the loss is 0.001808082452043891\n",
      "after 3628 traning the loss is 0.005569121800363064\n",
      "after 3629 traning the loss is 0.002103585284203291\n",
      "after 3630 traning the loss is 0.033925797790288925\n",
      "after 3631 traning the loss is 0.0008919507963582873\n",
      "after 3632 traning the loss is 0.008754393085837364\n",
      "after 3633 traning the loss is 0.004723154939711094\n",
      "after 3634 traning the loss is 0.0010042475769296288\n",
      "after 3635 traning the loss is 0.0017948184395208955\n",
      "after 3636 traning the loss is 0.004980618599802256\n",
      "after 3637 traning the loss is 0.0005171571392565966\n",
      "after 3638 traning the loss is 0.0035579309333115816\n",
      "after 3639 traning the loss is 0.007179945707321167\n",
      "after 3640 traning the loss is 0.00174755381885916\n",
      "after 3641 traning the loss is 0.004229722544550896\n",
      "after 3642 traning the loss is 0.0017199704889208078\n",
      "after 3643 traning the loss is 0.000542328751180321\n",
      "after 3644 traning the loss is 0.0005599470459856093\n",
      "after 3645 traning the loss is 0.0004900349886156619\n",
      "after 3646 traning the loss is 0.00041557251824997365\n",
      "after 3647 traning the loss is 0.0005194866098463535\n",
      "after 3648 traning the loss is 0.0003696967614814639\n",
      "after 3649 traning the loss is 0.0003797378740273416\n",
      "after 3650 traning the loss is 0.001218702644109726\n",
      "after 3651 traning the loss is 0.00041866666288115084\n",
      "after 3652 traning the loss is 0.0028962104115635157\n",
      "after 3653 traning the loss is 0.0002552099176682532\n",
      "after 3654 traning the loss is 0.0004039873310830444\n",
      "after 3655 traning the loss is 0.00033942528534680605\n",
      "after 3656 traning the loss is 0.0002140295400749892\n",
      "after 3657 traning the loss is 0.001753141637891531\n",
      "after 3658 traning the loss is 0.000543631671462208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3659 traning the loss is 0.00030319258803501725\n",
      "after 3660 traning the loss is 0.035051606595516205\n",
      "after 3661 traning the loss is 0.00015640030323993415\n",
      "after 3662 traning the loss is 0.0009364638244733214\n",
      "after 3663 traning the loss is 0.00036104422179050744\n",
      "after 3664 traning the loss is 0.0003543294733390212\n",
      "after 3665 traning the loss is 0.0009747750591486692\n",
      "after 3666 traning the loss is 0.0004186114529147744\n",
      "after 3667 traning the loss is 0.00032400761847384274\n",
      "after 3668 traning the loss is 0.001288699684664607\n",
      "after 3669 traning the loss is 0.0009847686160355806\n",
      "after 3670 traning the loss is 0.0010174766648560762\n",
      "after 3671 traning the loss is 0.0006810504128225148\n",
      "after 3672 traning the loss is 0.0041393679566681385\n",
      "after 3673 traning the loss is 0.00037021638127043843\n",
      "after 3674 traning the loss is 0.00716933561488986\n",
      "after 3675 traning the loss is 0.004121351521462202\n",
      "after 3676 traning the loss is 0.0011041623074561357\n",
      "after 3677 traning the loss is 0.0008314748993143439\n",
      "after 3678 traning the loss is 0.00022565387189388275\n",
      "after 3679 traning the loss is 0.0002568557974882424\n",
      "after 3680 traning the loss is 0.0001895801688078791\n",
      "after 3681 traning the loss is 0.00024415439111180604\n",
      "after 3682 traning the loss is 0.0004275355604477227\n",
      "after 3683 traning the loss is 0.0002854123304132372\n",
      "after 3684 traning the loss is 0.0002546290052123368\n",
      "after 3685 traning the loss is 0.00047386824735440314\n",
      "after 3686 traning the loss is 0.00014658045256510377\n",
      "after 3687 traning the loss is 0.0009745297720655799\n",
      "after 3688 traning the loss is 0.00031232848414219916\n",
      "after 3689 traning the loss is 0.00020626552577596158\n",
      "after 3690 traning the loss is 0.0014302600175142288\n",
      "after 3691 traning the loss is 0.013524819165468216\n",
      "after 3692 traning the loss is 0.004651520401239395\n",
      "after 3693 traning the loss is 0.0003155832819174975\n",
      "after 3694 traning the loss is 0.0006955377757549286\n",
      "after 3695 traning the loss is 0.001547332969494164\n",
      "after 3696 traning the loss is 0.004047746770083904\n",
      "after 3697 traning the loss is 0.00021514191757887602\n",
      "after 3698 traning the loss is 0.00048132636584341526\n",
      "after 3699 traning the loss is 0.0005283743375912309\n",
      "after 3700 traning the loss is 0.0005341242649592459\n",
      "after 3701 traning the loss is 0.011173403821885586\n",
      "after 3702 traning the loss is 0.0007865353254601359\n",
      "after 3703 traning the loss is 0.0002893616911023855\n",
      "after 3704 traning the loss is 0.00031511852284893394\n",
      "after 3705 traning the loss is 0.010868825949728489\n",
      "after 3706 traning the loss is 0.00046931777615100145\n",
      "after 3707 traning the loss is 0.007033538073301315\n",
      "after 3708 traning the loss is 0.0006780994590371847\n",
      "after 3709 traning the loss is 0.0006716554053127766\n",
      "after 3710 traning the loss is 0.0005010816385038197\n",
      "after 3711 traning the loss is 0.0006296779029071331\n",
      "after 3712 traning the loss is 0.0009982167975977063\n",
      "after 3713 traning the loss is 0.0003562637430150062\n",
      "after 3714 traning the loss is 0.00034804301685653627\n",
      "after 3715 traning the loss is 0.00018074049148708582\n",
      "after 3716 traning the loss is 0.00021716204355470836\n",
      "after 3717 traning the loss is 0.0002833153121173382\n",
      "after 3718 traning the loss is 0.00019892651471309364\n",
      "after 3719 traning the loss is 0.013000830076634884\n",
      "after 3720 traning the loss is 0.0005372599116526544\n",
      "after 3721 traning the loss is 0.0012449620990082622\n",
      "after 3722 traning the loss is 0.00023266936477739364\n",
      "after 3723 traning the loss is 0.0009995202999562025\n",
      "after 3724 traning the loss is 0.0009784286376088858\n",
      "after 3725 traning the loss is 0.0003450366493780166\n",
      "after 3726 traning the loss is 0.0007211478077806532\n",
      "after 3727 traning the loss is 0.0012355172075331211\n",
      "after 3728 traning the loss is 0.0005437784129753709\n",
      "after 3729 traning the loss is 0.0006769652827642858\n",
      "after 3730 traning the loss is 0.0006774784415028989\n",
      "after 3731 traning the loss is 0.0018022044096142054\n",
      "after 3732 traning the loss is 0.0021960625890642405\n",
      "after 3733 traning the loss is 0.001546960906125605\n",
      "after 3734 traning the loss is 0.00029226287733763456\n",
      "after 3735 traning the loss is 0.0003205084358341992\n",
      "after 3736 traning the loss is 0.0013930273707956076\n",
      "after 3737 traning the loss is 0.0004390310787130147\n",
      "after 3738 traning the loss is 0.0001991543103940785\n",
      "after 3739 traning the loss is 0.00023644062457606196\n",
      "after 3740 traning the loss is 0.0003055668785236776\n",
      "after 3741 traning the loss is 0.00017322422354482114\n",
      "after 3742 traning the loss is 0.00013896642485633492\n",
      "after 3743 traning the loss is 0.00021246893447823822\n",
      "after 3744 traning the loss is 0.007980030961334705\n",
      "after 3745 traning the loss is 0.0002067019377136603\n",
      "after 3746 traning the loss is 0.005773437209427357\n",
      "after 3747 traning the loss is 0.0003152375284116715\n",
      "after 3748 traning the loss is 0.000650835398118943\n",
      "after 3749 traning the loss is 0.001742920489050448\n",
      "after 3750 traning the loss is 0.003563891863450408\n",
      "after 3751 traning the loss is 0.00033008528407663107\n",
      "after 3752 traning the loss is 0.0013345974730327725\n",
      "after 3753 traning the loss is 0.0005535904783755541\n",
      "after 3754 traning the loss is 0.0014531349297612906\n",
      "after 3755 traning the loss is 0.0005818203208036721\n",
      "after 3756 traning the loss is 0.0004253495135344565\n",
      "after 3757 traning the loss is 0.003233116352930665\n",
      "after 3758 traning the loss is 0.0009635319001972675\n",
      "after 3759 traning the loss is 0.015613658353686333\n",
      "after 3760 traning the loss is 0.012274646200239658\n",
      "after 3761 traning the loss is 0.0009424716699868441\n",
      "after 3762 traning the loss is 0.0019231042824685574\n",
      "after 3763 traning the loss is 0.0003799686674028635\n",
      "after 3764 traning the loss is 0.0002957211690954864\n",
      "after 3765 traning the loss is 0.0007269305642694235\n",
      "after 3766 traning the loss is 0.0002517173415981233\n",
      "after 3767 traning the loss is 0.00039246026426553726\n",
      "after 3768 traning the loss is 0.0003388882614672184\n",
      "after 3769 traning the loss is 0.1301887333393097\n",
      "after 3770 traning the loss is 0.0018153914716094732\n",
      "after 3771 traning the loss is 0.00021349727467168123\n",
      "after 3772 traning the loss is 0.000143839351949282\n",
      "after 3773 traning the loss is 0.00014476529031526297\n",
      "after 3774 traning the loss is 0.00040366570465266705\n",
      "after 3775 traning the loss is 0.0007985381525941193\n",
      "after 3776 traning the loss is 0.0105223897844553\n",
      "after 3777 traning the loss is 0.00025952744181267917\n",
      "after 3778 traning the loss is 0.0001366270735161379\n",
      "after 3779 traning the loss is 0.0013530746800825\n",
      "after 3780 traning the loss is 0.0002179973089369014\n",
      "after 3781 traning the loss is 0.00046152289723977447\n",
      "after 3782 traning the loss is 0.0002726674429140985\n",
      "after 3783 traning the loss is 0.0001710947253741324\n",
      "after 3784 traning the loss is 0.0006752487970516086\n",
      "after 3785 traning the loss is 0.0003645654069259763\n",
      "after 3786 traning the loss is 0.0006976526929065585\n",
      "after 3787 traning the loss is 0.00025895345606841147\n",
      "after 3788 traning the loss is 0.0003407549229450524\n",
      "after 3789 traning the loss is 0.00029002639348618686\n",
      "after 3790 traning the loss is 0.00037149700801819563\n",
      "after 3791 traning the loss is 0.00017516963998787105\n",
      "after 3792 traning the loss is 0.07327727228403091\n",
      "after 3793 traning the loss is 0.0002759677008725703\n",
      "after 3794 traning the loss is 0.0008556091925129294\n",
      "after 3795 traning the loss is 0.005876221694052219\n",
      "after 3796 traning the loss is 0.004097512923181057\n",
      "after 3797 traning the loss is 0.0001873254805104807\n",
      "after 3798 traning the loss is 0.00011571778304642066\n",
      "after 3799 traning the loss is 0.003660565475001931\n",
      "after 3800 traning the loss is 0.00020332583517301828\n",
      "after 3801 traning the loss is 0.004648656118661165\n",
      "after 3802 traning the loss is 0.0001304390316363424\n",
      "after 3803 traning the loss is 0.0006529549136757851\n",
      "after 3804 traning the loss is 0.0001248386106453836\n",
      "after 3805 traning the loss is 0.00011750739213312045\n",
      "after 3806 traning the loss is 0.0011874232441186905\n",
      "after 3807 traning the loss is 0.0006482880562543869\n",
      "after 3808 traning the loss is 0.0014867553254589438\n",
      "after 3809 traning the loss is 0.0003016512782778591\n",
      "after 3810 traning the loss is 0.00018175746663473547\n",
      "after 3811 traning the loss is 0.011240188032388687\n",
      "after 3812 traning the loss is 0.0005118480767123401\n",
      "after 3813 traning the loss is 0.00031882873736321926\n",
      "after 3814 traning the loss is 0.0017024311237037182\n",
      "after 3815 traning the loss is 0.014266976155340672\n",
      "after 3816 traning the loss is 0.0008310413686558604\n",
      "after 3817 traning the loss is 0.009986208751797676\n",
      "after 3818 traning the loss is 0.0005293885478749871\n",
      "after 3819 traning the loss is 0.000263461988652125\n",
      "after 3820 traning the loss is 0.00018528985674493015\n",
      "after 3821 traning the loss is 0.000153803572175093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 3822 traning the loss is 0.02069135382771492\n",
      "after 3823 traning the loss is 0.0002499344409443438\n",
      "after 3824 traning the loss is 0.0002527823089621961\n",
      "after 3825 traning the loss is 0.00011233545956201851\n",
      "after 3826 traning the loss is 0.00016520361532457173\n",
      "after 3827 traning the loss is 9.454939572606236e-05\n",
      "after 3828 traning the loss is 0.0002554230741225183\n",
      "after 3829 traning the loss is 0.0006177772302180529\n",
      "after 3830 traning the loss is 0.0015309152659028769\n",
      "after 3831 traning the loss is 0.0003751428739633411\n",
      "after 3832 traning the loss is 0.0018555917777121067\n",
      "after 3833 traning the loss is 0.0008077680831775069\n",
      "after 3834 traning the loss is 0.00014146252942737192\n",
      "after 3835 traning the loss is 0.0003434342797845602\n",
      "after 3836 traning the loss is 0.0005343155353330076\n",
      "after 3837 traning the loss is 0.001040291623212397\n",
      "after 3838 traning the loss is 0.000463382137240842\n",
      "after 3839 traning the loss is 0.0001694221282377839\n",
      "after 3840 traning the loss is 0.0003692285972647369\n",
      "after 3841 traning the loss is 0.0003204482200089842\n",
      "after 3842 traning the loss is 0.00014067192387301475\n",
      "after 3843 traning the loss is 0.00017903203843161464\n",
      "after 3844 traning the loss is 0.02843043953180313\n",
      "after 3845 traning the loss is 0.00013770493387710303\n",
      "after 3846 traning the loss is 0.00021058533457107842\n",
      "after 3847 traning the loss is 9.06400746316649e-05\n",
      "after 3848 traning the loss is 0.0012705151457339525\n",
      "after 3849 traning the loss is 0.0004405970103107393\n",
      "after 3850 traning the loss is 0.0002960173587780446\n",
      "after 3851 traning the loss is 0.127241849899292\n",
      "after 3852 traning the loss is 0.006585344672203064\n",
      "after 3853 traning the loss is 0.000562449567951262\n",
      "after 3854 traning the loss is 0.009056349284946918\n",
      "after 3855 traning the loss is 0.0007280400604940951\n",
      "after 3856 traning the loss is 0.0005336520844139159\n",
      "after 3857 traning the loss is 0.00030054309172555804\n",
      "after 3858 traning the loss is 0.0033526832703500986\n",
      "after 3859 traning the loss is 0.009964930824935436\n",
      "after 3860 traning the loss is 0.0003161517670378089\n",
      "after 3861 traning the loss is 0.00023660612350795418\n",
      "after 3862 traning the loss is 0.0007529676659032702\n",
      "after 3863 traning the loss is 0.00044493775931186974\n",
      "after 3864 traning the loss is 0.0010593284387141466\n",
      "after 3865 traning the loss is 0.0007645860314369202\n",
      "after 3866 traning the loss is 0.00015646325482521206\n",
      "after 3867 traning the loss is 0.0039918082766234875\n",
      "after 3868 traning the loss is 0.00020400260109454393\n",
      "after 3869 traning the loss is 0.000926156179048121\n",
      "after 3870 traning the loss is 0.0010238832328468561\n",
      "after 3871 traning the loss is 8.975707169156522e-05\n",
      "after 3872 traning the loss is 0.0005411460297182202\n",
      "after 3873 traning the loss is 0.0005175655824132264\n",
      "after 3874 traning the loss is 0.000564505229704082\n",
      "after 3875 traning the loss is 0.0008193285902962089\n",
      "after 3876 traning the loss is 0.0005619055591523647\n",
      "after 3877 traning the loss is 0.00012033017992507666\n",
      "after 3878 traning the loss is 0.003555831266567111\n",
      "after 3879 traning the loss is 0.3124113976955414\n",
      "after 3880 traning the loss is 0.00022400218585971743\n",
      "after 3881 traning the loss is 0.0021851067431271076\n",
      "after 3882 traning the loss is 0.0009217408369295299\n",
      "after 3883 traning the loss is 0.0004316454578656703\n",
      "after 3884 traning the loss is 0.0002511603233870119\n",
      "after 3885 traning the loss is 0.17123566567897797\n",
      "after 3886 traning the loss is 0.00014175273827277124\n",
      "after 3887 traning the loss is 0.006669431459158659\n",
      "after 3888 traning the loss is 0.012994058430194855\n",
      "after 3889 traning the loss is 0.0009284683037549257\n",
      "after 3890 traning the loss is 0.016107935458421707\n",
      "after 3891 traning the loss is 4.48720675194636e-05\n",
      "after 3892 traning the loss is 0.0006517342990264297\n",
      "after 3893 traning the loss is 0.00013807123468723148\n",
      "after 3894 traning the loss is 0.0022677129600197077\n",
      "after 3895 traning the loss is 0.03746364638209343\n",
      "after 3896 traning the loss is 0.00019503870862536132\n",
      "after 3897 traning the loss is 0.0002781118964776397\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-94699ce4685c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss_plot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"after {} traning the loss is {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_sep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mg_sep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mvar_iter\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0macc_local\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    394\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "local_eop = 1\n",
    "var_iter = 100\n",
    "loss_plot = []\n",
    "test_plot = []\n",
    "g_sep = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_batch = next_batch(input_data_train, y_train_next.astype(int))\n",
    "    while train_batch.epo<local_eop:\n",
    "        in_dict = train_batch.get_dic_data()\n",
    "        [loss_val,_] = sess.run([loss, train_step],feed_dict = in_dict)\n",
    "        loss_plot.append(loss_val)\n",
    "        print(\"after {} traning the loss is {}\".format(g_sep, loss_val))\n",
    "        if g_sep+1%var_iter==0:\n",
    "            acc_local = sess.run([accuracy], feed_dict=in_dict)\n",
    "            print(\"acc is {}\".format(acc_local))\n",
    "            test_plot.append(acc_local)\n",
    "        g_sep+=1\n",
    "print(\"after {}epoch, the acc is {}\".format(local_eop, sess.run([acc], feed_dict=test_dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
